[{"title":"01 什么是神经网络？","url":"/blog/01%20%E4%BB%80%E4%B9%88%E6%98%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9F/","content":"\n一、课程开篇：深度学习与神经网络的关系\n “深度学习” &#x3D; 训练神经网络（尤其是非常大的神经网络）\n\n\n神经网络是深度学习的核心模型。\n本节目标：建立对神经网络的直观理解，而非数学推导。\n\n\n二、从一个简单例子开始：房价预测（Housing Price Prediction）1. 问题设定\n已知：6套房屋的 面积（x）  和 价格（y）\n目标：学习一个函数 ( f(x) \\rightarrow y )，用于预测新房子的价格\n\n2. 传统方法 vs 神经网络思路\n\n\n方法\n描述\n缺陷\n\n\n\n线性回归\n拟合一条直线：( y &#x3D; w x + b )\n可能预测出负价格（不合理）\n\n\n改进方案\n将函数在 y&#x3D;0 处截断： ( y &#x3D; \\max(0, w x + b) )\n更符合现实（价格 ≥ 0）\n\n\n\n✅ 这个“截断线性函数”就是 ReLU（Rectified Linear Unit）激活函数！\n\n\n三、最简单的神经网络：单个神经元输入 x（面积） → [神经元] → 输出 y（价格）\n\n\n神经元做了什么？\n\n接收输入 x\n计算线性组合：( z &#x3D; w x + b )\n应用 ReLU 激活：( a &#x3D; \\max(0, z) )\n输出预测值 y\n\n\n\n\n🔑 关键洞见：这个单神经元模型本身就是一个最简神经网络！\n\n\n四、构建更大的神经网络：多特征输入1. 更真实的房价影响因素　　除了面积，还考虑：\n\n卧室数量（# Bedrooms）\n邮政编码（Zip Code）→ 反映 步行便利性（Walkability）\n社区财富水平（Wealth）→ 反映 学区质量（School Quality）\n\n2. 神经网络如何“思考”？\n隐藏层神经元 自动学习中间抽象概念：\n\n某神经元 ≈ “家庭规模”（由面积 + 卧室数决定）\n某神经元 ≈ “生活便利度”（由邮编 + 财富决定）\n某神经元 ≈ “教育价值”（由邮编 + 财富决定）\n\n\n\n\n💡 重要原则：不要人为指定每个神经元的含义！而是把所有输入特征都提供给每个隐藏神经元，让网络自己决定如何组合。\n\n3. 全连接结构（Dense &#x2F; Fully Connected）\n输入层（4个特征） → 隐藏层（多个神经元）\n每个输入都连接到每个隐藏神经元\n这种结构赋予网络强大的函数拟合能力\n\n\n五、神经网络的核心优势\n\n\n优势\n说明\n\n\n\n✅ 端到端学习\n只需提供 (x, y) 训练数据，网络自动学习中间表示\n\n\n✅ 自动特征工程\n无需人工设计“家庭规模”等高级特征\n\n\n✅ 通用函数逼近器\n给定足够数据，可逼近任意复杂函数 ( f: x \\rightarrow y )\n\n\n✅ 适用于监督学习\n图像识别、语音转文本、房价预测等典型场景\n\n\n\n六、关键术语速记\n\n\n术语\n中文\n说明\n\n\n\nNeuron\n神经元\n基本计算单元\n\n\nReLU\n修正线性单元\n( \\text{ReLU}(z) &#x3D; \\max(0, z) )\n\n\nInput Layer\n输入层\n接收原始特征（如面积、卧室数）\n\n\nHidden Layer\n隐藏层\n自动学习特征表示的中间层\n\n\nOutput Layer\n输出层\n产生最终预测（如房价）\n\n\nFully Connected\n全连接\n每层神经元与下一层全部连接\n\n\n\n七、中文思维导图（脑图）mindmap  root(什么是神经网络？)    核心定义      深度学习 = 训练神经网络      监督学习：输入 x 到输出 y    简单模型：单神经元      输入：房屋面积(x)      处理：线性计算后取最大值（与0比较）      输出：房价(y)      这是最小的神经网络    扩展模型：多特征      输入特征        面积        卧室数        邮政编码        社区财富      隐藏层自动学习        家庭规模        步行便利性        学区质量      全连接结构        所有输入连接所有隐藏神经元    核心思想      数据驱动      不预设语义      网络自组织    优势      端到端学习      自动特征提取      强大表达能力    应用场景      房价预测      图像分类      语音识别      自然语言处理\n\n\n八、学习建议\n理解 ReLU 的作用：解决负输出问题，引入非线性。\n接受“黑箱”初期状态：不必强求解释每个神经元含义。\n动手实践：用 TensorFlow&#x2F;Keras 构建一个房价预测小网络。\n后续重点：损失函数、梯度下降、反向传播——这些是训练网络的引擎。\n\n\n　　✅ 总结一句话：\n\n神经网络是一个由大量简单计算单元（神经元）组成的系统，通过数据自动学习从输入到输出的复杂映射关系，而 ReLU 和全连接结构是其强大表达能力的基础。\n\n\n　　‍\n","categories":["神经网络与深度学习"]},{"title":"02 监督学习与神经网络","url":"/blog/02%20%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","content":"🎯 核心观点\n迄今为止，神经网络创造的绝大部分经济价值，都来自「监督学习」（Supervised Learning）。\n\n\n一、什么是监督学习？\n​定义：给定输入 ( x )，学习一个函数映射到输出 ( y )。\n\n输入 ( x )：特征（如房屋面积、用户年龄、图像像素等）\n输出 ( y )：目标标签（如房价、是否点击广告、物体类别等）\n\n\n​关键思想：通过大量带标签的数据（(x, y) 对）训练模型，使其能对新输入做出准确预测。\n\n\n\n二、监督学习的经典应用案例\n\n\n应用领域\n输入 (x)\n输出 (y)\n经济&#x2F;技术价值\n\n\n\n房价预测\n房屋特征（面积、卧室数等）\n价格\n结构化数据典型应用\n\n\n在线广告点击率预测\n用户信息 + 广告信息\n是否点击（0&#x2F;1）\n最赚钱的深度学习应用之一\n\n\n图像分类（计算机视觉）\n图像（像素）\n类别标签（如“猫”、“车”）\n推动CV革命，用于照片标签、安防等\n\n\n语音识别\n音频片段\n文本转录\n智能助手、字幕生成等\n\n\n机器翻译\n英文句子\n中文句子\n跨语言沟通自动化\n\n\n自动驾驶\n前方图像 + 雷达数据\n其他车辆位置&#x2F;轨迹\n多模态融合的关键组件\n\n\n\n💡 关键洞察：成功  &#x3D;  正确定义 (x) 和 (y) + 将监督学习嵌入更大系统（如自动驾驶）\n\n\n三、不同任务对应不同神经网络架构\n\n\n数据类型\n网络架构\n缩写\n适用场景\n\n\n\n通用&#x2F;结构化数据\n标准前馈神经网络\nMLP（多层感知机）\n房价预测、广告点击\n\n\n图像数据\n卷积神经网络\nCNN\n图像分类、目标检测\n\n\n序列数据（时间相关）\n循环神经网络\nRNN &#x2F; LSTM &#x2F; GRU\n语音、文本、时间序列\n\n\n多模态复杂任务\n混合&#x2F;定制架构\n—\n自动驾驶（图像+雷达）\n\n\n\n✅ ​CNN​：擅长提取局部空间特征（如边缘、纹理）✅ ​RNN：擅长处理顺序依赖（如“昨天”影响“今天”的语义）\n\n\n四、结构化数据 vs. 非结构化数据\n\n\n类型\n定义\n示例\n特点\n\n\n\n结构化数据\n表格形式，每列有明确含义\n房屋数据库（面积、卧室数）、用户画像（年龄、性别）\n易于传统模型处理，但神经网络也能提升精度\n\n\n非结构化数据\n无固定格式，原始信号\n图像、音频、文本\n人类天生擅长理解，神经网络突破最大领域\n\n\n\n🔥 ​深度学习的最大突破：让计算机终于能高效处理非结构化数据（图像&#x2F;语音&#x2F;文本），开启AI新时代。\n\n\n五、媒体关注 vs. 实际价值\n​媒体更爱报道​：识别猫、下围棋、生成艺术 → 因为直观、有趣、有“人性共鸣”\n\n​实际经济价值更多来自：\n\n广告推荐系统\n金融风控\n电商个性化推荐\n企业数据库智能分析\n\n\n\n\n📌 ​提醒​：不要只追逐“酷炫”应用，​结构化数据中的监督学习同样极具商业价值。\n\n\n六、为什么现在才爆发？（预告）\n虽然神经网络理论几十年前就存在，但直到近年才真正“起飞”。下一讲将探讨三大驱动力：\n\n​大数据（海量标注数据）\n​算力提升（GPU&#x2F;TPU）\n​算法改进（如ReLU、BatchNorm、残差连接等）\n\n\n\n🧠 思维导图（脑图）大纲（中文）mindmap    监督学习与神经网络      核心定义        输入 x        输出 y        学习映射函数      典型应用        房价预测          输入 房屋特征          输出 价格        在线广告          输入 用户和广告信息          输出 是否点击          经济价值最高        图像分类          输入 图像          输出 类别标签          使用 CNN        语音识别          输入 音频          输出 文本          使用 RNN        机器翻译          输入 英文句子          输出 中文句子        自动驾驶          输入 图像和雷达          输出 车辆位置      网络架构        标准神经网络          用于 结构化数据        卷积神经网络          用于 图像        循环神经网络          用于 序列数据        混合架构          用于 复杂任务      数据类型        结构化数据          表格形式          字段明确          如 房屋面积 用户年龄        非结构化数据          原始信号          如 图像 音频 文本          深度学习主战场      价值对比        媒体关注          识别猫          下围棋          生成艺术        实际价值          广告系统          个性化推荐          金融风控      为何近年爆发        大数据        强大算力        算法创新\n\n\n　　‍\n","categories":["神经网络与深度学习"]},{"title":"03 为什么深度学习现在才真正起飞？","url":"/blog/03%20%E4%B8%BA%E4%BB%80%E4%B9%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%B0%E5%9C%A8%E6%89%8D%E7%9C%9F%E6%AD%A3%E8%B5%B7%E9%A3%9E%EF%BC%9F/","content":"📌 核心观点总结1. 技术基础早已存在\n深度学习的核心思想（如神经网络）早在几十年前就已提出。\n但直到最近十年才大规模成功应用。\n\n2. 三大驱动力推动深度学习崛起✅ 驱动因素一：数据规模（Scale of Data）\n数字化社会带来海量数据：\n\n用户行为（网页、App、搜索等）\n传感器数据（手机摄像头、IoT设备、加速度计等）\n\n\n传统机器学习算法（如SVM、逻辑回归）在小数据下表现良好，但在大数据下性能趋于饱和。\n\n​神经网络的优势：随着数据量增加，大模型性能持续提升，无明显平台期。\n\n\n\n📊 图表说明：\n\nX轴：训练数据量（标注数据，记为 ​m）\nY轴：模型性能（如准确率）\n小&#x2F;中&#x2F;大神经网络：性能随规模增大而提升\n传统算法：早期上升快，后期停滞\n\n\n✅ 驱动因素二：计算能力（Scale of Computation）\nGPU、TPU 等专用硬件加速训练\n\n大模型训练成为可能\n\n​快速实验循环：\n\n快速训练 → 快速验证想法 → 快速迭代优化\n若训练需数周&#x2F;月，创新效率极低；若只需几分钟&#x2F;小时，则可高频试错\n\n\n\n✅ 驱动因素三：算法创新（Algorithmic Innovations）\n创新目标：提升训练速度与稳定性\n\n典型例子：激活函数从 Sigmoid → ReLU（Rectified Linear Unit）\n\nSigmoid 问题：梯度在两端趋近于0 → 梯度消失 → 学习缓慢\nReLU 优势：正区间梯度恒为1 → 梯度稳定 → 训练更快\n\n\n其他算法改进也多围绕“让大模型跑得更快、更稳”\n\n\n\n3. 关键结论\n深度学习的成功  &#x3D;  大数据 + 大模型 + 强算力 + 好算法\n\n在小数据场景下，特征工程和算法选择更重要，神经网络未必占优\n\n在大数据场景下，大型神经网络显著优于传统方法\n\n未来趋势依然乐观：\n\n数据持续增长\n硬件持续进步（GPU&#x2F;TPU&#x2F;光子芯片等）\n算法研究活跃，持续突破\n\n\n\n\n🧠 学习建议（来自吴恩达）\n当被问“为什么深度学习现在火了？”时，请画出上述“性能 vs 数据量”曲线图。\n在自己的组织中寻找具备大量标注数据的应用场景，这是深度学习发挥优势的关键前提。\n\n\n🌐 Mermaid 脑图mindmap  root((深度学习为何起飞?))    技术基础早已存在      “神经网络概念几十年前就有”    三大核心驱动力      数据规模(Scale of Data)        数字化社会产生海量数据          用户行为(网页/App)          传感器(IoT/手机摄像头)        传统算法性能饱和        神经网络随数据持续提升        关键: 需要大量**标注数据**(m)      计算能力(Scale of Computation)        GPU/TPU加速训练        支持大模型训练        快速实验循环          想法 → 实现 → 实验 → 迭代          训练快 = 创新快      算法创新(Algorithmic Innovation)        目标: 提速 &amp; 稳定        典型案例: Sigmoid → ReLU          Sigmoid: 梯度消失 → 学习慢          ReLU: 正区梯度=1 → 训练快        多数创新聚焦“高效计算”    关键洞察      小数据: 特征工程更重要      大数据: 大神经网络占优      成功公式: 大数据 + 大模型 + 强算力 + 好算法    未来展望      数据持续增长      硬件持续进步      算法研究活跃      深度学习将持续进步\n\n\n✅ 总结一句话：\n深度学习的爆发不是因为新理论，而是因为“数据够多、算力够强、算法够快”——三者共同解锁了神经网络的真正潜力。\n\n　　‍\n","categories":["神经网络与深度学习"]},{"title":"04 神经网络编程基础 — 二元分类（Binary Classification）","url":"/blog/04%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%20%E2%80%94%20%E4%BA%8C%E5%85%83%E5%88%86%E7%B1%BB%EF%BC%88Binary%20Classification%EF%BC%89/","content":"\n一、课程概述　　本节课是深度学习入门系列的第一部分，重点介绍神经网络编程的基本范式，并通过逻辑回归（Logistic Regression）  这一简单但核心的模型，讲解以下关键思想：\n\n向量化（Vectorization） ：避免使用显式的 for 循环遍历训练样本，而是通过矩阵运算一次性处理整个训练集。\n前向传播（Forward Propagation）与反向传播（Backward Propagation） ：神经网络计算的两个基本阶段。\n数据表示与符号约定（Notation） ：为后续构建更复杂的神经网络打下基础。\n\n\n💡 即使你已经熟悉逻辑回归，本节仍会引入新的工程视角和实现技巧。\n\n\n二、核心内容详解1. 二分类问题设定（Binary Classification Problem）\n任务目标：给定一张图像，判断是否为“猫”。\n\n若是猫 → 输出标签 $y &#x3D; 1$\n若不是猫 → 输出标签 $y &#x3D; 0$\n\n\n图像在计算机中的表示：\n\n彩色图像 &#x3D; 3 个通道（Red, Green, Blue）\n假设图像尺寸为 $64 \\times 64$ 像素\n则每个通道是一个 $64 \\times 64$ 的矩阵\n总像素数 &#x3D; $64 \\times 64 \\times 3 &#x3D; 12,!288$\n\n\n特征向量 $\\mathbf{x}$ 的构造：\n\n将所有 RGB 像素值“展平”（flatten &#x2F; unroll）成一个列向量\n得到输入特征向量 $\\mathbf{x} \\in \\mathbb{R}^{12288}$\n记作：$n_x &#x3D; 12288$，有时简写为 $n$\n\n\n\n\n✅ 目标：学习一个函数 $f: \\mathbf{x} \\rightarrow y \\in {0, 1}$\n\n\n2. 数据集与符号约定（Notation）\n\n\n符号\n含义\n\n\n\n$(x^{(i)}, y^{(i)})$\n第 $i$ 个训练样本（注意上标不是幂）\n\n\n$m$\n训练样本总数（有时写作 $m_{\\text{train}}$）\n\n\n$m_{\\text{test}}$\n测试集样本数量\n\n\n$\\mathbf{X}$\n所有训练输入组成的矩阵，维度为 $n_x \\times m$每一列是一个样本：$\\mathbf{X} &#x3D; [x^{(1)}\\ x^{(2)}\\ \\cdots\\ x^{(m)}]$\n\n\n$\\mathbf{Y}$\n所有标签组成的矩阵，维度为 $1 \\times m$$\\mathbf{Y} &#x3D; [y^{(1)}\\ y^{(2)}\\ \\cdots\\ y^{(m)}]$\n\n\n\n🔑 关键工程实践：将不同样本的数据按列堆叠（column-wise stacking） ，便于向量化计算。\n\n\n在 Python 中：\nX.shape  # (nx, m)Y.shape  # (1, m)\n\n\n⚠️ 注意：有些教材按行堆叠（$x^{(i)T}$ 作为行），但本课程采用列堆叠，更适配深度学习框架（如 NumPy、TensorFlow）。\n\n\n3. 为什么用逻辑回归教学？\n逻辑回归是最简单的神经网络（单神经元）\n\n它天然支持二分类\n\n可清晰展示：\n\n损失函数（Loss Function）\n梯度下降（Gradient Descent）\n前向&#x2F;反向传播流程\n\n\n为后续多层神经网络奠定基础\n\n\n\n4. 核心编程思想预告\n避免 for 循环：利用 NumPy 等库进行向量化运算，大幅提升效率。\n\n计算分两步：\n\n前向传播（Forward Prop） ：计算预测值 $\\hat{y}$\n反向传播（Backward Prop） ：计算梯度，更新参数\n\n\n这种模式将在深层网络中反复出现。\n\n\n\n三、学习建议\n动手实现逻辑回归的向量化版本（不用 for 循环）\n熟记符号约定（$\\mathbf{X}, \\mathbf{Y}, m, n_x$）\n理解“列堆叠”为何更适合 GPU&#x2F;并行计算\n下一节将正式推导逻辑回归的数学与代码\n\n\n四、Mermaid 脑图mindmap  root(神经网络编程基础)    二分类问题      输入 图像尺寸64乘64乘3      输出 标签y为1表示猫      输出 标签y为0表示非猫      特征向量x        维度nx为12288        由RGB像素展平得到    数据表示      单个训练样本 记作x上标i和y上标i      训练样本总数 m      测试样本总数 mTest    矩阵约定      输入矩阵X        所有样本按列堆叠        第1列是x上标1        第m列是x上标m        矩阵形状 nx行m列      标签矩阵Y        所有标签按列堆叠        第1列是y上标1        第m列是y上标m        矩阵形状 1行m列      工程惯例 每一列对应一个样本    编程范式      向量化计算        避免使用for循环        使用矩阵或张量整体运算      前向传播        计算预测值yHat      反向传播        计算损失对参数的梯度        更新模型参数    教学工具 逻辑回归      本质是单神经元模型      专用于二分类任务      为深层神经网络打基础\n\n\n五、总结　　本节课虽以“逻辑回归”为载体，实则传授了现代深度学习工程的核心范式：向量化 + 列堆叠数据 + 前&#x2F;后向传播分离。掌握这些，就等于拿到了进入神经网络世界的第一把钥匙 🔑。\n　　建议结合代码练习（如用 NumPy 实现无循环的逻辑回归），加深理解。\n","categories":["神经网络与深度学习"]},{"title":"05 逻辑回归","url":"/blog/05%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/","content":"一、课程内容详解1. 逻辑回归（Logistic Regression）简介\n适用场景：监督学习中的二分类问题，即标签 $y \\in {0, 1}$。\n\n目标：给定输入特征向量 $\\mathbf{x} \\in \\mathbb{R}^{n_x}$，模型输出预测值 $\\hat{y}$，表示：\n$$\\hat{y} &#x3D; P(y &#x3D; 1 \\mid \\mathbf{x})$$\n即在给定输入 $\\mathbf{x}$ 的条件下，$y &#x3D; 1$ 的概率。\n\n\n2. 为何不能直接使用线性回归？\n若令 $\\hat{y} &#x3D; \\mathbf{w}^\\top \\mathbf{x} + b$，则：\n\n输出可能 小于 0 或 大于 1；\n不符合概率定义（概率必须在 $[0, 1]$ 区间内）。\n\n\n\n3. 逻辑回归的核心：Sigmoid 函数\n引入 Sigmoid 激活函数：\n$$\\sigma(z) &#x3D; \\frac{1}{1 + e^{-z}}$$\n\n定义 $z &#x3D; \\mathbf{w}^\\top \\mathbf{x} + b$，则最终预测为：\n$$\\hat{y} &#x3D; \\sigma(\\mathbf{w}^\\top \\mathbf{x} + b)$$\n\n\nSigmoid 函数性质：\n当 $z \\to +\\infty$，$\\sigma(z) \\to 1$\n当 $z \\to -\\infty$，$\\sigma(z) \\to 0$\n当 $z &#x3D; 0$，$\\sigma(0) &#x3D; 0.5$\n\n4. 参数说明\n权重向量：$\\mathbf{w} \\in \\mathbb{R}^{n_x}$\n偏置项：$b \\in \\mathbb{R}$\n在本课程中，不采用将 $b$ 合并进 $\\mathbf{w}$ 的方式（即不引入 $x_0 &#x3D; 1$ 的技巧），而是将 $\\mathbf{w}$ 与 $b$ 作为独立参数处理ty-reference。\n\n5. 学习目标\n通过训练数据学习最优的 $\\mathbf{w}$ 和 $b$，使得 $\\hat{y}$ 尽可能接近真实标签 $y$。\n为此，需要定义一个损失函数（Loss Function）  和成本函数（Cost Function） （将在后续视频讲解）。\n\n\n二、课程核心要点总结\n\n\n要点\n内容\n\n\n\n任务类型\n二分类（Binary Classification）\n\n\n输入\n特征向量 $\\mathbf{x} \\in \\mathbb{R}^{n_x}$\n\n\n输出\n预测概率 $\\hat{y} &#x3D; P(y&#x3D;1 \\mid \\mathbf{x}) \\in [0,1]$\n\n\n模型结构\n$\\hat{y} &#x3D; \\sigma(\\mathbf{w}^\\top \\mathbf{x} + b)$\n\n\n激活函数\nSigmoid: $\\sigma(z) &#x3D; \\dfrac{1}{1 + e^{-z}}$\n\n\n参数形式\n$\\mathbf{w}$ 与 $b$ 分离，不合并\n\n\n后续步骤\n定义损失函数 → 优化参数 → 训练模型\n\n\n\n四、补充说明\n逻辑回归虽然名为“回归”，但本质是最简单的神经网络模型，仅包含一个神经元（带 Sigmoid 激活）ty-reference。\n它是构建更复杂神经网络（如多层感知机、深度网络）的基础单元ty-reference。\n在实际深度学习框架（如 PyTorch、TensorFlow）中，逻辑回归常作为分类任务的入门案例ty-reference。\n\n\n🎯 它是干啥的？\n解决二分类问题：比如判断一张图是不是猫（是&#x2F;不是）、邮件是不是垃圾邮件（是&#x2F;否）。\n输出一个概率：不是直接说“是”或“不是”，而是告诉你“有 85% 的可能是猫”。\n\n\n❌ 为啥不能用线性回归？　　想象一下：\n\n线性回归会说：“这张图是猫的概率是 1.5” 😱\n或者：“概率是  -0.3”？？？这根本说不通！\n\n　　✅ 概率必须在 0 到 1 之间！所以需要一个“聪明”的函数来帮忙。\n\n✨ 核心武器：Sigmoid 函数\n它长得像一条平滑的“S”曲线。\n\n特点：\n\n输入很大 → 输出接近 1\n输入很小（负得很多）→ 输出接近 0\n输入是 0 → 输出正好是 0.5\n\n\n\n　　👉 这样就能把任意数字“压缩”到 0～1 之间，完美表示概率！\n\n🧠 模型怎么算预测结果？\n先计算一个中间值： 权重 × 输入特征 + 偏置 （专业点叫：线性组合）\n把这个值丢进 Sigmoid 函数，得到最终预测概率！\n\n\n💡 举个例子：输入是一张图片 → 提取 1000 个特征 → 乘上对应的 1000 个权重 → 加上偏置 → 过 Sigmoid → 输出“是猫的概率”\n\n\n🔧 参数长什么样？\n权重（weights） ：和输入特征一样多，每个特征都有一个“重要程度”。\n偏置（bias） ：一个单独的数，用来微调结果。\n⚠️ 注意：本课程里，权重和偏置是分开存的，不搞“合并技巧”，更清晰！\n\n\n📚 接下来要学什么？\n如何判断模型好不好？→ 定义损失函数（比如交叉熵）\n怎么让模型变聪明？→ 用梯度下降调整参数\n最终目标：让预测概率越来越接近真实标签！\n\n\n🧩 超兼容中文脑图mindmap  root((逻辑回归))    用途      用于二分类问题      比如识别是不是猫    输出内容      输出一个概率值      范围在零到一之间    为什么不用线性回归      线性结果可能小于零      也可能大于一      不符合概率定义    核心方法      先算线性组合        权重乘以输入特征        再加上偏置      然后套上Sigmoid函数        把结果压到零到一    Sigmoid特点      输入很大时输出接近一      输入很小时输出接近零      输入为零时输出零点五    模型参数      权重向量        和输入特征数量相同      偏置项        一个单独的数字      权重和偏置分开处理    下一步      定义损失函数      优化参数      训练模型\n\n\n","categories":["神经网络与深度学习"]},{"title":"06 逻辑回归成本函数","url":"/blog/06%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%88%90%E6%9C%AC%E5%87%BD%E6%95%B0/","content":"1. 回顾：逻辑回归模型\n逻辑回归用于二分类问题。\n\n对于输入样本 $x^{(i)}$，模型预测输出为：\n$$\\hat{y}^{(i)} &#x3D; \\sigma(w^\\top x^{(i)} + b)$$\n其中 $\\sigma(z) &#x3D; \\frac{1}{1 + e^{-z}}$ 是 Sigmoid 函数。\n\n$w$ 和 $b$ 是需要学习的参数。\n\n\n\n注：上标 $(i)$ 表示第 $i$ 个训练样本。\n\n\n2. 为什么不能用平方误差作为损失函数？\n直觉上可能想用平方误差：$L(\\hat{y}, y) &#x3D; \\frac{1}{2}(\\hat{y} - y)^2$\n但问题在于：当把这个损失用于逻辑回归时，整体代价函数会变成非凸函数（non-convex） 。\n非凸函数意味着存在多个局部极小值，梯度下降可能无法找到全局最优解。\n因此，不推荐在逻辑回归中使用平方误差。\n\n\n3. 逻辑回归使用的损失函数（Loss Function）\n对单个样本 $(x^{(i)}, y^{(i)})$，定义损失函数为：\n$$L(\\hat{y}^{(i)}, y^{(i)}) &#x3D; -\\left[ y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)}) \\right]$$\n\n这个函数称为 对数损失（Log Loss）  或 交叉熵损失（Cross-Entropy Loss） 。\n\n\n直观理解：\n当 $y &#x3D; 1$ 时，损失简化为 $-\\log(\\hat{y})$：\n\n要使损失小 → $\\hat{y}$ 要接近 1。\n\n\n当 $y &#x3D; 0$ 时，损失简化为 $-\\log(1 - \\hat{y})$：\n\n要使损失小 → $\\hat{y}$ 要接近 0。\n\n\n完美符合二分类目标！\n\n\n\n4. 代价函数（Cost Function）\n损失函数衡量单个样本的误差。\n\n代价函数衡量整个训练集的平均误差：\n$$J(w, b) &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^{m} L(\\hat{y}^{(i)}, y^{(i)})$$\n展开后为：\n$$J(w, b) &#x3D; -\\frac{1}{m} \\sum_{i&#x3D;1}^{m} \\left[ y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)}) \\right]$$\n\n训练目标：找到 $w$ 和 **$b$**​ ，使得 $J(w, b)$ 最小。\n\n\n\n5. 逻辑回归与神经网络的关系\n逻辑回归可看作只有一个神经元的神经网络。\n输入层 → 单个计算单元（带 Sigmoid 激活）→ 输出。\n这是理解更复杂神经网络的起点。\n\n\n二、课程总结\n\n\n主题\n内容\n\n\n\n模型\n$\\hat{y} &#x3D; \\sigma(w^\\top x + b)$\n\n\n损失函数（单样本）\n$L &#x3D; -[y \\log(\\hat{y}) + (1 - y)\\log(1 - \\hat{y})]$\n\n\n代价函数（全体样本）\n$J(w, b) &#x3D; \\frac{1}{m} \\sum L^{(i)}$\n\n\n为何不用平方误差？\n导致非凸优化问题，梯度下降效果差\n\n\n为何用对数损失？\n凸函数，有唯一全局最优，梯度下降高效\n\n\n与神经网络关系\n逻辑回归 &#x3D; 单神经元网络\n\n\n\n三、脑图mindmap  root((逻辑回归代价函数))    模型回顾      输入是第i个样本x      参数包括权重w和偏置b      预测值通过Sigmoid函数计算      Sigmoid函数将任意实数映射到0到1之间    为什么不用平方误差      平方误差会导致优化问题非凸      非凸问题有多个局部最优解      梯度下降可能找不到全局最优      因此不适合逻辑回归    单样本损失函数      损失函数衡量单个预测的好坏      当真实标签是1时 希望预测值接近1      当真实标签是0时 希望预测值接近0      使用对数形式构建损失 更利于优化    整体代价函数      对所有训练样本求平均损失      代价函数是关于w和b的函数      训练目标是最小化这个代价函数      用梯度下降等方法优化参数    与神经网络的关系      逻辑回归可看作最简单的神经网络      只包含一个神经元      输入经过线性组合再加激活函数      是理解深度学习的基础单元\n\n\n四、学习建议\n动手推导：自己写出 $J(w, b)$ 对 $w$ 和 $b$ 的偏导数（后续课程会讲梯度下降）。\n可视化理解：画出 $-\\log(\\hat{y})$ 和 $-\\log(1 - \\hat{y})$ 的图像，感受损失如何惩罚错误预测。\n编程实现：用 Python&#x2F;Numpy 实现逻辑回归的前向传播和代价函数计算。\n\n\n","categories":["神经网络与深度学习"]},{"title":"07 梯度下降（Gradient Descent）","url":"/blog/07%20%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%EF%BC%88Gradient%20Descent%EF%BC%89/","content":"1. 背景回顾：逻辑回归与目标　　在逻辑回归中，我们希望学习参数 权重向量 $\\mathbf{w}$ 和 偏置 $b$，使得模型对训练数据的预测尽可能准确。\n\n对于第 $i$ 个样本，模型输出为：\n$$\\hat{y}^{(i)} &#x3D; \\sigma(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b)$$\n其中 $\\sigma(z) &#x3D; \\frac{1}{1 + e^{-z}}$ 是 sigmoid 激活函数。\n\n单个样本的 损失函数（Loss Function）  定义为：\n$$\\mathcal{L}(\\hat{y}^{(i)}, y^{(i)}) &#x3D; -\\left[ y^{(i)} \\log \\hat{y}^{(i)} + (1 - y^{(i)}) \\log (1 - \\hat{y}^{(i)}) \\right]$$\n\n整个训练集（共 $m$ 个样本）的 成本函数（Cost Function）  为平均损失：\n$$J(\\mathbf{w}, b) &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^{m} \\mathcal{L}(\\hat{y}^{(i)}, y^{(i)})$$\n\n\n\n✅ 目标：找到 $\\mathbf{w}$ 和 $b$，使得 $J(\\mathbf{w}, b)$ 最小。\n\n\n2. 成本函数的性质：凸性（Convexity）\n逻辑回归所使用的上述成本函数 $J(\\mathbf{w}, b)$ 是一个 凸函数（convex function） 。\n凸函数的图像像一个“碗”，只有一个全局最小值，没有局部极小值。\n这一性质保证了：无论从哪里初始化参数，梯度下降最终都会收敛到全局最优解（或非常接近）。\n\n\n💡 因此，逻辑回归通常将 $\\mathbf{w} &#x3D; \\mathbf{0}$, $b &#x3D; 0$ 作为初始值（无需随机初始化）。\n\n\n3. 梯度下降算法原理　　梯度下降是一种迭代优化算法，通过不断沿 成本函数下降最快的方向 更新参数，逐步逼近最小值。\n3.1 直观理解\n在参数空间 $(\\mathbf{w}, b)$ 中，$J(\\mathbf{w}, b)$ 构成一个曲面。\n梯度下降从某个初始点出发，每一步都朝 最陡下降方向 移动。\n步长由 学习率（learning rate）​$\\alpha$ 控制。\n\n3.2 一维简化示例（仅含 $w$）　　假设 $J(w)$ 是单变量函数，则梯度下降更新规则为：\n$$w :&#x3D; w - \\alpha \\cdot \\frac{dJ(w)}{dw}$$\n\n若导数 $\\frac{dJ}{dw} &gt; 0$，则 $w$ 减小（向左移动）；\n若导数 $\\frac{dJ}{dw} &lt; 0$，则 $w$ 增大（向右移动）；\n最终趋向最小值点。\n\n\n🔍 导数 $\\frac{dJ}{dw}$ 表示函数在该点的斜率，决定了下降方向。\n\n\n4. 逻辑回归中的梯度下降（多参数情况）　　由于 $J(\\mathbf{w}, b)$ 同时依赖 $\\mathbf{w}$ 和 $b$，需对每个参数分别求偏导并更新：\n参数更新规则：$$\\begin{aligned}\\mathbf{w} &amp;:&#x3D; \\mathbf{w} - \\alpha \\cdot \\frac{\\partial J(\\mathbf{w}, b)}{\\partial \\mathbf{w}} \\b &amp;:&#x3D; b - \\alpha \\cdot \\frac{\\partial J(\\mathbf{w}, b)}{\\partial b}\\end{aligned}$$\n\n⚠️ 注意：因为 $J$ 是多变量函数，使用 偏导数（partial derivative）  符号 $\\partial$，而非普通导数 $d$。但在实际编程和直觉理解中，可将其视为“对某个参数的斜率”。\n\n编程实现约定：\n在代码中，通常用变量名表示导数：\n\n​dw 表示 $\\frac{\\partial J}{\\partial \\mathbf{w}}$\n​db 表示 $\\frac{\\partial J}{\\partial b}$\n\n\n更新语句写作：\nw = w - alpha * dwb = b - alpha * db\n\n\n5. 关于导数与微积分的说明\n即使你不熟悉微积分，也可以有效使用神经网络。\n课程后续会提供直观的导数理解（如“斜率”、“变化率”），无需深入数学推导。\n核心思想：导数告诉我们当前参数应往哪个方向调整，才能更快降低成本。\n\n\n6. 总结：梯度下降的核心步骤\n初始化：设 $\\mathbf{w} &#x3D; \\mathbf{0}$, $b &#x3D; 0$（逻辑回归常用）。\n\n重复以下步骤直到收敛：\n\n计算成本函数 $J(\\mathbf{w}, b)$\n\n计算偏导数 $\\frac{\\partial J}{\\partial \\mathbf{w}}$ 和 $\\frac{\\partial J}{\\partial b}$\n\n更新参数：\n$$\\mathbf{w} \\leftarrow \\mathbf{w} - \\alpha \\cdot \\frac{\\partial J}{\\partial \\mathbf{w}}, \\quadb \\leftarrow b - \\alpha \\cdot \\frac{\\partial J}{\\partial b}$$\n\n\n\n输出：学到的最优参数 $\\mathbf{w}^, b^$\n\n\n\n附：符号说明\n\n\n符号\n含义\n\n\n\n$\\mathbf{x}^{(i)}$\n第 $i$ 个输入特征向量\n\n\n$y^{(i)}$\n第 $i$ 个真实标签（0 或 1）\n\n\n$\\hat{y}^{(i)}$\n模型预测输出\n\n\n$J(\\mathbf{w}, b)$\n成本函数（整体误差）\n\n\n$\\alpha$\n学习率（控制步长）\n\n\n$\\frac{\\partial J}{\\partial \\mathbf{w}}$\n成本对权重的偏导（梯度）\n\n\n$\\frac{\\partial J}{\\partial b}$\n成本对偏置的偏导\n\n\n\n　　✅ 关键洞见：梯度下降不是魔法，而是一个基于局部斜率信息进行迭代修正的过程。只要成本函数是凸的（如逻辑回归），它就能可靠地找到最优解。\n","categories":["神经网络与深度学习"]},{"title":"08 导数的直观理解（Intuition about Derivatives）","url":"/blog/08%20%E5%AF%BC%E6%95%B0%E7%9A%84%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3%EF%BC%88Intuition%20about%20Derivatives%EF%BC%89/","content":"1. 为什么需要理解导数？\n在深度学习中，不需要精通微积分也能有效应用神经网络。\n\n但具备对导数的直观理解有助于：\n\n理解反向传播（Backpropagation）\n调试和设计模型\n理解优化算法（如梯度下降）\n\n\n后续课程（如第4周）会将微积分封装在 forward​ 和 backward 函数中，使用者无需手动计算。\n\n\n\n✅ 建议：即使微积分生疏，只要能完成编程作业，就能成功应用深度学习。\n\n\n2. 导数 &#x3D; 斜率（Slope）\n关键思想：“导数”听起来很吓人，其实它就是函数在某一点的斜率。每当你听到“导数”，就想象成“这条曲线在这里有多陡”。\n\n\n3. 直观例子：线性函数 $f(a) &#x3D; 3a$▶ 场景一：$a &#x3D; 2$\n$f(2) &#x3D; 3 \\times 2 &#x3D; 6$\n将 $a$ 微小扰动：$a &#x3D; 2.001$\n则 $f(2.001) &#x3D; 3 \\times 2.001 &#x3D; 6.003$\n\n　　👉 变化量分析：\n\n输入变化：$\\Delta a &#x3D; 0.001$\n\n输出变化：$\\Delta f &#x3D; 0.003$\n\n斜率（导数）为：\n$$\\frac{\\Delta f}{\\Delta a} &#x3D; \\frac{0.003}{0.001} &#x3D; 3$$\n\n\n▶ 场景二：$a &#x3D; 5$\n$f(5) &#x3D; 15$\n\n$f(5.001) &#x3D; 15.003$\n\n同样得到：\n$$\\frac{\\Delta f}{\\Delta a} &#x3D; \\frac{0.003}{0.001} &#x3D; 3$$\n\n\n　　✅ 结论：对于线性函数 $f(a) &#x3D; 3a$，处处导数为 3。\n\n4. 导数的标准记法　　导数有两种等价写法：\n\n莱布尼茨记法（Leibniz notation） ：\n $$ \\frac{d f(a)}{d a} &#x3D; 3 $$\n\n算子记法：\n $$ \\frac{d}{d a} f(a) &#x3D; 3 $$\n\n\n\n这两种写法含义完全相同，都表示：“当 $a$ 增加一个极小量时，$f(a)$ 增加 3 倍该量”。\n\n\n5. 导数的正式定义（补充说明）　　虽然课程用 $\\Delta a &#x3D; 0.001$ 来直观解释，但严格数学定义中，导数是当扰动趋于无穷小时的极限：\n$$\\frac{d f(a)}{d a} &#x3D; \\lim_{\\Delta a \\to 0} \\frac{f(a + \\Delta a) - f(a)}{\\Delta a}$$\n\n在 $f(a) &#x3D; 3a$ 的例子中，无论 $\\Delta a$ 多小，比值恒为 3。\n因此导数恒等于 3。\n\n\n6. 重要性质：线性函数的导数恒定\n对于任意 $a$，函数 $f(a) &#x3D; 3a$ 的斜率不变。\n几何上：直线的“陡峭程度”处处相同。\n代数上：导数不依赖于 $a$ 的具体取值。\n\n\n7. 下一讲预告：非线性函数的导数\n线性函数的导数是常数。\n非线性函数（如 $f(a) &#x3D; a^2$）的导数随位置变化。\n例如：在 $a &#x3D; 2$ 处的斜率 ≠ 在 $a &#x3D; 5$ 处的斜率。\n这正是深度学习中梯度变化驱动参数更新的核心机制。\n\n\n🔑 核心要点总结\n\n\n概念\n说明\n\n\n\n导数 &#x3D; 斜率\n描述函数输出随输入微小变化的变化率\n\n\n直观理解方法\n给输入一个微小扰动（如 +0.001），观察输出变化\n\n\n线性函数导数\n$f(a) &#x3D; ka \\Rightarrow \\frac{df}{da} &#x3D; k$（常数）\n\n\n导数记法\n$\\frac{df(a)}{da}$ 或 $\\frac{d}{da}f(a)$\n\n\n实际应用\n深度学习中通过自动微分（Autograd）自动计算，无需手推\n\n\n\n📌 学习建议\n不必死记公式，重在理解“导数反映变化快慢” 。\n动手画图：在纸上画 $f(a) &#x3D; 3a$，标出两个点，计算斜率。\n下一课重点：非线性函数的局部斜率如何变化——这是神经网络训练的关键！\n\n","categories":["神经网络与深度学习"]},{"title":"09 导数（Derivatives）的直观理解与实例","url":"/blog/09%20%E5%AF%BC%E6%95%B0%EF%BC%88Derivatives%EF%BC%89%E7%9A%84%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3%E4%B8%8E%E5%AE%9E%E4%BE%8B/","content":"一、导数的本质：函数在某一点的“斜率”\n导数（Derivative）描述的是函数在某一点处的瞬时变化率，也就是该点处切线的斜率。\n\n对于函数 $f(a)$，其在点 $a$ 处的导数记作：\n$$\\frac{d}{da} f(a)$$\n或简写为 $f’(a)$。\n\n\n\n✅ 关键理解：导数不是固定值（除非函数是直线），它会随着输入 $a$ 的不同而变化。\n\n\n二、经典例子 1：$f(a) &#x3D; a^2$1. 在 $a &#x3D; 2$ 处\n$f(2) &#x3D; 2^2 &#x3D; 4$\n\n微小扰动：$a &#x3D; 2.001 \\Rightarrow f(2.001) \\approx 4.004001 \\approx 4.004$\n\n变化量：\n\n$\\Delta a &#x3D; 0.001$\n$\\Delta f \\approx 0.004$\n\n\n斜率（导数）近似为：\n$$\\frac{\\Delta f}{\\Delta a} \\approx \\frac{0.004}{0.001} &#x3D; 4$$\n\n\n2. 在 $a &#x3D; 5$ 处\n$f(5) &#x3D; 25$\n\n$f(5.001) \\approx 25.010005 \\approx 25.010$\n\n$\\Delta f \\approx 0.010$，所以：\n$$\\frac{\\Delta f}{\\Delta a} \\approx \\frac{0.010}{0.001} &#x3D; 10$$\n\n\n3. 通用导数公式（来自微积分）：$$\\frac{d}{da}(a^2) &#x3D; 2a$$\n\n验证：\n\n当 $a &#x3D; 2$，导数 &#x3D; $2 \\times 2 &#x3D; 4$\n当 $a &#x3D; 5$，导数 &#x3D; $2 \\times 5 &#x3D; 10$\n\n\n\n\n🔍 注意：使用 $\\Delta a &#x3D; 0.001$ 是近似，真正的导数定义基于无穷小（infinitesimal）变化。因此实际值（如 4.004001）与线性近似（4.004）之间存在微小误差。\n\n\n三、经典例子 2：$f(a) &#x3D; a^3$\n微积分公式：\n$$\\frac{d}{da}(a^3) &#x3D; 3a^2$$\n\n举例：$a &#x3D; 2$\n\n$f(2) &#x3D; 8$\n$f(2.001) &#x3D; (2.001)^3 \\approx 8.012018 \\approx 8.012$\n$\\Delta f \\approx 0.012$，$\\Delta a &#x3D; 0.001$\n斜率 ≈ $0.012 &#x2F; 0.001 &#x3D; 12$\n\n\n公式验证：\n$$3a^2 &#x3D; 3 \\times 2^2 &#x3D; 3 \\times 4 &#x3D; 12 \\quad \\checkmark$$\n\n\n\n四、经典例子 3：$f(a) &#x3D; \\log(a)$（自然对数，底数为 $e$）\n微积分公式：\n$$\\frac{d}{da} \\log(a) &#x3D; \\frac{1}{a}$$\n\n举例：$a &#x3D; 2$\n\n$f(2) &#x3D; \\log(2) \\approx 0.69315$\n$f(2.001) \\approx 0.69365$\n$\\Delta f \\approx 0.0005$\n预期变化：$\\frac{1}{a} \\cdot \\Delta a &#x3D; \\frac{1}{2} \\times 0.001 &#x3D; 0.0005 \\quad \\checkmark$\n\n\n\n\n💡 这说明：当 $a &#x3D; 2$ 时，函数增长速度只有输入变化的一半。\n\n\n五、两个核心结论（Take-home Messages）✅ 结论 1：导数就是函数在某点的斜率\n对于线性函数（如 $f(a) &#x3D; 3a$），导数处处相同（恒为 3）。\n对于非线性函数（如 $a^2, a^3, \\log a$），导数随 $a$ 变化而变化。\n\n✅ 结论 2：常用导数公式可查表获得\n不必每次都从定义推导，可直接使用微积分中的标准公式：\n$$\\begin{aligned}\\frac{d}{da}(a^n) &amp;&#x3D; n a^{n-1} \\\\frac{d}{da}(\\log a) &amp;&#x3D; \\frac{1}{a} \\\\frac{d}{da}(e^a) &amp;&#x3D; e^a \\\\frac{d}{da}(\\sin a) &amp;&#x3D; \\cos a \\quad \\text{（虽未提及，但属常见）}\\end{aligned}$$\n\n\n\n六、后续预告：计算图（Computation Graph）\n下一节将引入计算图（Computation Graph）的概念。\n用于高效计算复杂函数（如神经网络中的损失函数）的导数。\n为反向传播（Backpropagation）打下基础。\n\n\n📌 总结表格：常见函数及其导数\n\n\n函数 $f(a)$\n导数 $f’(a) &#x3D; \\frac{d}{da}f(a)$\n\n\n\n$a^2$\n$2a$\n\n\n$a^3$\n$3a^2$\n\n\n$\\log a$\n$\\dfrac{1}{a}$\n\n\n$c \\cdot a$（$c$ 为常数）\n$c$\n\n\n\n　　希望这份总结能帮助你牢固掌握导数的直观意义与计算方法，为后续学习神经网络的梯度下降和反向传播做好准备！\n","categories":["神经网络与深度学习"]},{"title":"10 计算图（Computation Graph）","url":"/blog/10%20%E8%AE%A1%E7%AE%97%E5%9B%BE%EF%BC%88Computation%20Graph%EF%BC%89/","content":"1. 背景与动机　　在深度学习中，神经网络的计算通常分为两个阶段：\n\n前向传播（Forward Propagation） ：从输入开始，逐层计算，最终得到输出（例如损失函数 $J$）。\n反向传播（Backward Propagation） ：从输出 $J$ 出发，利用链式法则计算梯度（即偏导数），用于参数更新。\n\n　　计算图 正是用来清晰地表示这两个过程的工具。它将复杂的函数分解为一系列基本运算，并以有向图的形式组织起来，使得前向计算和反向求导变得直观且系统化。\n\n2. 简化示例：函数 $J &#x3D; 3(a + bc)$　　为了说明计算图，课程使用了一个比完整神经网络更简单的函数：\n$$J &#x3D; 3(a + bc)$$\n　　这个函数可以分解为 三个计算步骤：\n步骤 1：计算中间变量 $u$$$u &#x3D; b \\cdot c$$\n步骤 2：计算中间变量 $v$$$v &#x3D; a + u$$\n步骤 3：计算最终输出 $J$$$J &#x3D; 3v$$\n\n3. 构建计算图　　计算图是一个有向无环图（DAG） ，节点表示变量或操作，边表示数据流向。\n\n输入节点（叶节点） ：$a, b, c$\n中间节点：$u, v$\n输出节点（根节点） ：$J$\n\n　　图结构如下（文字描述）：\na ----\\        +----&gt; [v = a + u] ----&gt; [J = 3v]b ----\\       ^       *----&gt; [u = b·c]c ----/\n\n\n从左到右（蓝色箭头）：前向传播，计算 $J$ 的值。\n从右到左（红色箭头）：反向传播，计算 $\\frac{\\partial J}{\\partial a}, \\frac{\\partial J}{\\partial b}, \\frac{\\partial J}{\\partial c}$。\n\n\n4. 前向传播示例（数值代入）　　设：\n\n$a &#x3D; 5$\n$b &#x3D; 3$\n$c &#x3D; 2$\n\n　　则逐步计算：\n\n$u &#x3D; b \\cdot c &#x3D; 3 \\times 2 &#x3D; 6$\n$v &#x3D; a + u &#x3D; 5 + 6 &#x3D; 11$\n$J &#x3D; 3v &#x3D; 3 \\times 11 &#x3D; 33$\n\n　　验证原式：\n$$J &#x3D; 3(a + bc) &#x3D; 3(5 + 3 \\times 2) &#x3D; 3(5 + 6) &#x3D; 3 \\times 11 &#x3D; 33 \\quad \\checkmark$$\n\n5. 为什么需要计算图？\n模块化：将复杂函数拆解为简单操作（如加法、乘法），便于实现和调试。\n自动微分基础：现代深度学习框架（如 TensorFlow、PyTorch）底层都依赖计算图来自动计算梯度。\n高效反向传播：通过链式法则（Chain Rule） ，从输出 $J$ 反向逐层计算梯度，避免重复计算。\n\n\n在后续课程中，将展示如何通过从右向左的反向遍历，高效计算：\n$$\\frac{\\partial J}{\\partial a},\\quad \\frac{\\partial J}{\\partial b},\\quad \\frac{\\partial J}{\\partial c}$$\n\n\n6. 与神经网络的联系\n在逻辑回归或神经网络中，$J$ 通常是损失函数（Loss Function） ，例如交叉熵损失。\n我们的目标是最小化 $J$，因此需要知道 $J$ 对每个参数（如权重 $w$、偏置 $b$）的梯度。\n计算图使得这一过程系统化、可扩展，即使网络有成千上万个参数，也能高效求导。\n\n\n✅ 总结要点\n\n\n概念\n说明\n\n\n\n计算图\n将函数分解为基本运算的有向图，用于组织前向&#x2F;反向计算\n\n\n前向传播\n从输入到输出，计算函数值（如 $J$）\n\n\n反向传播\n从输出到输入，利用链式法则计算梯度\n\n\n中间变量\n如 $u &#x3D; bc$, $v &#x3D; a + u$，使复杂函数可分解\n\n\n实际应用\n是自动微分和深度学习框架的核心机制\n\n\n","categories":["神经网络与深度学习"]},{"title":"11 使用计算图求导（Derivatives with a Computation Graph）","url":"/blog/11%20%E4%BD%BF%E7%94%A8%E8%AE%A1%E7%AE%97%E5%9B%BE%E6%B1%82%E5%AF%BC%EF%BC%88Derivatives%20with%20a%20Computation%20Graph%EF%BC%89/","content":"🧠 课程核心思想　　在深度学习中，反向传播（Backpropagation）  是通过计算图（Computation Graph）  高效计算损失函数对各参数偏导数的核心机制。本节通过一个具体例子，展示了如何利用链式法则（Chain Rule）  沿着计算图从右向左（backward pass）  逐层计算梯度。\n\n📐 示例函数与计算图结构　　考虑如下函数：\n$$J &#x3D; 3v, \\quad \\text{其中} \\quad v &#x3D; a + u, \\quad u &#x3D; b \\cdot c$$\n　　给定初始值：\n\n$a &#x3D; 5$\n$b &#x3D; 3$\n$c &#x3D; 2$\n$u &#x3D; b \\cdot c &#x3D; 6$\n$v &#x3D; a + u &#x3D; 11$\n$J &#x3D; 3v &#x3D; 33$\n\n　　计算图结构（从左到右为前向传播）：\nb ──┐    X → u ──┐c ──┘       +            → v → ×3 → Ja ──────────┘\n\n\n🔁 反向传播：从右向左计算导数　　目标：计算 $J$ 对各个中间变量和输入变量的偏导数：\n\n$\\frac{\\partial J}{\\partial v}$\n$\\frac{\\partial J}{\\partial a}$\n$\\frac{\\partial J}{\\partial u}$\n$\\frac{\\partial J}{\\partial b}$\n$\\frac{\\partial J}{\\partial c}$\n\n\n1. 计算 $\\frac{\\partial J}{\\partial v}$$$J &#x3D; 3v \\quad \\Rightarrow \\quad \\frac{\\partial J}{\\partial v} &#x3D; 3$$\n　　记作代码中的变量：dv = 3\n\n2. 计算 $\\frac{\\partial J}{\\partial a}$　　由于 $v &#x3D; a + u$，所以：\n$$\\frac{\\partial v}{\\partial a} &#x3D; 1$$\n　　应用链式法则：\n$$\\frac{\\partial J}{\\partial a} &#x3D; \\frac{\\partial J}{\\partial v} \\cdot \\frac{\\partial v}{\\partial a} &#x3D; 3 \\cdot 1 &#x3D; 3$$\n　　记作：da = 3\n\n3. 计算 $\\frac{\\partial J}{\\partial u}$　　同理，$v &#x3D; a + u \\Rightarrow \\frac{\\partial v}{\\partial u} &#x3D; 1$\n$$\\frac{\\partial J}{\\partial u} &#x3D; \\frac{\\partial J}{\\partial v} \\cdot \\frac{\\partial v}{\\partial u} &#x3D; 3 \\cdot 1 &#x3D; 3$$\n　　记作：du = 3\n\n4. 计算 $\\frac{\\partial J}{\\partial b}$　　由于 $u &#x3D; b \\cdot c$，所以：\n$$\\frac{\\partial u}{\\partial b} &#x3D; c &#x3D; 2$$\n　　再用链式法则：\n$$\\frac{\\partial J}{\\partial b} &#x3D; \\frac{\\partial J}{\\partial u} \\cdot \\frac{\\partial u}{\\partial b} &#x3D; 3 \\cdot 2 &#x3D; 6$$\n　　记作：db = 6\n\n5. 计算 $\\frac{\\partial J}{\\partial c}$　　同理：\n$$\\frac{\\partial u}{\\partial c} &#x3D; b &#x3D; 3$$\n$$\\frac{\\partial J}{\\partial c} &#x3D; \\frac{\\partial J}{\\partial u} \\cdot \\frac{\\partial u}{\\partial c} &#x3D; 3 \\cdot 3 &#x3D; 9$$\n　　记作：dc = 9\n\n💻 编程中的简化记号　　在实际代码（如 Python）中，为了简洁，通常省略对最终输出 $J$ 的显式书写，而直接用变量名表示其对某中间量的偏导：\n\n\n\n数学符号\n代码变量名\n含义\n\n\n\n$\\frac{\\partial J}{\\partial v}$\n​dv\n$J$ 对 $v$ 的偏导\n\n\n$\\frac{\\partial J}{\\partial a}$\n​da\n$J$ 对 $a$ 的偏导\n\n\n$\\frac{\\partial J}{\\partial u}$\n​du\n$J$ 对 $u$ 的偏导\n\n\n$\\frac{\\partial J}{\\partial b}$\n​db\n$J$ 对 $b$ 的偏导\n\n\n$\\frac{\\partial J}{\\partial c}$\n​dc\n$J$ 对 $c$ 的偏导\n\n\n\n✅ 这种记法假设所有导数都是相对于同一个最终输出 $J$（即损失函数），因此无需重复写 dJ_d...。\n\n\n🔗 链式法则（Chain Rule）回顾　　若变量依赖关系为：\n$$J \\leftarrow v \\leftarrow u \\leftarrow b$$\n　　则：\n$$\\frac{\\partial J}{\\partial b} &#x3D; \\frac{\\partial J}{\\partial v} \\cdot \\frac{\\partial v}{\\partial u} \\cdot \\frac{\\partial u}{\\partial b}$$\n　　但在本例中，因 $v$ 直接依赖于 $u$，而 $J$ 直接依赖于 $v$，可分步计算：\n$$\\frac{\\partial J}{\\partial b} &#x3D; \\underbrace{\\frac{\\partial J}{\\partial u}}{&#x3D;3} \\cdot \\underbrace{\\frac{\\partial u}{\\partial b}}{&#x3D;2} &#x3D; 6$$\n\n🔄 前向 vs 反向传播\n\n\n步骤\n方向\n目的\n计算内容\n\n\n\n前向传播（Forward Pass）\n左 → 右\n计算输出 $J$\n$a, b, c \\rightarrow u \\rightarrow v \\rightarrow J$\n\n\n反向传播（Backward Pass）\n右 ← 左\n计算梯度\n$\\frac{\\partial J}{\\partial v} \\rightarrow \\frac{\\partial J}{\\partial a}, \\frac{\\partial J}{\\partial u} \\rightarrow \\frac{\\partial J}{\\partial b}, \\frac{\\partial J}{\\partial c}$\n\n\n\n⚡ 效率关键：反向传播避免重复计算，利用已算出的上游梯度（如 dv​）高效推导下游梯度（如 da​, du）。\n\n\n✅ 关键结论\n计算图是理解和实现自动微分的基础工具。\n反向传播的本质是链式法则的系统化应用。\n编程中采用简写记号（如 ​dv​​ ,  ​da​​ ）极大提升代码可读性与简洁性。\n所有梯度最终服务于优化目标（如最小化损失函数 **$J$**​ ） 。\n\n\n🔜 下一步预告　　正如视频末尾所提，下一节将把这一机制应用到逻辑回归（Logistic Regression）  中，展示如何在真实模型中计算梯度并更新参数。\n","categories":["神经网络与深度学习"]},{"title":"12 逻辑回归的梯度下降（Gradient Descent for Logistic Regression）","url":"/blog/12%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%EF%BC%88Gradient%20Descent%20for%20Logistic%20Regression%EF%BC%89/","content":"‍\n1. 逻辑回归模型回顾　　对于一个样本 $(x, y)$，其中：\n\n输入特征向量：$\\mathbf{x} &#x3D; \\begin{bmatrix} x_1 \\ x_2 \\end{bmatrix} \\in \\mathbb{R}^2$（为简化，假设只有两个特征）\n参数：权重 $\\mathbf{w} &#x3D; \\begin{bmatrix} w_1 \\ w_2 \\end{bmatrix}$，偏置 $b \\in \\mathbb{R}$\n真实标签：$y \\in {0, 1}$\n\n　　逻辑回归的前向传播过程如下：\n$$\\begin{aligned}z &amp;&#x3D; \\mathbf{w}^\\top \\mathbf{x} + b &#x3D; w_1 x_1 + w_2 x_2 + b \\\\hat{y} &#x3D; a &amp;&#x3D; \\sigma(z) &#x3D; \\frac{1}{1 + e^{-z}} \\\\mathcal{L}(a, y) &amp;&#x3D; -y \\log a - (1 - y) \\log(1 - a)\\end{aligned}$$\n　　其中：\n\n$a$ 是模型预测的概率输出（即 $\\hat{y}$）\n$\\mathcal{L}(a, y)$ 是单个样本的损失函数（Loss） ，也称为交叉熵损失（Cross-Entropy Loss）\n\n\n2. 反向传播：计算梯度（使用计算图）　　目标：通过反向传播计算损失 $\\mathcal{L}$ 对参数 $\\mathbf{w}$ 和 $b$ 的偏导数，用于梯度下降更新。\n步骤 1：计算 $\\frac{\\partial \\mathcal{L}}{\\partial a}$$$\\frac{\\partial \\mathcal{L}}{\\partial a} &#x3D; -\\frac{y}{a} + \\frac{1 - y}{1 - a}$$\n　　记作：da = -y/a + (1 - y)/(1 - a)\n\n步骤 2：计算 $\\frac{\\partial \\mathcal{L}}{\\partial z}$　　利用链式法则：\n$$\\frac{\\partial \\mathcal{L}}{\\partial z} &#x3D; \\frac{\\partial \\mathcal{L}}{\\partial a} \\cdot \\frac{\\partial a}{\\partial z}$$\n　　由于 $a &#x3D; \\sigma(z)$，其导数为：\n$$\\frac{\\partial a}{\\partial z} &#x3D; a(1 - a)$$\n　　因此：\n$$\\frac{\\partial \\mathcal{L}}{\\partial z} &#x3D; \\left( -\\frac{y}{a} + \\frac{1 - y}{1 - a} \\right) \\cdot a(1 - a) &#x3D; a - y$$\n　　记作：dz = a - y\n\n✅ 这是一个非常简洁且重要的结果：dz &#x3D; a - y\n\n\n步骤 3：计算参数梯度　　根据 $z &#x3D; w_1 x_1 + w_2 x_2 + b$，可得：\n$$\\begin{aligned}\\frac{\\partial \\mathcal{L}}{\\partial w_1} &amp;&#x3D; \\frac{\\partial \\mathcal{L}}{\\partial z} \\cdot \\frac{\\partial z}{\\partial w_1} &#x3D; dz \\cdot x_1 \\\\frac{\\partial \\mathcal{L}}{\\partial w_2} &amp;&#x3D; dz \\cdot x_2 \\\\frac{\\partial \\mathcal{L}}{\\partial b} &amp;&#x3D; dz \\cdot 1 &#x3D; dz\\end{aligned}$$\n　　记作：\n\n​dw1 = x1 * dz\n​dw2 = x2 * dz\n​db = dz\n\n\n3. 梯度下降更新规则（单个样本）　　设学习率为 $\\alpha$，则参数更新为：\n$$\\begin{aligned}w_1 &amp;:&#x3D; w_1 - \\alpha \\cdot dw_1 &#x3D; w_1 - \\alpha \\cdot x_1 (a - y) \\w_2 &amp;:&#x3D; w_2 - \\alpha \\cdot x_2 (a - y) \\b &amp;:&#x3D; b - \\alpha \\cdot (a - y)\\end{aligned}$$\n　　这是一次基于单个训练样本的梯度下降步骤。\n\n4. 扩展到整个训练集（预告）　　在实际训练中，我们有 $m$ 个样本 ${(\\mathbf{x}^{(i)}, y^{(i)})}_{i&#x3D;1}^m$。此时需计算总损失（Cost Function） ：\n$$J(\\mathbf{w}, b) &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^m \\mathcal{L}(a^{(i)}, y^{(i)})$$\n　　对应的梯度为各样本梯度的平均值：\n$$\\begin{aligned}d\\mathbf{w} &amp;&#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^m \\mathbf{x}^{(i)} (a^{(i)} - y^{(i)}) \\db &amp;&#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^m (a^{(i)} - y^{(i)})\\end{aligned}$$\n　　然后进行批量更新：\n$$\\begin{aligned}\\mathbf{w} &amp;:&#x3D; \\mathbf{w} - \\alpha \\cdot d\\mathbf{w} \\b &amp;:&#x3D; b - \\alpha \\cdot db\\end{aligned}$$\n\n🔜 这部分内容将在下一节课中详细讲解（向量化与批量梯度下降）。\n\n\n5. 关键公式总结（必须记住）\n\n\n量\n表达式\n\n\n\n预测值\n$a &#x3D; \\sigma(\\mathbf{w}^\\top \\mathbf{x} + b)$\n\n\n单样本损失\n$\\mathcal{L}(a, y) &#x3D; -y \\log a - (1 - y)\\log(1 - a)$\n\n\n关键中间梯度\n$dz &#x3D; a - y$\n\n\n权重梯度\n$d\\mathbf{w} &#x3D; \\mathbf{x} \\cdot dz$\n\n\n偏置梯度\n$db &#x3D; dz$\n\n\n\n6. 为什么用计算图？　　虽然对逻辑回归而言，直接求导更简单，但吴恩达使用计算图（Computation Graph）  是为了：\n\n建立反向传播（Backpropagation）的直观理解\n为后续深度神经网络的梯度计算打下基础\n强调链式法则（Chain Rule）  在自动微分中的核心作用\n\n\n　　✅ 学习建议：\n\n动手推导一次 $\\frac{\\partial \\mathcal{L}}{\\partial z} &#x3D; a - y$，加深理解\n尝试用 Python 实现单样本和批量的逻辑回归梯度下降\n注意区分 Loss（单样本）  和 Cost（全体样本平均）\n\n","categories":["神经网络与深度学习"]},{"title":"13 在 m 个样本上执行梯度下降（Gradient Descent on m Examples）","url":"/blog/13%20%E5%9C%A8%20m%20%E4%B8%AA%E6%A0%B7%E6%9C%AC%E4%B8%8A%E6%89%A7%E8%A1%8C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%EF%BC%88Gradient%20Descent%20on%20m%20Examples%EF%BC%89/","content":"🎯 课程目标　　本节课程的核心目标是：\n\n如何将单样本的梯度下降扩展到整个训练集（m 个样本）上，并为后续向量化（Vectorization）打下基础。\n\n\n📌 1. 逻辑回归回顾　　我们考虑一个二分类问题，使用 逻辑回归（Logistic Regression）  模型：\n\n输入特征：$\\mathbf{x}^{(i)} \\in \\mathbb{R}^n$（第 $i$ 个样本）\n真实标签：$y^{(i)} \\in {0, 1}$\n模型参数：权重 $\\mathbf{w} \\in \\mathbb{R}^n$，偏置 $b \\in \\mathbb{R}$\n\n　　模型预测为：\n$$z^{(i)} &#x3D; \\mathbf{w}^\\top \\mathbf{x}^{(i)} + b,\\quad a^{(i)} &#x3D; \\sigma(z^{(i)}) &#x3D; \\frac{1}{1 + e^{-z^{(i)}}}$$\n\n📌 2. 成本函数（Cost Function）　　对 m 个训练样本，整体成本函数 $J(\\mathbf{w}, b)$ 定义为 平均交叉熵损失：\n$$J(\\mathbf{w}, b) &#x3D; -\\frac{1}{m} \\sum_{i&#x3D;1}^{m} \\left[ y^{(i)} \\log a^{(i)} + (1 - y^{(i)}) \\log (1 - a^{(i)}) \\right]$$\n\n注意：这是 单个样本损失 $\\mathcal{L}^{(i)}$ 的平均值。\n\n\n📌 3. 单样本梯度（回顾）　　对于单个样本 $(\\mathbf{x}^{(i)}, y^{(i)})$，我们已知其梯度为：\n$$dz^{(i)} &#x3D; a^{(i)} - y^{(i)}$$\n$$d\\mathbf{w}^{(i)} &#x3D; \\mathbf{x}^{(i)} dz^{(i)}, \\quad db^{(i)} &#x3D; dz^{(i)}$$\n　　其中 $d\\mathbf{w}^{(i)} \\in \\mathbb{R}^n$ 是该样本对权重的梯度贡献。\n\n📌 4. 整体梯度（m 个样本）　　由于成本函数是 平均损失，其梯度也是 各样本梯度的平均：\n$$\\frac{\\partial J}{\\partial \\mathbf{w}} &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^{m} d\\mathbf{w}^{(i)} &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^{m} \\mathbf{x}^{(i)} (a^{(i)} - y^{(i)})$$\n$$\\frac{\\partial J}{\\partial b} &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^{m} (a^{(i)} - y^{(i)})$$\n\n这就是我们要用于梯度下降的 总梯度。\n\n\n📌 5. 梯度下降算法（朴素实现，含 for 循环）　　以下是 一次梯度下降迭代 的完整步骤（假设特征数 $n &#x3D; 2$，便于理解）：\n初始化J = 0dw1 = 0, dw2 = 0, db = 0\n\n遍历所有 m 个样本（第一个 for 循环）　　对每个 $i &#x3D; 1$ 到 $m$：\n\n计算线性输出：\n $$ z^{(i)} &#x3D; w_1 x_1^{(i)} + w_2 x_2^{(i)} + b $$\n\n计算激活（预测）：\n $$ a^{(i)} &#x3D; \\sigma(z^{(i)}) $$\n\n累加成本函数：\n $$ J \\mathrel{+}&#x3D; -\\left[ y^{(i)} \\log a^{(i)} + (1 - y^{(i)}) \\log (1 - a^{(i)}) \\right] $$\n\n计算局部梯度：\n $$ dz^{(i)} &#x3D; a^{(i)} - y^{(i)} $$\n\n累加参数梯度：\n $$ dw_1 \\mathrel{+}&#x3D; x_1^{(i)} \\cdot dz^{(i)} \\ dw_2 \\mathrel{+}&#x3D; x_2^{(i)} \\cdot dz^{(i)} \\ db \\mathrel{+}&#x3D; dz^{(i)} $$\n\n\n\n如果有 $n$ 个特征，则需对 $j &#x3D; 1$ 到 $n$ 执行 dw_j += x_j^{(i)} * dz^{(i)}​ —— 这就是 第二个 for 循环。\n\n计算平均梯度$$dw_1 &#x3D; \\frac{dw_1}{m},\\quad dw_2 &#x3D; \\frac{dw_2}{m},\\quad db &#x3D; \\frac{db}{m},\\quad J &#x3D; \\frac{J}{m}$$\n更新参数（学习率 $\\alpha$）$$w_1 :&#x3D; w_1 - \\alpha \\cdot dw_1 \\w_2 :&#x3D; w_2 - \\alpha \\cdot dw_2 \\b :&#x3D; b - \\alpha \\cdot db$$\n\n此过程需重复多次（多个 epoch）以完成训练。\n\n\n⚠️ 6. 问题：双重 for 循环效率低　　上述实现存在两个显式 for 循环：\n\n外层循环：遍历 $m$ 个样本\n内层循环：遍历 $n$ 个特征（如 dw1, dw2, ..., dwn）\n\n　　在深度学习中，当 $m$ 和 $n$ 都很大时（如百万级样本、千维特征），这种写法 速度极慢。\n\n✅ 7. 解决方案：向量化（Vectorization）\n向量化 &#x3D; 用矩阵&#x2F;向量运算代替 for 循环\n\n　　核心思想：\n\n将所有样本堆叠成矩阵：$\\mathbf{X} \\in \\mathbb{R}^{n \\times m}$\n所有标签组成向量：$\\mathbf{Y} \\in \\mathbb{R}^{1 \\times m}$\n一次性计算所有 $z^{(i)}, a^{(i)}, dz^{(i)}$ 等\n\n　　例如：\n$$\\mathbf{Z} &#x3D; \\mathbf{w}^\\top \\mathbf{X} + b \\quad (\\text{形状: } 1 \\times m) \\\\mathbf{A} &#x3D; \\sigma(\\mathbf{Z}) \\d\\mathbf{Z} &#x3D; \\mathbf{A} - \\mathbf{Y} \\d\\mathbf{w} &#x3D; \\frac{1}{m} \\mathbf{X} d\\mathbf{Z}^\\top \\quad (\\text{形状: } n \\times 1) \\db &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^{m} dZ^{(i)}$$\n\n向量化后，无需任何 for 循环，且可利用 GPU 并行加速。\n\n\n🔚 总结\n\n\n内容\n说明\n\n\n\n成本函数\n$J(\\mathbf{w}, b) &#x3D; -\\frac{1}{m} \\sum_{i&#x3D;1}^m [y^{(i)} \\log a^{(i)} + (1-y^{(i)}) \\log(1-a^{(i)})]$\n\n\n单样本梯度\n$dz^{(i)} &#x3D; a^{(i)} - y^{(i)}$, $d\\mathbf{w}^{(i)} &#x3D; \\mathbf{x}^{(i)} dz^{(i)}$\n\n\n整体梯度\n对所有样本求平均\n\n\n朴素实现\n需要两个 for 循环（样本 + 特征）\n\n\n高效实现\n使用向量化，完全消除 for 循环\n\n\n下一步\n学习 向量化技术，实现无循环的高效梯度下降\n\n\n","categories":["神经网络与深度学习"]},{"title":"14 向量化（Vectorization）","url":"/blog/14%20%E5%90%91%E9%87%8F%E5%8C%96%EF%BC%88Vectorization%EF%BC%89/","content":"1. 什么是向量化？　　向量化 是指避免在代码中使用显式的 for 循环，转而使用高度优化的矩阵&#x2F;向量运算（如 NumPy 中的内置函数），从而大幅提升计算效率。\n\n在深度学习中，我们经常处理大规模数据集（例如百万级特征或样本）。如果使用非向量化实现，程序运行会极其缓慢；而向量化能充分利用 CPU&#x2F;GPU 的并行计算能力（SIMD 指令），使代码快数百倍甚至上千倍。\n\n\n2. 为什么需要向量化？—— 以逻辑回归为例　　在逻辑回归中，我们需要计算：\n$$z &#x3D; \\mathbf{w}^\\top \\mathbf{x} + b$$\n　　其中：\n\n$\\mathbf{w} \\in \\mathbb{R}^{n_x}$ 是权重向量，\n$\\mathbf{x} \\in \\mathbb{R}^{n_x}$ 是输入特征向量，\n$b$ 是偏置项，\n$n_x$ 是特征数量（可能非常大）。\n\n❌ 非向量化实现（显式 for 循环）：z = 0for i in range(n_x):    z += w[i] * x[i]z += b\n\n\n时间复杂度：$O(n_x)$\n实际运行慢，无法利用硬件并行性。\n\n✅ 向量化实现（使用 NumPy）：z = np.dot(w, x) + b\n\n\n一行代码完成相同计算。\n底层由 C&#x2F;Fortran 优化，自动并行化。\n速度提升可达 300 倍以上（见下文实验）。\n\n\n3. 实验演示：向量化 vs 非向量化实验设置：\n创建两个长度为 $10^6$ 的随机向量 $\\mathbf{a}, \\mathbf{b} \\in \\mathbb{R}^{1,000,000}$\n计算点积：$\\mathbf{a}^\\top \\mathbf{b} &#x3D; \\sum_{i&#x3D;1}^{10^6} a_i b_i$\n\n✅ 向量化版本（NumPy）：c = np.dot(a, b)\n\n\n耗时：约 1.5 毫秒\n\n❌ 非向量化版本（for 循环）：c = 0for i in range(1000000):    c += a[i] * b[i]\n\n\n耗时：约 480 毫秒\n慢了约 300 倍！\n\n\n💡 结果验证：两种方法计算出的 c​ 值完全一致（如 250699.123…），说明向量化不仅快，而且数值正确。\n\n\n4. 为什么向量化更快？\n现代 CPU 和 GPU 都支持 SIMD（Single Instruction, Multiple Data）  指令。\n\n即：一条指令同时处理多个数据。\n\n\nNumPy 等库底层使用高度优化的 C&#x2F;C++&#x2F;BLAS 库（如 OpenBLAS、Intel MKL），能自动利用 SIMD 并行。\n\n显式 for 循环由 Python 解释器逐行执行，解释开销大 + 无并行 → 极慢。\n\n\n\n⚠️ 注意：即使没有 GPU，仅在 CPU 上，向量化也能带来巨大加速！\n\n\n5. 核心原则（Rule of Thumb）\n “尽可能避免显式 for 循环！”\n\n　　在深度学习中，以下操作都应向量化：\n\n矩阵乘法（如 $\\mathbf{W} \\mathbf{X}$）\n激活函数（如 np.sigmoid(Z) 作用于整个矩阵）\n损失函数计算\n梯度更新\n\n\n6. 后续内容预告　　本节是向量化的入门。接下来课程将：\n\n展示如何向量化整个逻辑回归模型（包括前向传播、损失计算、反向传播）\n\n扩展到多样本批量（batch）处理，即对 $m$ 个样本同时计算：\n$$\\mathbf{Z} &#x3D; \\mathbf{W}^\\top \\mathbf{X} + b$$\n其中 $\\mathbf{X} \\in \\mathbb{R}^{n_x \\times m}$ 是所有样本组成的矩阵。\n\n\n\n✅ 总结要点\n\n\n项目\n非向量化\n向量化\n\n\n\n代码风格\n显式 for 循环\n使用 np.dot​, np.sum 等\n\n\n速度\n慢（毫秒 → 秒级）\n快（微秒 → 毫秒级）\n\n\n可读性\n冗长\n简洁、数学直观\n\n\n并行性\n无\n自动利用 CPU&#x2F;GPU 并行\n\n\n推荐程度\n❌ 避免\n✅ 必须掌握\n\n\n\n　　掌握向量化是高效深度学习编程的基石。它不仅让代码跑得更快，还能让你更专注于算法本身，而非低效的循环细节。\n","categories":["神经网络与深度学习"]},{"title":"16 向量化逻辑回归（Vectorizing Logistic Regression）","url":"/blog/16%20%E5%90%91%E9%87%8F%E5%8C%96%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88Vectorizing%20Logistic%20Regression%EF%BC%89/","content":"🎯 核心目标　　在不使用任何显式 for​ 循环的前提下，一次性对整个训练集（共 $M$ 个样本）进行前向传播（forward propagation）和激活值计算，从而大幅提升计算效率。这是深度学习中向量化（vectorization）的核心思想。\n\n1️⃣ 传统方法 vs 向量化方法❌ 传统方法（低效）　　对于每个训练样本 $x^{(i)} \\in \\mathbb{R}^{n_x}$，依次计算：\n$$z^{(i)} &#x3D; w^T x^{(i)} + b \\a^{(i)} &#x3D; \\sigma(z^{(i)}) &#x3D; \\frac{1}{1 + e^{-z^{(i)}}}$$\n　　需要循环 $M$ 次 → 时间复杂度高，无法利用现代 CPU&#x2F;GPU 的并行能力。\n✅ 向量化方法（高效）　　将所有训练样本堆叠成矩阵，一次性完成全部计算。\n\n2️⃣ 数据表示：从向量到矩阵\n单个输入样本：$x^{(i)} \\in \\mathbb{R}^{n_x}$\n\n将 $M$ 个样本横向堆叠成 输入矩阵 $X$：\n$$X &#x3D; \\begin{bmatrix}\\vert &amp; \\vert &amp; &amp; \\vert \\x^{(1)} &amp; x^{(2)} &amp; \\cdots &amp; x^{(M)} \\\\vert &amp; \\vert &amp; &amp; \\vert\\end{bmatrix} \\in \\mathbb{R}^{n_x \\times M}$$\n\n\n\n💡 注意：每一列是一个样本（column-major），这是深度学习中的标准约定。\n\n\n3️⃣ 向量化前向传播步骤 1：计算所有 $z^{(i)}$ → 得到向量 $Z$　　我们希望一次性计算：\n$$Z &#x3D; \\begin{bmatrix} z^{(1)} &amp; z^{(2)} &amp; \\cdots &amp; z^{(M)} \\end{bmatrix} \\in \\mathbb{R}^{1 \\times M}$$\n　　利用矩阵运算：\n$$Z &#x3D; w^T X + b$$\n　　其中：\n\n$w \\in \\mathbb{R}^{n_x}$ 是权重向量\n$w^T X \\in \\mathbb{R}^{1 \\times M}$：每一列是 $w^T x^{(i)}$\n$b \\in \\mathbb{R}$ 是标量偏置\n\n\n🔍 广播机制（Broadcasting）虽然 $b$ 是标量，但在 NumPy 中执行 w.T @ X + b 时，Python 会自动将 $b$ 广播为形状 $(1, M)$ 的行向量 $[b, b, \\dots, b]$，然后逐元素相加。\n\n步骤 2：计算所有激活值 $a^{(i)}$ → 得到向量 $A$　　定义 sigmoid 函数作用于整个矩阵（向量化 sigmoid）：\n$$A &#x3D; \\sigma(Z) &#x3D; \\frac{1}{1 + e^{-Z}} \\quad \\text{（逐元素应用）}$$\n　　结果：\n$$A &#x3D; \\begin{bmatrix} a^{(1)} &amp; a^{(2)} &amp; \\cdots &amp; a^{(M)} \\end{bmatrix} \\in \\mathbb{R}^{1 \\times M}$$\n\n4️⃣ Python &#x2F; NumPy 实现（一行代码！）import numpy as np# 假设：# X.shape = (n_x, M)# w.shape = (n_x, 1) 或 (n_x,) —— 但通常用 (n_x, 1)# b is a scalarZ = np.dot(w.T, X) + b          # shape: (1, M)A = 1 / (1 + np.exp(-Z))        # vectorized sigmoid, shape: (1, M)\n\n\n✅ 这两行代码就完成了对整个训练集的前向传播，无任何 for 循环！\n\n\n5️⃣ 关键优势总结\n\n\n项目\n传统方法\n向量化方法\n\n\n\n循环次数\n$M$ 次\n0 次\n\n\n计算效率\n低（串行）\n高（并行）\n\n\n代码简洁性\n冗长\n极简（1~2 行）\n\n\n可扩展性\n难以扩展到深层网络\n天然适用于神经网络\n\n\n\n6️⃣ 后续预告：向量化反向传播　　课程提到，反向传播（backward propagation）同样可以向量化：\n\n一次性计算所有样本的梯度 $\\frac{\\partial \\mathcal{L}}{\\partial w}$ 和 $\\frac{\\partial \\mathcal{L}}{\\partial b}$\n\n利用 $dZ &#x3D; A - Y$（其中 $Y$ 是真实标签矩阵）\n\n最终得到：\n$$dw &#x3D; \\frac{1}{M} X (A - Y)^T \\db &#x3D; \\frac{1}{M} \\sum_{i&#x3D;1}^M (a^{(i)} - y^{(i)})$$\n\n\n\n这部分将在下一节详细讲解。\n\n\n📌 总结要点（Key Takeaways）\n向量化是深度学习高效计算的基石。\n\n将训练样本按列堆叠成矩阵 $X \\in \\mathbb{R}^{n_x \\times M}$。\n\n前向传播可写为：\n $$ Z &#x3D; w^T X + b,\\quad A &#x3D; \\sigma(Z) $$\n\n利用 NumPy 的广播机制和向量化函数，避免显式循环。\n\n此方法可无缝推广到多层神经网络。\n\n\n\n　　如果你正在学习深度学习编程，强烈建议你在 Jupyter Notebook 中亲手实现这个向量化逻辑回归，并与 for 循环版本对比速度（可用 %timeit），你会直观感受到向量化的威力！\n","categories":["神经网络与深度学习"]},{"title":"17 向量化逻辑回归的梯度计算（Vectorizing Logistic Regression's Gradient Computation）","url":"/blog/17%20%E5%90%91%E9%87%8F%E5%8C%96%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%A2%AF%E5%BA%A6%E8%AE%A1%E7%AE%97%EF%BC%88Vectorizing%20Logistic%20Regression_s%20Gradient%20Computation%EF%BC%89/","content":"一、背景回顾　　在上一节中，我们已经学会了如何通过向量化一次性计算整个训练集上的预测值：\n\n对于 $m$ 个训练样本，输入矩阵为：\n$$X &#x3D; \\begin{bmatrix}| &amp; | &amp; &amp; | \\x^{(1)} &amp; x^{(2)} &amp; \\cdots &amp; x^{(m)} \\| &amp; | &amp; &amp; |\\end{bmatrix} \\in \\mathbb{R}^{n \\times m}$$\n其中每个 $x^{(i)} \\in \\mathbb{R}^n$ 是一个样本的特征向量。\n\n参数向量 $w \\in \\mathbb{R}^n$，偏置标量 $b \\in \\mathbb{R}$。\n\n线性输出（logits）为：\n$$Z &#x3D; w^\\top X + b \\quad \\text{（在 NumPy 中自动广播）}$$\n注意：这里 $b$ 是标量，但 NumPy 会将其广播到长度为 $m$ 的向量。\n\n激活（预测概率）为：\n$$A &#x3D; \\sigma(Z) &#x3D; \\frac{1}{1 + e^{-Z}} \\in \\mathbb{R}^{1 \\times m}$$\n\n真实标签为：\n$$Y &#x3D; \\begin{bmatrix} y^{(1)} &amp; y^{(2)} &amp; \\cdots &amp; y^{(m)} \\end{bmatrix} \\in \\mathbb{R}^{1 \\times m}$$\n\n\n\n二、目标：向量化梯度计算　　逻辑回归的损失函数是交叉熵损失，对单个样本 $(x^{(i)}, y^{(i)})$ 的梯度为：\n$$\\begin{aligned}dz^{(i)} &amp;&#x3D; a^{(i)} - y^{(i)} \\dw^{(i)} &amp;&#x3D; x^{(i)} dz^{(i)} \\db^{(i)} &amp;&#x3D; dz^{(i)}\\end{aligned}$$\n　　传统实现需要对 $i &#x3D; 1$ 到 $m$ 循环累加。现在我们要完全向量化，去掉所有显式 for 循环。\n\n三、关键步骤：定义向量化的中间变量1. 定义误差向量 $dZ$　　将所有样本的 $dz^{(i)}$ 拼成一行向量：\n$$dZ &#x3D; A - Y &#x3D; \\begin{bmatrix} a^{(1)} - y^{(1)} &amp; a^{(2)} - y^{(2)} &amp; \\cdots &amp; a^{(m)} - y^{(m)} \\end{bmatrix} \\in \\mathbb{R}^{1 \\times m}$$\n\n✅ 一行代码实现（NumPy）：\ndZ = A - Y\n2. 向量化计算 $db$　　偏置梯度是所有 $dz^{(i)}$ 的平均值：\n$$db &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^m dz^{(i)} &#x3D; \\frac{1}{m} \\cdot \\text{np.sum}(dZ)$$\n\n✅ 一行代码：\ndb = (1 / m) * np.sum(dZ)\n3. 向量化计算 $dw$　　权重梯度为：\n$$dw &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^m x^{(i)} dz^{(i)}$$\n　　注意到 $X \\in \\mathbb{R}^{n \\times m}$，而 $dZ^\\top \\in \\mathbb{R}^{m \\times 1}$，因此：\n$$dw &#x3D; \\frac{1}{m} X \\cdot dZ^\\top \\in \\mathbb{R}^{n \\times 1}$$\n\n✅ 一行代码：\ndw = (1 / m) * np.dot(X, dZ.T)\n\n🔍 为什么成立？\n矩阵乘法展开：\n$$X \\cdot dZ^\\top &#x3D; x^{(1)} dz^{(1)} + x^{(2)} dz^{(2)} + \\cdots + x^{(m)} dz^{(m)}$$\n正好是 $dw$ 的累加形式。\n\n\n四、完整向量化逻辑回归的一次梯度下降迭代# 前向传播Z = np.dot(w.T, X) + b        # shape: (1, m)A = sigmoid(Z)                # shape: (1, m)# 反向传播（梯度计算）dZ = A - Y                    # shape: (1, m)dw = (1 / m) * np.dot(X, dZ.T)  # shape: (n, 1)db = (1 / m) * np.sum(dZ)     # scalar# 参数更新w = w - alpha * dwb = b - alpha * db\n\n\n✅ 无任何 for 循环！  仅需矩阵运算即可完成整个训练集的前向+反向传播。\n\n\n五、注意事项\n外层循环无法避免：虽然单次梯度下降可完全向量化，但若要运行 $T$ 次迭代（如 1000 次），仍需一个外层 for 循环遍历迭代次数。\n广播机制（Broadcasting） ：在 Z = w.T @ X + b​ 中，标量 b​ 被自动广播到 (1, m) 形状，这是 NumPy 的强大特性，将在下一节详细讲解。\n\n\n六、总结\n\n\n步骤\n非向量化（低效）\n向量化（高效）\n\n\n\n前向传播\n循环计算每个 $a^{(i)}$\n一次矩阵运算 $A &#x3D; \\sigma(w^\\top X + b)$\n\n\n梯度 $dZ$\n循环计算 $a^{(i)} - y^{(i)}$\n一行：dZ = A - Y\n\n\n梯度 $dw$\n循环累加 $x^{(i)} dz^{(i)}$\n一行：dw = (1/m) * X @ dZ.T\n\n\n梯度 $db$\n循环累加 $dz^{(i)}$\n一行：db = (1/m) * sum(dZ)\n\n\n\n💡 核心思想：用矩阵运算代替 for 循环，大幅提升计算效率，尤其在 GPU 上效果显著。\n\n","categories":["神经网络与深度学习"]},{"title":"18 Python 中的广播机制（Broadcasting in Python）","url":"/blog/18%20Python%20%E4%B8%AD%E7%9A%84%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6%EF%BC%88Broadcasting%20in%20Python%EF%BC%89/","content":"一、广播机制的作用　　广播（Broadcasting）是 NumPy 中一种强大的机制，它允许对不同形状的数组进行算术运算，而无需显式地编写 for 循环。这不仅能显著提升代码运行速度，还能使代码更加简洁、易读。\n\n✅ 核心优势：\n\n避免显式循环\n提高计算效率（向量化）\n减少代码行数\n\n\n\n二、实际应用示例：计算食物热量百分比1. 问题设定　　给定一个 $3 \\times 4$ 的矩阵 $\\mathbf{A}$，表示 100 克四种食物（苹果、牛肉、鸡蛋、土豆）中来自碳水化合物（Carbs）、蛋白质（Proteins）、脂肪（Fats）的卡路里：\n$$\\mathbf{A} &#x3D;\\begin{bmatrix}56 &amp; 0 &amp; 4 &amp; 68 \\1.2 &amp; 104 &amp; 52 &amp; 8 \\1.8 &amp; 135 &amp; 99 &amp; 0.5\\end{bmatrix}$$\n\n每一列代表一种食物\n每一行代表一种营养成分\n\n　　目标：计算每种食物中，各营养成分所占的热量百分比。\n　　例如，苹果总热量为：\n$$56 + 1.2 + 1.8 &#x3D; 59 \\text{ 千卡}$$\n　　其中碳水占比为：\n$$\\frac{56}{59} \\approx 94.9%$$\n2. 向量化解法（使用广播）　　步骤 1：计算每列总和（即每种食物的总热量）\ncal = A.sum(axis=0)  # shape: (4,)\n\n\n​axis=0 表示沿第 0 轴（行方向）求和 → 对每一列求和\n\n结果 cal 是一个长度为 4 的一维数组：\n$$\\text{cal} &#x3D; [59,\\ 239,\\ 155,\\ 76.5]$$\n\n\n　　步骤 2：利用广播计算百分比\npercentage = 100 * A / cal.reshape(1, 4)\n\n\n​cal.reshape(1, 4) 将其变为 $1 \\times 4$ 的行向量\n广播机制自动将该行向量“复制”3次，形成 $3 \\times 4$ 矩阵，再与 $\\mathbf{A}$ 逐元素除法\n\n　　最终得到百分比矩阵：\n$$\\text{percentage} &#x3D; 100 \\times\\begin{bmatrix}\\frac{56}{59} &amp; \\frac{0}{239} &amp; \\frac{4}{155} &amp; \\frac{68}{76.5} \\\\frac{1.2}{59} &amp; \\frac{104}{239} &amp; \\frac{52}{155} &amp; \\frac{8}{76.5} \\\\frac{1.8}{59} &amp; \\frac{135}{239} &amp; \\frac{99}{155} &amp; \\frac{0.5}{76.5}\\end{bmatrix}$$\n\n💡 注意：虽然 cal​ 本身在 NumPy 中已可直接广播，但显式调用 reshape(1, 4)​ 可增强代码可读性和鲁棒性。reshape 是 O(1) 操作，无性能损失。\n\n\n三、广播机制的一般规则（General Broadcasting Rules）　　NumPy 的广播遵循以下核心原则：\n情况 1：$(m, n)$ 矩阵 与 $(1, n)$ 矩阵 运算\n$(1, n)$ 被“复制” $m$ 次，扩展为 $(m, n)$\n然后进行逐元素运算（+、−、×、÷）\n\n　　示例：\n$$\\begin{bmatrix}1 &amp; 2 &amp; 3 \\4 &amp; 5 &amp; 6\\end{bmatrix}+\\begin{bmatrix}100 &amp; 200 &amp; 300\\end{bmatrix}\\begin{bmatrix}101 &amp; 202 &amp; 303 \\104 &amp; 205 &amp; 306\\end{bmatrix}$$\n情况 2：$(m, n)$ 矩阵 与 $(m, 1)$ 矩阵 运算\n$(m, 1)$ 被“复制” $n$ 次（横向），扩展为 $(m, n)$\n再逐元素运算\n\n　　示例：\n$$\\begin{bmatrix}1 &amp; 2 &amp; 3 \\4 &amp; 5 &amp; 6\\end{bmatrix}+\\begin{bmatrix}100 \\200\\end{bmatrix}\\begin{bmatrix}101 &amp; 102 &amp; 103 \\204 &amp; 205 &amp; 206\\end{bmatrix}$$\n情况 3：标量（Scalar）与任意形状数组运算\n标量被视为 $(1,1)$，自动扩展到目标数组形状\n\n　　示例：\n$$\\begin{bmatrix}1 \\ 2 \\ 3 \\ 4\\end{bmatrix}\n\n100\\begin{bmatrix}101 \\ 102 \\ 103 \\ 104\\end{bmatrix}$$\n\n\n✅ 这正是神经网络中偏置项（bias $b$）加到激活值上的实现方式！\n\n\n四、广播的维度对齐规则（补充说明）　　更一般的广播规则（来自 NumPy 文档）：\n\n从右向左对齐两个数组的形状（shape）\n\n对每个维度：\n\n若两数组在该维度大小相同，或\n其中一个为 1，则可广播\n\n\n广播后的维度取两者最大值\n\n\n　　例如：\n\n​(3, 4)​ 与 (4,)​ → (3, 4)​ 与 (1, 4) → 可广播\n​(3, 1)​ 与 (1, 4)​ → 广播为 (3, 4)\n\n\n五、与其他语言对比（MATLAB&#x2F;Octave）\nMATLAB&#x2F;Octave 中类似功能由 bsxfun 实现\nPython 的广播更简洁、自动，无需显式调用函数\n对深度学习编程而言，Python 广播已成为标准实践\n\n\n六、最佳实践建议\n善用 ​reshape​​ 明确维度 即使不是必须，也建议用 reshape 确保张量形状符合预期，避免隐式错误。\n优先使用向量化操作 避免 for​ 循环，利用广播 + NumPy 内建函数（如 sum​, mean​, max 等）\n调试时打印  ​.shape​ 在复杂运算前后检查张量形状，防止广播意外导致逻辑错误。\n\n\n七、总结\n\n\n概念\n说明\n\n\n\n广播（Broadcasting）\nNumPy 自动扩展小数组以匹配大数组形状，支持高效向量化运算\n\n\n典型用途\n归一化、百分比计算、加偏置、批量处理\n\n\n关键参数\n​axis=0​（列方向求和），axis=1（行方向求和）\n\n\n性能优势\n比 for 循环快数十至数百倍，尤其在 GPU&#x2F;TPU 上更明显\n\n\n","categories":["神经网络与深度学习"]},{"title":"15 更多向量化示例（More Vectorization Examples）","url":"/blog/15%20%E6%9B%B4%E5%A4%9A%E5%90%91%E9%87%8F%E5%8C%96%E7%A4%BA%E4%BE%8B%EF%BC%88More%20Vectorization%20Examples%EF%BC%89/","content":"一、核心思想：避免显式 for 循环\n黄金法则（Rule of Thumb） ：在编写神经网络或回归模型时，尽可能避免使用显式的 for 循环。虽然有时无法完全消除循环，但只要能用 NumPy 等库的内置向量化函数替代，代码速度通常会显著提升。\n\n　　原因：\n\nPython 的 for 循环在解释执行下效率低；\nNumPy 底层由 C&#x2F;C++ 实现，支持 SIMD（单指令多数据）并行计算；\n向量化代码更简洁、可读性更强。\n\n\n二、向量化示例 1：矩阵-向量乘法❌ 非向量化实现（双重 for 循环）　　设 $\\mathbf{A} \\in \\mathbb{R}^{n \\times m}$，$\\mathbf{v} \\in \\mathbb{R}^{m}$，目标是计算：\n$$\\mathbf{u} &#x3D; \\mathbf{A} \\mathbf{v}, \\quad \\text{其中} \\quad u_i &#x3D; \\sum_{j&#x3D;1}^{m} A_{ij} v_j$$\n　　Python 伪代码：\nu = np.zeros((n, 1))for i in range(n):    for j in range(m):        u[i] += A[i][j] * v[j]\n\n✅ 向量化实现（一行代码）u = np.dot(A, v)  # 或 A @ v\n\n\n消除了两层嵌套循环；\n利用 BLAS（基础线性代数子程序）高效计算。\n\n\n三、向量化示例 2：逐元素函数（Element-wise Functions）　　假设已有向量 $\\mathbf{v} &#x3D; [v_1, v_2, \\dots, v_n]^\\top$，想计算：\n$$\\mathbf{u} &#x3D; \\left[ e^{v_1}, e^{v_2}, \\dots, e^{v_n} \\right]^\\top$$\n❌ 非向量化实现u = np.zeros_like(v)for i in range(len(v)):    u[i] = np.exp(v[i])\n\n✅ 向量化实现u = np.exp(v)\n\n其他常用 NumPy 向量化函数：\n\n\n操作\nNumPy 函数\n说明\n\n\n\n对数\n​np.log(v)\n逐元素 $\\log(v_i)$\n\n\n绝对值\n​np.abs(v)\n逐元素 $\n\n\n最大值（与0比较）\n​np.maximum(v, 0)\nReLU 激活函数\n\n\n平方\n​v ** 2\n逐元素 $v_i^2$\n\n\n倒数\n​1 / v\n逐元素 $1&#x2F;v_i$（注意除零）\n\n\n\n💡 提示：当你想写 for 循环时，先查 NumPy 文档——很可能已有对应函数！\n\n\n四、应用：逻辑回归梯度下降的向量化　　回顾逻辑回归的梯度计算（训练集大小为 $m$，特征数为 $n_x$）：\n　　原始非向量化版本包含两个 for 循环：\n\n外层：遍历每个训练样本 $i &#x3D; 1, \\dots, m$\n内层：遍历每个特征 $j &#x3D; 1, \\dots, n_x$，更新 $dw_j$\n\n❌ 原始代码结构（简化版）dw1 = 0; dw2 = 0  # 假设 nx=2for i in range(m):    dz = ...  # 计算 dz(i)    dw1 += x1[i] * dz    dw2 += x2[i] * dzdw1 /= m; dw2 /= m\n\n　　→ 若 $n_x$ 很大，需写 $n_x$ 个变量和循环！\n✅ 第一步向量化：将 dw 变成向量dw = np.zeros((nx, 1))  # 初始化为向量for i in range(m):    dz_i = ...          # 标量    x_i = X[:, i:i+1]   # 第 i 个样本，形状 (nx, 1)    dw += x_i * dz_i    # 向量加法，自动广播dw /= m\n\n　　✅ 效果：\n\n消除了内层对特征的 for 循环；\n保留外层对样本的循环（$m$ 次）；\n代码更通用（适用于任意 $n_x$）。\n\n\n五、展望：完全向量化（下一讲预告）\n即使外层对训练样本的循环，也可以被消除！\n\n　　通过将整个训练集 $\\mathbf{X} \\in \\mathbb{R}^{n_x \\times m}$ 和标签 $\\mathbf{Y} \\in \\mathbb{R}^{1 \\times m}$ 一次性输入，利用矩阵运算，完全不用任何 for 循环即可完成前向传播与梯度计算。\n　　例如：\n\n预测值：$\\mathbf{A} &#x3D; \\sigma(\\mathbf{W}^\\top \\mathbf{X} + b)$\n损失梯度：$d\\mathbf{W} &#x3D; \\frac{1}{m} \\mathbf{X} (\\mathbf{A} - \\mathbf{Y})^\\top$\n\n　　这将在下一节课中详细展开。\n\n✅ 总结要点\n\n\n主题\n关键点\n\n\n\n向量化优势\n更快、更简洁、更接近数学表达\n\n\n避免 for 循环\n尤其是嵌套循环；优先使用 NumPy 内置函数\n\n\n矩阵乘法\n用 np.dot​ 或 @ 替代双重循环\n\n\n逐元素操作\n​np.exp​, np.log​, **​, / 等天然支持向量\n\n\n逻辑回归优化\n将参数 $dw$ 从标量列表变为向量，消除特征维度循环\n\n\n终极目标\n完全向量化：一次处理整个训练集，零 for 循环\n\n\n","categories":["神经网络与深度学习"]},{"title":"19 避免 NumPy 中的“秩1数组”（Rank-1 Array）陷阱","url":"/blog/19%20%E9%81%BF%E5%85%8D%20NumPy%20%E4%B8%AD%E7%9A%84%E2%80%9C%E7%A7%A91%E6%95%B0%E7%BB%84%E2%80%9D%EF%BC%88Rank-1%20Array%EF%BC%89%E9%99%B7%E9%98%B1/","content":"1. 问题背景：NumPy 的灵活性是一把双刃剑\n优点：Python + NumPy 提供了强大的广播机制（broadcasting），使得代码简洁、表达力强。\n缺点：过度灵活可能导致隐蔽的 bug，尤其在向量维度处理上容易出错。\n\n\n例如：将列向量与行向量相加，本应报错，但 NumPy 会自动广播并返回一个矩阵，而非报错。\n\n\n2. 关键问题：什么是“秩1数组”（Rank-1 Array）？　　当你执行：\na = np.random.randn(5)\n\n\n​a.shape​ 返回的是 (5,)​ —— 这是一个 秩为1的数组（rank-1 array）。\n它既不是行向量也不是列向量，行为不一致，容易引发混淆。\n\n表现异常的例子：\n​a.T​（转置）看起来和 a 完全一样。\n​np.dot(a, a.T)​ 返回一个标量（scalar），而不是你可能预期的 $5 \\times 5$ 外积矩阵。\n\n\n💡 原因：NumPy 将 (5,) 视为一维数组，点积默认计算内积（inner product）。\n\n\n3. 正确做法：显式使用二维向量（列向量或行向量）✅ 推荐写法：\n列向量（column vector）：\na = np.random.randn(5, 1)  # shape: (5, 1)\n行向量（row vector）：\na = np.random.randn(1, 5)  # shape: (1, 5)\n\n对比效果：\n\n\n操作\n秩1数组 (5,)\n列向量 (5,1)\n\n\n\n​a.T\n仍是 (5,)，无变化\n变为 (1,5) 行向量\n\n\n​a @ a.T​ 或 np.dot(a, a.T)\n标量（内积）\n$5 \\times 5$ 矩阵（外积）\n\n\n\n外积公式（outer product）：\n若 $\\mathbf{a} \\in \\mathbb{R}^{n \\times 1}$，则\n$$\\mathbf{a} \\mathbf{a}^\\top \\in \\mathbb{R}^{n \\times n}$$\n\n\n4. 实用技巧：防御性编程（Defensive Programming）(1) 使用 assert 显式检查形状assert a.shape == (5, 1), &quot;a must be a column vector&quot;\n\n\n不仅能提前捕获错误，还能作为代码文档，提高可读性。\n\n(2) 遇到秩1数组？立即 reshape！a = a.reshape(5, 1)   # 强制转为列向量# 或a = a.reshape(1, 5)   # 强制转为行向量\n\n\n即使输入是 (5,)​，reshape 后行为就变得可预测。\n\n\n5. 总结：三条黄金准则\n永远不要使用秩1数组（shape 为 (n,) 的数组）。\n\n始终明确向量方向：\n\n列向量：(n, 1)\n行向量：(1, n)\n\n\n多用 ​assert​​ 和 ​reshape​：\n\n​assert 用于验证维度；\n​reshape 用于标准化输入。\n\n\n\n\n6. 为什么这在神经网络中特别重要？　　在深度学习中，我们频繁进行如下操作：\n\n权重矩阵乘法：$\\mathbf{W} \\mathbf{x}$\n损失函数计算：$\\ell(\\mathbf{y}, \\hat{\\mathbf{y}})$\n梯度更新：$\\mathbf{W} :&#x3D; \\mathbf{W} - \\alpha \\nabla_{\\mathbf{W}} \\mathcal{L}$\n\n　　若向量维度不明确，广播机制可能导致：\n\n意外的维度扩展\n梯度计算错误\n模型无法收敛\n\n\n✅ 显式维度 &#x3D; 更少 bug + 更高可复现性\n\n\n附：常见操作对照表\n\n\n操作\n秩1数组 (5,)\n列向量 (5,1)\n行向量 (1,5)\n\n\n\n转置 .T\n​(5,)（不变）\n​(1,5)\n​(5,1)\n\n\n​a @ a.T\n标量（内积）\n$5 \\times 5$ 矩阵\n$1 \\times 1$ 标量\n\n\n​a.T @ a\n标量\n$1 \\times 1$ 标量\n$5 \\times 5$ 矩阵\n\n\n广播加法 a + b\n易出错\n行为明确\n行为明确\n\n\n","categories":["神经网络与深度学习"]},{"title":"20 逻辑回归代价函数详解","url":"/blog/20%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/","content":"1. 逻辑回归的基本形式　　在逻辑回归中，我们对输入特征向量 $\\mathbf{x} \\in \\mathbb{R}^n$ 做如下预测：\n$$\\hat{y} &#x3D; \\sigma(\\mathbf{w}^\\top \\mathbf{x} + b)$$\n　　其中：\n\n$\\mathbf{w} \\in \\mathbb{R}^n$ 是权重向量；\n$b \\in \\mathbb{R}$ 是偏置项；\n$\\sigma(z)$ 是 Sigmoid 函数，定义为：\n\n$$\\sigma(z) &#x3D; \\frac{1}{1 + e^{-z}}$$\n　　我们把 $\\hat{y}$ 解释为：\n\n在给定输入 $\\mathbf{x}$ 的条件下，标签 $y &#x3D; 1$ 的概率，即：\n\n$$\\hat{y} &#x3D; P(y &#x3D; 1 \\mid \\mathbf{x}; \\mathbf{w}, b)$$\n　　因此：\n\n若真实标签 $y &#x3D; 1$，则 $P(y \\mid \\mathbf{x}) &#x3D; \\hat{y}$\n若真实标签 $y &#x3D; 0$，则 $P(y \\mid \\mathbf{x}) &#x3D; 1 - \\hat{y}$\n\n\n2. 将两种情况统一成一个概率表达式　　由于 $y \\in {0, 1}$，我们可以将上述两个情形合并为一个统一的概率公式：\n$$P(y \\mid \\mathbf{x}; \\mathbf{w}, b) &#x3D; \\hat{y}^y (1 - \\hat{y})^{(1 - y)}$$\n　　✅ 验证：\n\n当 $y &#x3D; 1$：上式变为 $\\hat{y}^1 (1 - \\hat{y})^0 &#x3D; \\hat{y}$\n当 $y &#x3D; 0$：上式变为 $\\hat{y}^0 (1 - \\hat{y})^1 &#x3D; 1 - \\hat{y}$\n\n　　完全符合我们的期望！\n\n3. 对数似然函数（Log-Likelihood）　　为了便于优化，我们对概率取对数（因为对数函数是单调递增的，最大化概率等价于最大化对数概率）：\n$$\\log P(y \\mid \\mathbf{x}) &#x3D; \\log\\left( \\hat{y}^y (1 - \\hat{y})^{(1 - y)} \\right) &#x3D; y \\log \\hat{y} + (1 - y) \\log (1 - \\hat{y})$$\n　　注意：这个值是我们希望最大化的（因为它是“对数似然”）。\n　　但机器学习中通常采用最小化损失函数的形式，所以我们定义单个样本的损失函数为它的负值：\n$$\\mathcal{L}(\\hat{y}, y) &#x3D; - \\left[ y \\log \\hat{y} + (1 - y) \\log (1 - \\hat{y}) \\right]$$\n　　这就是著名的 交叉熵损失（Cross-Entropy Loss） 。\n\n4. 整个训练集的代价函数（Cost Function）　　假设训练集包含 $m$ 个独立同分布（i.i.d.）的样本 ${(\\mathbf{x}^{(i)}, y^{(i)})}_{i&#x3D;1}^m$，则整个数据集的联合概率为：\n$$P(\\text{所有标签} \\mid \\text{所有 } \\mathbf{x}) &#x3D; \\prod_{i&#x3D;1}^m P(y^{(i)} \\mid \\mathbf{x}^{(i)})$$\n　　取对数得：\n$$\\log P &#x3D; \\sum_{i&#x3D;1}^m \\left[ y^{(i)} \\log \\hat{y}^{(i)} + (1 - y^{(i)}) \\log (1 - \\hat{y}^{(i)}) \\right]$$\n　　根据最大似然估计（Maximum Likelihood Estimation, MLE） ，我们要最大化这个对数似然。等价地，我们最小化其负值，即总代价函数：\n$$J(\\mathbf{w}, b) &#x3D; -\\frac{1}{m} \\sum_{i&#x3D;1}^m \\left[ y^{(i)} \\log \\hat{y}^{(i)} + (1 - y^{(i)}) \\log (1 - \\hat{y}^{(i)}) \\right]$$\n　　其中：\n\n$\\hat{y}^{(i)} &#x3D; \\sigma(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b)$\n系数 $\\frac{1}{m}$ 是为了对损失进行平均，使代价函数尺度更稳定（不影响优化方向）\n\n\n5. 总结：为什么用这个代价函数？\n这个代价函数来源于概率建模：我们假设输出是伯努利分布的概率。\n通过最大似然估计自然导出交叉熵形式。\n它是凸函数（在逻辑回归中），保证梯度下降能找到全局最优解。\n相比平方误差（MSE），它在分类任务中梯度更合理，避免学习缓慢的问题。\n\n\n✅ 最终公式汇总\n预测值：\n$$\\hat{y}^{(i)} &#x3D; \\sigma(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b) &#x3D; \\frac{1}{1 + e^{-(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b)}}$$\n\n单样本损失：\n$$\\mathcal{L}^{(i)} &#x3D; - \\left[ y^{(i)} \\log \\hat{y}^{(i)} + (1 - y^{(i)}) \\log (1 - \\hat{y}^{(i)}) \\right]$$\n\n整体代价函数：\n$$J(\\mathbf{w}, b) &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^m \\mathcal{L}^{(i)} &#x3D; -\\frac{1}{m} \\sum_{i&#x3D;1}^m \\left[ y^{(i)} \\log \\hat{y}^{(i)} + (1 - y^{(i)}) \\log (1 - \\hat{y}^{(i)}) \\right]$$\n\n\n","categories":["神经网络与深度学习"]},{"title":"21 神经网络概述","url":"/blog/21%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A6%82%E8%BF%B0/","content":"1. 回顾：逻辑回归（Logistic Regression）　　在上一周的学习中，我们学习了逻辑回归模型，其计算流程如下：\n\n输入特征向量：$\\mathbf{x} \\in \\mathbb{R}^{n_x}$\n\n参数：权重 $\\mathbf{w} \\in \\mathbb{R}^{n_x}$，偏置 $b \\in \\mathbb{R}$\n\n线性组合：\n$$z &#x3D; \\mathbf{w}^\\top \\mathbf{x} + b$$\n\n激活函数（Sigmoid）：\n$$a &#x3D; \\hat{y} &#x3D; \\sigma(z) &#x3D; \\frac{1}{1 + e^{-z}}$$\n\n损失函数（单个样本）：\n$$\\mathcal{L}(a, y) &#x3D; -\\left[ y \\log a + (1 - y) \\log(1 - a) \\right]$$\n\n\n　　这个过程可以用一个计算图（computation graph）  表示：\n$$\\mathbf{x}, \\mathbf{w}, b \\rightarrow z \\rightarrow a &#x3D; \\hat{y} \\rightarrow \\mathcal{L}$$\n\n2. 神经网络的基本思想　　神经网络的核心思想是：将多个“逻辑回归单元”堆叠起来，形成多层结构。\n\n“You can form a neural network by stacking together a lot of little sigmoid units.”\n\n示例结构（含一个隐藏层）：\n输入层：3 个特征 $x_1, x_2, x_3$ → 向量 $\\mathbf{x} \\in \\mathbb{R}^3$\n隐藏层：3 个神经元（每个都执行类似逻辑回归的计算）\n输出层：1 个神经元 → 输出 $\\hat{y}$\n\n\n3. 神经网络的前向传播（Forward Propagation）　　我们将使用方括号上标表示网络的层数（注意：不是训练样本索引！）：\n\n$[\\ell]$ 表示第 $\\ell$ 层（layer）\n$(i)$ 表示第 $i$ 个训练样本（如 $x^{(i)}$）\n\n第 1 层（隐藏层）：　　设隐藏层有 $n^{[1]} &#x3D; 3$ 个神经元。\n\n权重矩阵：$\\mathbf{W}^{[1]} \\in \\mathbb{R}^{3 \\times 3}$（因为输入是 3 维）\n\n偏置向量：$\\mathbf{b}^{[1]} \\in \\mathbb{R}^{3}$\n\n线性部分：\n$$\\mathbf{z}^{[1]} &#x3D; \\mathbf{W}^{[1]} \\mathbf{x} + \\mathbf{b}^{[1]}$$\n\n激活部分（逐元素 Sigmoid）：\n$$\\mathbf{a}^{[1]} &#x3D; \\sigma(\\mathbf{z}^{[1]}) &#x3D;\\begin{bmatrix}\\sigma(z_1^{[1]}) \\\\sigma(z_2^{[1]}) \\\\sigma(z_3^{[1]})\\end{bmatrix}$$\n\n\n第 2 层（输出层）：\n权重：$\\mathbf{W}^{[2]} \\in \\mathbb{R}^{1 \\times 3}$\n\n偏置：$b^{[2]} \\in \\mathbb{R}$\n\n线性部分：\n$$z^{[2]} &#x3D; \\mathbf{W}^{[2]} \\mathbf{a}^{[1]} + b^{[2]}$$\n\n激活（输出）：\n$$a^{[2]} &#x3D; \\hat{y} &#x3D; \\sigma(z^{[2]})$$\n\n\n\n注意：$a^{[2]}$ 就是最终预测值 $\\hat{y}$。\n\n总结前向传播流程：$$\\mathbf{x}\\overset{\\mathbf{W}^{[1]}, \\mathbf{b}^{[1]}}{\\longrightarrow}\\mathbf{z}^{[1]}\\overset{\\sigma}{\\longrightarrow}\\mathbf{a}^{[1]}\\overset{\\mathbf{W}^{[2]}, b^{[2]}}{\\longrightarrow}z^{[2]}\\overset{\\sigma}{\\longrightarrow}a^{[2]} &#x3D; \\hat{y}\\rightarrow \\mathcal{L}(a^{[2]}, y)$$\n\n4. 损失函数　　对于单个样本 $(\\mathbf{x}, y)$，损失函数仍为：\n$$\\mathcal{L}(a^{[2]}, y) &#x3D; -\\left[ y \\log a^{[2]} + (1 - y) \\log(1 - a^{[2]}) \\right]$$\n\n5. 反向传播（Backpropagation）概览　　为了训练神经网络，我们需要通过反向传播计算梯度，更新参数。\n　　逻辑回归中的反向传播步骤为：\n$$\\mathcal{L} \\rightarrow da \\rightarrow dz \\rightarrow d\\mathbf{w}, db$$\n　　在神经网络中，这一过程被重复多次，从输出层向输入层逐层回传：\n反向传播路径（以两层网络为例）：$$\\mathcal{L}\\rightarrow da^{[2]}\\rightarrow dz^{[2]}\\rightarrow d\\mathbf{W}^{[2]}, db^{[2]}\\rightarrow da^{[1]}\\rightarrow dz^{[1]}\\rightarrow d\\mathbf{W}^{[1]}, d\\mathbf{b}^{[1]}$$\n\n这些梯度将用于梯度下降法更新参数。\n\n\n6. 关键符号说明\n\n\n符号\n含义\n\n\n\n$x^{(i)}$\n第 $i$ 个训练样本的输入特征\n\n\n$y^{(i)}$\n第 $i$ 个训练样本的真实标签\n\n\n$[\\ell]$\n第 $\\ell$ 层（layer index）\n\n\n$\\mathbf{W}^{[\\ell]}$\n第 $\\ell$ 层的权重矩阵\n\n\n$\\mathbf{b}^{[\\ell]}$\n第 $\\ell$ 层的偏置向量\n\n\n$\\mathbf{z}^{[\\ell]}$\n第 $\\ell$ 层的线性输出\n\n\n$\\mathbf{a}^{[\\ell]}$\n第 $\\ell$ 层的激活输出（$\\mathbf{a}^{[0]} &#x3D; \\mathbf{x}$）\n\n\n\n7. 核心思想总结\n神经网络 &#x3D; 多层逻辑回归单元的堆叠\n每一层都包含：线性变换 + 非线性激活（如 Sigmoid）\n前向传播：从输入到输出逐层计算\n反向传播：从损失函数反向计算梯度，用于参数更新\n方括号上标 $[\\cdot]$ 表示层，圆括号上标 $(\\cdot)$ 表示样本\n\n","categories":["神经网络与深度学习"]},{"title":"22 神经网络结构概述","url":"/blog/22%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%A6%82%E8%BF%B0/","content":"一、神经网络结构概述　　本节讲解的是一个具有单个隐藏层的前馈神经网络（Feedforward Neural Network）。其结构如下：\n\n输入层（Input Layer） ：包含 3 个输入特征 $x_1, x_2, x_3$。\n隐藏层（Hidden Layer） ：包含 4 个神经元（节点）。\n输出层（Output Layer） ：包含 1 个神经元，输出预测值 $\\hat{y}$。\n\n\n⚠️ 注意：虽然从视觉上看有三层（输入、隐藏、输出），但在神经网络术语中，输入层不计入层数。因此该网络被称为  “两层神经网络” （Layer 1 &#x3D; 隐藏层，Layer 2 &#x3D; 输出层）。\n\n\n二、符号约定（Notation）　　为了清晰描述各层的计算过程，引入以下符号：\n1. 输入表示\n原始输入向量：\n$$\\mathbf{x} &#x3D;\\begin{bmatrix}x_1 \\ x_2 \\ x_3\\end{bmatrix}\\in \\mathbb{R}^3$$\n\n输入层的激活值（即输入本身）记为：\n$$\\mathbf{a}^{[0]} &#x3D; \\mathbf{x}$$\n其中上标 $[0]$ 表示第 0 层（输入层），$\\mathbf{a}$ 表示 activation（激活值） 。\n\n\n2. 隐藏层激活值\n隐藏层有 4 个神经元，其激活值构成一个 4 维向量：\n$$\\mathbf{a}^{[1]} &#x3D;\\begin{bmatrix}a^{[1]}_1 \\ a^{[1]}_2 \\ a^{[1]}_3 \\ a^{[1]}_4\\end{bmatrix}\\in \\mathbb{R}^4$$\n\n\n3. 输出层激活值\n输出层只有一个神经元，其激活值即为模型预测：\n$$\\hat{y} &#x3D; a^{[2]} \\in \\mathbb{R}$$\n\n\n\n三、“隐藏层”名称的由来\n在监督学习中，训练数据提供的是输入 $\\mathbf{x}$ 和真实标签 $y$。\n隐藏层的激活值 $\\mathbf{a}^{[1]}$ 在训练集中不可见（即没有标注），因此称为 “hidden”。\n我们只能观测到输入和输出，中间的表示由模型自动学习。\n\n\n四、参数（Weights and Biases）　　每一层（除输入层外）都有对应的可学习参数：\n1. 隐藏层参数（Layer 1）\n权重矩阵 $\\mathbf{W}^{[1]} \\in \\mathbb{R}^{4 \\times 3}$：每一行对应一个隐藏神经元，每一列对应一个输入特征。\n偏置向量 $\\mathbf{b}^{[1]} \\in \\mathbb{R}^{4 \\times 1}$\n\n\n为什么是 $4 \\times 3$？因为有 4 个隐藏单元，每个接收 3 个输入。\n\n2. 输出层参数（Layer 2）\n权重向量 $\\mathbf{W}^{[2]} \\in \\mathbb{R}^{1 \\times 4}$\n偏置标量 $b^{[2]} \\in \\mathbb{R}$（常写作 $1 \\times 1$ 向量）\n\n\n为什么是 $1 \\times 4$？因为输出层有 1 个神经元，接收来自 4 个隐藏单元的输入。\n\n\n五、前向传播计算流程（Forward Propagation）　　整个网络的计算分为两步：\n第一步：隐藏层计算　　对隐藏层的每个神经元，先进行线性组合，再通过激活函数（如 sigmoid、ReLU 等）：\n$$\\mathbf{z}^{[1]} &#x3D; \\mathbf{W}^{[1]} \\mathbf{a}^{[0]} + \\mathbf{b}^{[1]} \\quad \\in \\mathbb{R}^4$$\n$$\\mathbf{a}^{[1]} &#x3D; g^{[1]}(\\mathbf{z}^{[1]})$$\n　　其中 $g^{[1]}$ 是隐藏层的激活函数（例如 ReLU）。\n第二步：输出层计算$$z^{[2]} &#x3D; \\mathbf{W}^{[2]} \\mathbf{a}^{[1]} + b^{[2]} \\quad \\in \\mathbb{R}$$\n$$\\hat{y} &#x3D; a^{[2]} &#x3D; g^{[2]}(z^{[2]})$$\n　　若用于二分类，通常 $g^{[2]}$ 为 sigmoid 函数：\n$$\\hat{y} &#x3D; \\sigma(z^{[2]}) &#x3D; \\frac{1}{1 + e^{-z^{[2]}}}$$\n\n六、关键总结\n\n\n概念\n说明\n\n\n\n层数命名\n输入层不计数，隐藏层为 Layer 1，输出层为 Layer 2 → 称为“两层神经网络”\n\n\n激活值\n$\\mathbf{a}^{[l]}$ 表示第 $l$ 层的输出（传递给下一层的值）\n\n\n参数维度\n$\\mathbf{W}^{[l]}$ 的形状为 $(n^{[l]}, n^{[l-1]})$，其中 $n^{[l]}$ 是第 $l$ 层神经元数量\n\n\n隐藏层含义\n其真实值在训练数据中不可见，需模型自行学习\n\n\n\n七、后续内容预告　　下一讲将深入讲解前向传播的具体计算过程，包括：\n\n如何逐层计算 $z$ 和 $a$\n激活函数的选择与作用\n参数维度的通用规则\n\n","categories":["神经网络与深度学习"]},{"title":"23 计算神经网络的输出","url":"/blog/23%20%E8%AE%A1%E7%AE%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%BE%93%E5%87%BA/","content":"1. 神经网络结构回顾\n考虑一个 具有一个隐藏层 的神经网络：\n\n输入层：3 个特征 → $\\mathbf{x} &#x3D; [x_1, x_2, x_3]^\\top \\in \\mathbb{R}^3$\n隐藏层：4 个神经元（节点）\n输出层：1 个神经元（用于二分类，输出 $\\hat{y}$）\n\n\n\n\n💡 注：这种网络被称为  “两层神经网络” （因为只计带参数的层：隐藏层 + 输出层）。\n\n\n2. 单个神经元的计算（类比逻辑回归）　　每个神经元执行两步计算：\n\n线性组合：\n $$ z &#x3D; \\mathbf{w}^\\top \\mathbf{x} + b $$\n\n激活函数（Sigmoid） ：\n $$ a &#x3D; \\sigma(z) &#x3D; \\frac{1}{1 + e^{-z}} $$\n\n\n　　这与逻辑回归完全一致。神经网络就是将这一过程 在多个神经元上重复。\n\n3. 隐藏层的逐节点计算（非向量化形式）　　对隐藏层第 $i$ 个神经元（$i &#x3D; 1,2,3,4$）：\n$$z^{[1]}_i &#x3D; (\\mathbf{w}^{[1]}_i)^\\top \\mathbf{x} + b^{[1]}_i$$\n$$a^{[1]}_i &#x3D; \\sigma(z^{[1]}_i)$$\n　　其中：\n\n上标 $[1]$ 表示 第 1 层（隐藏层）\n下标 $i$ 表示该层的第 $i$ 个神经元\n\n\n4. 向量化：高效计算整个隐藏层　　为了避免 for 循环，我们将所有神经元的计算 向量化。\n定义参数矩阵和向量：\n权重矩阵 $\\mathbf{W}^{[1]} \\in \\mathbb{R}^{4 \\times 3}$：\n$$\\mathbf{W}^{[1]} &#x3D;\\begin{bmatrix}(\\mathbf{w}^{[1]}_1)^\\top \\(\\mathbf{w}^{[1]}_2)^\\top \\(\\mathbf{w}^{[1]}_3)^\\top \\(\\mathbf{w}^{[1]}_4)^\\top\\end{bmatrix}$$\n\n偏置向量 $\\mathbf{b}^{[1]} \\in \\mathbb{R}^{4 \\times 1}$：\n$$\\mathbf{b}^{[1]} &#x3D;\\begin{bmatrix}b^{[1]}_1 \\b^{[1]}_2 \\b^{[1]}_3 \\b^{[1]}_4\\end{bmatrix}$$\n\n\n向量化前向传播（隐藏层）：$$\\mathbf{z}^{[1]} &#x3D; \\mathbf{W}^{[1]} \\mathbf{x} + \\mathbf{b}^{[1]} \\quad \\in \\mathbb{R}^{4 \\times 1}$$\n$$\\mathbf{a}^{[1]} &#x3D; \\sigma(\\mathbf{z}^{[1]}) \\quad \\text{（Sigmoid 逐元素作用）}$$\n\n✅ 尺寸验证：\n\n$\\mathbf{W}^{[1]}$: $4 \\times 3$\n$\\mathbf{x}$: $3 \\times 1$\n$\\mathbf{b}^{[1]}$: $4 \\times 1$\n$\\mathbf{z}^{[1]}, \\mathbf{a}^{[1]}$: $4 \\times 1$\n\n\n\n5. 输出层的计算　　输出层只有一个神经元，其参数为：\n\n$\\mathbf{w}^{[2]} \\in \\mathbb{R}^{1 \\times 4}$\n$b^{[2]} \\in \\mathbb{R}$\n\n　　计算：\n$$z^{[2]} &#x3D; \\mathbf{w}^{[2]} \\mathbf{a}^{[1]} + b^{[2]} \\quad \\in \\mathbb{R}$$\n$$a^{[2]} &#x3D; \\sigma(z^{[2]}) &#x3D; \\hat{y}$$\n\n🔁 注意：这里 $\\mathbf{w}^{[2]}$ 是行向量，因此无需转置。\n\n\n💡 类比：输出层等价于以 $\\mathbf{a}^{[1]}$ 为输入的 逻辑回归模型。\n\n\n6. 整体前向传播流程（单样本）　　给定输入 $\\mathbf{x} \\in \\mathbb{R}^3$，神经网络输出 $\\hat{y}$ 的完整计算步骤为：\n$$\\begin{aligned}\\mathbf{z}^{[1]} &amp;&#x3D; \\mathbf{W}^{[1]} \\mathbf{x} + \\mathbf{b}^{[1]} \\\\mathbf{a}^{[1]} &amp;&#x3D; \\sigma(\\mathbf{z}^{[1]}) \\z^{[2]} &amp;&#x3D; \\mathbf{w}^{[2]} \\mathbf{a}^{[1]} + b^{[2]} \\a^{[2]} &amp;&#x3D; \\sigma(z^{[2]}) &#x3D; \\hat{y}\\end{aligned}$$\n\n✅ 这就是 4 行代码 实现整个神经网络的前向传播！\n\n\n7. 符号约定补充\n输入可记作：$\\mathbf{a}^{[0]} &#x3D; \\mathbf{x}$\n最终输出：$\\hat{y} &#x3D; a^{[2]}$\n激活函数 $\\sigma(\\cdot)$ 在向量上是 逐元素应用\n\n\n8. 下一步：批量向量化（处理多个样本）　　虽然本视频只讨论 单个训练样本，但实际训练中我们会将 $m$ 个样本堆叠成矩阵：\n\n$\\mathbf{X} &#x3D; [\\mathbf{x}^{(1)}, \\mathbf{x}^{(2)}, \\dots, \\mathbf{x}^{(m)}] \\in \\mathbb{R}^{3 \\times m}$\n相应地，$\\mathbf{Z}^{[1]}, \\mathbf{A}^{[1]}$ 等也变成 $4 \\times m$ 矩阵\n\n　　这将在下一节讲解，核心思想是 用矩阵运算一次性计算所有样本，极大提升效率。\n\n✅ 总结要点\n\n\n概念\n说明\n\n\n\n神经元计算\n$z &#x3D; \\mathbf{w}^\\top \\mathbf{x} + b$, $a &#x3D; \\sigma(z)$\n\n\n向量化动机\n避免 for 循环，利用矩阵运算加速\n\n\n隐藏层输出\n$\\mathbf{a}^{[1]} &#x3D; \\sigma(\\mathbf{W}^{[1]} \\mathbf{x} + \\mathbf{b}^{[1]})$\n\n\n输出层\n本质是逻辑回归，输入为隐藏层激活值\n\n\n符号规范\n上标 $[l]$ 表示层，下标 $i$ 表示神经元\n\n\n","categories":["神经网络与深度学习"]},{"title":"24 多样本向量化（Vectorizing Across Multiple Examples）","url":"/blog/24%20%E5%A4%9A%E6%A0%B7%E6%9C%AC%E5%90%91%E9%87%8F%E5%8C%96%EF%BC%88Vectorizing%20Across%20Multiple%20Examples%EF%BC%89/","content":"1. 背景回顾：单个样本的前向传播　　在上一节课中，我们学习了如何对单个训练样本 $x^{(i)}$ 进行前向传播，计算一个含一个隐藏层的神经网络的输出 $\\hat{y}^{(i)} &#x3D; a^{2}$。其计算步骤如下：\n$$\\begin{aligned}z^{1} &amp;&#x3D; W^{[1]} x^{(i)} + b^{[1]} \\a^{1} &amp;&#x3D; \\sigma\\left(z^{1}\\right) \\z^{2} &amp;&#x3D; W^{[2]} a^{1} + b^{[2]} \\a^{2} &amp;&#x3D; \\sigma\\left(z^{2}\\right) &#x3D; \\hat{y}^{(i)}\\end{aligned}$$\n　　其中：\n\n$x^{(i)} \\in \\mathbb{R}^{n_x}$ 是第 $i$ 个训练样本；\n$W^{[l]}$ 和 $b^{[l]}$ 是第 $l$ 层的权重和偏置；\n$\\sigma(\\cdot)$ 是激活函数（如 sigmoid）；\n上标 $[l]$ 表示第 $l$ 层，上标 $(i)$ 表示第 $i$ 个训练样本。\n\n\n2. 问题：逐个处理效率低　　若共有 $m$ 个训练样本，则朴素实现需循环 $m$ 次：\nfor i in range(1, m+1):    z[1](i) = W[1] @ x(i) + b[1]    a[1](i) = sigma(z[1](i))    ...\n\n　　这种写法计算效率低，无法利用现代硬件（如 GPU）的并行能力。\n\n3. 解决方案：向量化（Vectorization）　　我们将所有训练样本按列堆叠成矩阵，从而一次性完成所有样本的前向传播。\n3.1 数据矩阵定义\n输入矩阵：\n$$X &#x3D; \\begin{bmatrix}| &amp; | &amp; &amp; | \\x^{(1)} &amp; x^{(2)} &amp; \\cdots &amp; x^{(m)} \\| &amp; | &amp; &amp; |\\end{bmatrix} \\in \\mathbb{R}^{n_x \\times m}$$\n\n类似地，定义中间变量矩阵：\n$$Z^{[1]} &#x3D; \\begin{bmatrix}| &amp; | &amp; &amp; | \\z^{1} &amp; z^{1} &amp; \\cdots &amp; z^{1} \\| &amp; | &amp; &amp; |\\end{bmatrix} \\in \\mathbb{R}^{n^{[1]} \\times m}$$\n$$A^{[1]} &#x3D; \\begin{bmatrix}| &amp; | &amp; &amp; | \\a^{1} &amp; a^{1} &amp; \\cdots &amp; a^{1} \\| &amp; | &amp; &amp; |\\end{bmatrix} \\in \\mathbb{R}^{n^{[1]} \\times m}$$\n\n\n\n✅ 关键约定：\n\n水平方向（列） ：不同训练样本（从左到右是样本 1 到 $m$）；\n垂直方向（行） ：不同神经元（从上到下是第 1 个到第 $n^{[l]}$ 个隐藏单元）。\n\n\n\n4. 向量化后的前向传播公式　　将单样本公式中的小写字母（向量）替换为大写字母（矩阵），即可得到完全向量化的批量计算：\n$$\\begin{aligned}Z^{[1]} &amp;&#x3D; W^{[1]} X + b^{[1]} \\A^{[1]} &amp;&#x3D; \\sigma\\left(Z^{[1]}\\right) \\Z^{[2]} &amp;&#x3D; W^{[2]} A^{[1]} + b^{[2]} \\A^{[2]} &amp;&#x3D; \\sigma\\left(Z^{[2]}\\right)\\end{aligned}$$\n\n🔍 注意：这里的加法 $W^{[1]}X + b^{[1]}$ 中，$b^{[1]}$ 是一个列向量（$\\in \\mathbb{R}^{n^{[1]} \\times 1}$），但在 NumPy 等框架中会自动进行广播（broadcasting） ，将其加到每一列上，等价于对每个样本加上相同的偏置。\n\n\n5. 广播机制说明（Broadcasting）　　例如，设：\n\n$W^{[1]} \\in \\mathbb{R}^{n^{[1]} \\times n_x}$\n$X \\in \\mathbb{R}^{n_x \\times m}$\n$b^{[1]} \\in \\mathbb{R}^{n^{[1]} \\times 1}$\n\n　　则：\n\n$W^{[1]} X \\in \\mathbb{R}^{n^{[1]} \\times m}$\n$b^{[1]}$ 会被广播为 $\\mathbb{R}^{n^{[1]} \\times m}$，每列都是 $b^{[1]}$\n\n　　因此：\n$$Z^{[1]}[:, i] &#x3D; W^{[1]} x^{(i)} + b^{[1]} \\quad \\text{对所有 } i&#x3D;1,\\dots,m$$\n　　这正是我们想要的！\n\n6. 总结：向量化的优势\n\n\n方法\n是否使用循环\n计算效率\n代码简洁性\n是否适合 GPU\n\n\n\n朴素实现\n是（for 循环）\n低\n差\n❌\n\n\n向量化\n否\n高（并行）\n好\n✅\n\n\n\n💡 重要提示：深度学习框架（如 TensorFlow、PyTorch）内部高度依赖此类向量化操作。掌握此技巧是写出高效、正确模型的基础。\n\n\n7. 补充：符号规范回顾\n\n\n符号\n含义\n\n\n\n$x^{(i)}$\n第 $i$ 个训练样本（列向量）\n\n\n$X$\n所有训练样本组成的矩阵（$n_x \\times m$）\n\n\n$a^{l}$\n第 $i$ 个样本在第 $l$ 层的激活值\n\n\n$A^{[l]}$\n所有样本在第 $l$ 层的激活矩阵（$n^{[l]} \\times m$）\n\n\n$W^{[l]}$\n第 $l$ 层的权重矩阵（$n^{[l]} \\times n^{[l-1]}$）\n\n\n$b^{[l]}$\n第 $l$ 层的偏置向量（$n^{[l]} \\times 1$）\n\n\n\n✅ 结语　　通过将训练样本按列堆叠，并将单样本前向传播公式直接推广到矩阵形式，我们实现了无循环、高效率的批量前向传播。这一思想不仅适用于两层神经网络，也适用于更深的网络和更复杂的架构，是深度学习工程实践的核心技能之一。\n","categories":["神经网络与深度学习"]},{"title":"25 神经网络中的向量化实现（Vectorized Implementation）","url":"/blog/25%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%90%91%E9%87%8F%E5%8C%96%E5%AE%9E%E7%8E%B0%EF%BC%88Vectorized%20Implementation%EF%BC%89/","content":"一、背景与动机　　在训练神经网络时，如果我们对每个训练样本单独进行前向传播（forward propagation），会使用如下形式的循环：\nfor i in range(m):    z1[i] = W1 @ x[i] + b1    a1[i] = g(z1[i])    ...\n\n　　但这种逐样本处理的方式效率低下。向量化（vectorization）  的目标是：一次性对所有 $m$ 个训练样本进行前向传播计算，从而大幅提升计算效率（尤其在 GPU 上）。\n\n二、数据组织方式\n单个输入样本：$\\mathbf{x}^{(i)} \\in \\mathbb{R}^{n_x}$（列向量）\n\n所有训练样本堆叠成矩阵：\n$$\\mathbf{X} &#x3D;\\begin{bmatrix}\\vert &amp; \\vert &amp; &amp; \\vert \\\\mathbf{x}^{(1)} &amp; \\mathbf{x}^{(2)} &amp; \\cdots &amp; \\mathbf{x}^{(m)} \\\\vert &amp; \\vert &amp; &amp; \\vert\\end{bmatrix}\\in \\mathbb{R}^{n_x \\times m}$$\n\n注意：每个样本是矩阵的一列（这是吴恩达课程的标准约定）。\n\n\n\n\n三、单隐藏层神经网络的前向传播（非向量化 vs 向量化）1. 非向量化（逐样本）形式：　　对第 $i$ 个样本：\n$$\\begin{aligned}\\mathbf{z}^{1} &amp;&#x3D; \\mathbf{W}^{[1]} \\mathbf{x}^{(i)} + \\mathbf{b}^{[1]} \\\\mathbf{a}^{1} &amp;&#x3D; g^{[1]}(\\mathbf{z}^{1}) \\z^{2} &amp;&#x3D; \\mathbf{w}^{[2]T} \\mathbf{a}^{1} + b^{[2]} \\a^{2} &amp;&#x3D; g^{[2]}(z^{2})\\end{aligned}$$\n2. 向量化（批量）形式：　　将所有样本同时处理：\n$$\\begin{aligned}\\mathbf{Z}^{[1]} &amp;&#x3D; \\mathbf{W}^{[1]} \\mathbf{X} + \\mathbf{b}^{[1]} \\\\mathbf{A}^{[1]} &amp;&#x3D; g^{[1]}(\\mathbf{Z}^{[1]}) \\\\mathbf{Z}^{[2]} &amp;&#x3D; \\mathbf{w}^{[2]T} \\mathbf{A}^{[1]} + b^{[2]} \\\\mathbf{A}^{[2]} &amp;&#x3D; g^{[2]}(\\mathbf{Z}^{[2]})\\end{aligned}$$\n　　其中：\n\n$\\mathbf{Z}^{[1]} \\in \\mathbb{R}^{n^{[1]} \\times m}$\n$\\mathbf{A}^{[1]} \\in \\mathbb{R}^{n^{[1]} \\times m}$\n$\\mathbf{Z}^{[2]} \\in \\mathbb{R}^{1 \\times m}$\n$\\mathbf{A}^{[2]} \\in \\mathbb{R}^{1 \\times m}$\n\n\n✅ 关键点：输出矩阵的每一列对应一个样本的计算结果。\n\n\n四、为什么向量化是正确的？——矩阵乘法的解释　　考虑权重矩阵 $\\mathbf{W}^{[1]} \\in \\mathbb{R}^{n^{[1]} \\times n_x}$，输入矩阵 $\\mathbf{X} &#x3D; [\\mathbf{x}^{(1)}, \\mathbf{x}^{(2)}, \\dots, \\mathbf{x}^{(m)}]$。\n　　根据矩阵乘法规则：\n$$\\mathbf{W}^{[1]} \\mathbf{X} &#x3D;\\left[\\mathbf{W}^{[1]} \\mathbf{x}^{(1)},\\mathbf{W}^{[1]} \\mathbf{x}^{(2)},\\dots,\\mathbf{W}^{[1]} \\mathbf{x}^{(m)}\\right]\\left[\\mathbf{z}^{1},\\mathbf{z}^{1},\\dots,\\mathbf{z}^{1}\\right]&#x3D; \\mathbf{Z}^{[1]}$$\n\n这正是我们想要的：一次矩阵乘法自动完成所有样本的线性变换。\n\n关于偏置项 $\\mathbf{b}^{[1]}$ 的广播（Broadcasting）\n$\\mathbf{b}^{[1]} \\in \\mathbb{R}^{n^{[1]} \\times 1}$\n\n在 NumPy &#x2F; Python 中，W1 @ X + b1 会自动将 $\\mathbf{b}^{[1]}$ 广播（broadcast）到每一列，即：\n$$\\mathbf{Z}^{[1]} &#x3D; \\mathbf{W}^{[1]} \\mathbf{X} + \\underbrace{\\begin{bmatrix} \\mathbf{b}^{[1]} &amp; \\mathbf{b}^{[1]} &amp; \\cdots &amp; \\mathbf{b}^{[1]} \\end{bmatrix}}_{m \\text{ 次重复}}$$\n\n\n　　因此，即使包含偏置项，向量化依然成立。\n\n五、通用模式与深层网络的扩展　　课程指出，前向传播具有递归对称结构：\n　　令 $\\mathbf{A}^{[0]} &#x3D; \\mathbf{X}$（输入层激活值），则对任意第 $l$ 层：\n$$\\begin{aligned}\\mathbf{Z}^{[l]} &amp;&#x3D; \\mathbf{W}^{[l]} \\mathbf{A}^{[l-1]} + \\mathbf{b}^{[l]} \\\\mathbf{A}^{[l]} &amp;&#x3D; g^{[l]}(\\mathbf{Z}^{[l]})\\end{aligned}$$\n\n🔁 这种“线性变换 + 激活函数”的模式在每一层重复，使得向量化可自然推广到任意深度的神经网络。\n\n\n六、小结（Recap）\n\n\n操作\n非向量化（循环）\n向量化（矩阵）\n\n\n\n输入\n$\\mathbf{x}^{(i)}$\n$\\mathbf{X} \\in \\mathbb{R}^{n_x \\times m}$\n\n\n线性输出\n$\\mathbf{z}^{1} &#x3D; \\mathbf{W}^{[1]} \\mathbf{x}^{(i)} + \\mathbf{b}^{[1]}$\n$\\mathbf{Z}^{[1]} &#x3D; \\mathbf{W}^{[1]} \\mathbf{X} + \\mathbf{b}^{[1]}$\n\n\n激活输出\n$\\mathbf{a}^{1} &#x3D; g(\\mathbf{z}^{1})$\n$\\mathbf{A}^{[1]} &#x3D; g(\\mathbf{Z}^{[1]})$\n\n\n　　✅ 优势：\n\n无需显式 for 循环\n利用高度优化的 BLAS 库（如 cuBLAS）\n代码简洁，运行速度快\n\n\n七、后续内容预告　　本节使用 Sigmoid 激活函数作为示例，但吴恩达指出：Sigmoid 并非最优选择。下一节将介绍其他更有效的激活函数，如：\n\nReLU（Rectified Linear Unit）：$g(z) &#x3D; \\max(0, z)$\ntanh\nLeaky ReLU 等\n\n　　这些函数能缓解梯度消失问题，加速训练。\n","categories":["神经网络与深度学习"]},{"title":"Higher-order component","url":"/blog/Higher-order-component/","content":"高阶组件可以做什么？增强回调和生命周期\n增强回调\n\ntype Base = &#123; onClick: () =&gt; void &#125;;export const withLoggingOnClickWithProps = &lt;TProps extends Base&gt;(Component: ComponentType&lt;TProps&gt;) =&gt; &#123;  // our returned component will now have additional logText prop  return (props: TProps &amp; &#123; logText: string &#125;) =&gt; &#123;    const onClick = () =&gt; &#123;      // accessing it here, as any other props      console.log(&#x27;Log on click: &#x27;, props.logText);      props.onClick();    &#125;;    return &lt;Component &#123;...props&#125; onClick=&#123;onClick&#125; /&gt;;  &#125;;&#125;;const Page = () =&gt; &#123;  return (    &lt;ButtonWithLoggingOnClickWithProps onClick=&#123;onClickCallback&#125; logText=&quot;this is Page button&quot;&gt;      Click me    &lt;/ButtonWithLoggingOnClickWithProps&gt;  );&#125;;\n\n\n在挂载时发送数据而不是点击时\n\nexport const withLoggingOnMount = &lt;TProps extends unknown&gt;(Component: ComponentType&lt;TProps&gt;) =&gt; &#123;  return (props: TProps) =&gt; &#123;    // no more overriding onClick, just adding normal useEffect    useEffect(() =&gt; &#123;      console.log(&#x27;log on mount&#x27;);    &#125;, []);    // just passing props intact    return &lt;Component &#123;...props&#125; /&gt;;  &#125;;&#125;;\n\n拦截 DOM 事件useEffect(() =&gt; &#123;  const keyPressListener = (event) =&gt; &#123;    // do stuff  &#125;;  window.addEventListener(&#x27;keypress&#x27;, keyPressListener);  return () =&gt; window.removeEventListener(&#x27;keypress&#x27;, keyPressListener);&#125;, []);export const Modal = (&#123; onClose &#125;: ModalProps) =&gt; &#123;  const onKeyPress = (event) =&gt; event.stopPropagation();  return &lt;div onKeyPress=&#123;onKeyPress&#125;&gt;...// dialog code&lt;/div&gt;;&#125;;// same asexport const withSupressKeyPress = &lt;TProps extends unknown&gt;(Component: ComponentType&lt;TProps&gt;) =&gt; &#123;  return (props: TProps) =&gt; &#123;    const onKeyPress = (event) =&gt; &#123;      event.stopPropagation();    &#125;;    return (      &lt;div onKeyPress=&#123;onKeyPress&#125;&gt;        &lt;Component &#123;...props&#125; /&gt;      &lt;/div&gt;    );  &#125;;&#125;;\n\n通用 React 上下文选择器// mini-reduxexport const withContextSelector = &lt;TProps extends unknown, TValue extends unknown&gt;（  Component: ComponentType&lt;TProps &amp; Record&lt;string, TValue&gt;&gt;,  selectors: Record&lt;string, (data: Context) =&gt; TValue&gt;,）: Component&lt;Record&lt;string, TValue&gt;&gt; =&gt; &#123;  // memoising component generally for every prop  const MemoisedComponent = React.memo(Component) as ComponentType&lt;Record&lt;string, TValue&gt;&gt;;  return (props: TProps &amp; Record&lt;string, TValue&gt;) =&gt; &#123;    // extracting everything from context    const data = useFormContext();    // mapping keys that are coming from &quot;selectors&quot; argument    // to data from context    const contextProps = Object.keys(selectors).reduce((acc, key) =&gt; &#123;      acc[key] = selectors[key](data);      return acc;    &#125;, &#123;&#125;);    // spreading all props to the memoised component    return &lt;MemoisedComponent &#123;...props&#125; &#123;...contextProps&#125; /&gt;;  &#125;;&#125;\n\n// props are injected by the higher order component belowconst CountriesWithFormId = (&#123;  formId,  countryName,&#125;: &#123;  formId: string,  countryName: string,&#125;) =&gt; &#123;  console.log(&quot;Countries with selector re-render&quot;);  return (    &lt;div&gt;      &lt;h3&gt;List of countries for form: &#123;formId&#125;&lt;/h3&gt;      Selected country: &#123;countryName&#125;      &lt;ul&gt;        &lt;li&gt;Australia&lt;/li&gt;        &lt;li&gt;USA&lt;/li&gt;      &lt;/ul&gt;    &lt;/div&gt;  );&#125;;// mapping props to selector functionsconst CountriesWithFormIdSelector = withContextSelector(CountriesWithFormId, &#123;  formId: (data) =&gt; data.id,  countryName: (data) =&gt; data.country,&#125;);\n\n总结\n使用附加功能增强回调和 React 生命周期事件，例如发送日志记录或分析事件\n拦截 DOM 事件，例如在打开模式对话框时阻止全局键盘快捷键\n提取一段上下文而不导致组件中不必要的重新渲染\n\n","categories":["React"]},{"title":"JavaScript 引擎基础：Shapes 和 Inline Caches","url":"/blog/JavaScript%20%E5%BC%95%E6%93%8E%E5%9F%BA%E7%A1%80%EF%BC%9AShapes%20%E5%92%8C%20Inline%20Caches/","content":"本文就所有 JavaScript 引擎中常见的一些关键基础内容进行了介绍——这不仅仅局限于 V8 引擎。作为一名 JavaScript 开发者，深入了解 JavaScript 引擎是如何工作的将有助于你了解自己所写代码的性能特征。关于本文，全文共由五个部分组成：\n\n​JavaScript 引擎工作流程​：介绍 JavaScript 引擎的处理流水线，这一部分会涉及到解释器／编译器的内容，且会分点介绍不同引擎间的差别与共同点；\n​JavaScript 对象模型​；\n​属性访问的优化​：通过 Shapes、Transistion 链与树、ICs 等概念的穿插介绍引擎是如何优化获取对象属性的；\n​高效存储数组​；\n​Take-aways​：对全文内容做了一个小结，并给了两点建议。\n\n　　原文 JavaScript engine fundamentals: Shapes and Inline Caches，作者 @Benedikt 和 @Mathias，译者 hijiangtao。\n\n如果你倾向看视频演讲，请移步 YouTube 查看更多。\n\n1. JavaScript 引擎工作流程　　这一切都得从你所写的 JavaScript 代码开始说起。JavaScript 引擎在解析源码后将其转换为抽象语法树（AST）。基于 AST，解释器便可以开始工作并产生字节码。非常棒！此时引擎正在执行 JavaScript 代码。\n​\n　　为了使它执行得更快，可以将字节码与分析数据（profiling data）一起发给优化编译器。优化编译器根据已有的分析数据做出特定假设，然后生成高度优化的机器码。\n　　如果在某点上一个假设被证明是不正确的，那么优化编译器会去优化并回退至解释器部分。\n1.1 JavaScript 引擎中的解释器&#x2F;编译器流程　　现在，让我们关注实际执行 JavaScript 代码的这部分流程，即代码被解释和优化的地方，并讨论其在主要的 JavaScript 引擎之间存在的一些差异。\n　　一般来说，（所有 JavaSciript 引擎）都有一个包含解释器和优化编译器的处理流程。其中，解释器可以快速生成未优化的字节码，而优化编译器会需要更长的时间，以便最终生成高度优化的机器码。\n​\n　　这个通用流程几乎与在 Chrome 和 Node.js 中使用的 V8 引擎工作流程一致：\n​\n　　V8 中的解释器被称作 Ignition，它负责生成并执行字节码。当它运行字节码时会收集分析数据，而它之后可以被用于加快（代码）执行的速度。当一个函数变得 ​hot​，例如它经常被调用，生成的字节码和分析数据则会被传给 TurboFan——我们的优化编译器，它会依据分析数据生成高度优化的机器码。\n​\n　　SpiderMonkey，在 Firefox 和 SpiderNode 中使用的 Mozilla 的 JavaScript 引擎，则有一些不同的地方。它们有两个优化编译器。解释器将代码解释给 Baseline 编译器，该编译器可以生成部分优化的代码。 结合运行代码时收集的分析数据，IonMonkey 编译器可以生成高度优化的代码。 如果尝试优化失败，IonMonkey 将回退到 Baseline 阶段的代码。\n​\n　　Chakra，用于 Edge 和 Node-ChakraCore 两个项目的微软 JavaScript 引擎，也有类似两个优化编译器的设置。解释器将代码优化成 SimpleJIT——其中 JIT 代表 Just-In-Time 编译器——它可以生成部分优化的代码。 结合分析数据，FullJIT 可以生成更深入优化的代码。\n​\n　　JavaScriptCore（缩写为 JSC），Apple 的 JavaScript 引擎，被用于 Safari 和 React Native 两个项目中，它通过三种不同的优化编译器使效果达到极致。低级解释器 LLInt 将代码解释后传递给 Baseline 编译器，而（经过 Baseline 编译器）优化后的代码便传给了 DFG 编译器，（在 DFG 编译器处理后）结果最终传给了 FTL 编译器进行处理。\n　　为什么有些引擎会拥有更多的优化编译器呢？这完全是一些折衷的取舍。解释器可以快速生成字节码，但字节码通常不够高效。另一方面，优化编译器处理需要更长的时间，但最终会生成更高效的机器码。到底是快速获取可执行的代码（解释器），还是花费更多时间但最终以最佳性能运行代码（优化编译器），这其中包含一个平衡点。一些引擎选择添加具有不同耗时&#x2F;效率特性的多个优化编译器，以更高的复杂性为代价来对这些折衷点进行更细粒度的控制。\n　　我们刚刚强调了每个 JavaScript 引擎中解释器和优化编译器流程中的主要区别。除了这些差异之外，​所有 JavaScript 引擎都有相同的架构​：那就是拥有一个解析器和某种解释器&#x2F;编译器流程。\n2. JavaScript 对象模型　　通过关注一些方面的具体实现，让我们来看看 JavaScript 引擎间还有哪些共同之处。\n　　例如，JavaScript 引擎是如何实现 JavaScript 对象模型的，以及他们使用了哪些技巧来加快获取 JavaScript 对象属性的速度？事实证明，所有主要引擎在这一点上的实现都很相似。\n　　ECMAScript 规范基本上将所有对象定义为由字符串键值映射到 property 属性 的字典。\n​\n　　除 [[Value]]​ 外，规范还定义了如下属性：\n\n​[[Writable]]​ 决定该属性是否可以被重新赋值；\n​[[Enumerable]]​ 决定该属性是否出现在 for-in​ 循环中；\n​[[Configurable]]​ 决定该属性是否可被删除。\n\n　　​[[双方括号]] ​的符号表示看上去有些特别，但这正是规范定义不能直接暴露给 JavaScript 的属性的表示方法。在 JavaScript 中你仍然可以通过 Object.getOwnPropertyDescriptor​ API 获得指定对象的属性值：\nconst object = &#123; foo: 42 &#125;;Object.getOwnPropertyDescriptor(object, &#x27;foo&#x27;);// → &#123; value: 42, writable: true, enumerable: true, configurable: true &#125;\n\n　　JavaScript 就是这个定义对象的，那么数组呢？\n　　你可以将数组想象成一组特殊的对象。两者的一个区别便是数组会对数组索引进行特殊的处理。这里所指的数组索引是 ECMAScript 规范中的一个特殊术语。在 JavaScript 中，数组被限制最多只能拥有 2​32​-1 项。数组索引是指该限制内的任何有效索引，即从 0 到 2​32​-2 的任何整数。\n　　另一个区别是数组还有一个充满魔力的 length​ 属性。\nconst array = [&#x27;a&#x27;, &#x27;b&#x27;];array.length; // → 2array[2] = &#x27;c&#x27;;array.length; // → 3\n\n　　在这个例子中，array​ 在生成时长度单位为 2。接着我们向索引为 2 ​的位置分配了另一个元素，length​ 属性便自动更新。\n　　JavaScript 在定义数组的方式上和对象类似。例如，包括数组索引的所有键值都明确地表示为字符串。 数组中的第一个元素存储在键值为 ‘0’ 的位置下。\n​\n　　​&#39;length&#39;​ 属性恰好是另一个不可枚举且不可配置的属性。\n　　一个元素一旦被添加到数组中，JavaScript 便会自动更新 &#39;length&#39;​ 属性的 [[Value]]​ 属性值。\n​\n　　一般来说，数组的行为与对象也非常相似。\n3. 属性访问的优化　　让我们深入了解下 JavaScript 引擎是如何有效地应对对象相关操作的。\n　　观察 JavaScript 程序，访问属性是最常见的一个操作。使得 JavaScript 引擎能够快速获取属性便至关重要。\nconst object = &#123;    foo: &#x27;bar&#x27;,    baz: &#x27;qux&#x27;,&#125;;// Here, we’re accessing the property `foo` on `object`:doSomething(object.foo);//          ^^^^^^^^^^\n\n3.1 Shapes　　在 JavaScript 程序中，多个对象具有相同的键值属性是非常常见的。这些对象都具有相同的形状。\nconst object1 = &#123; x: 1, y: 2 &#125;;const object2 = &#123; x: 3, y: 4 &#125;;// `object1` and `object2` have the same shape.\n\n　　访问具有相同形状对象的相同属性也很常见：\nfunction logX(object) &#123;    console.log(object.x);    //          ^^^^^^^^&#125;const object1 = &#123; x: 1, y: 2 &#125;;const object2 = &#123; x: 3, y: 4 &#125;;logX(object1);logX(object2);\n\n　　考虑到这一点，JavaScript 引擎可以根据对象的形状来优化对象的属性获取。它是这么实现的。\n　　假设我们有一个具有属性 x​ 和 y​ 的对象，它使用我们前面讨论过的字典数据结构：它包含用字符串表示的键值，而它们指向各自的属性值。\n​\n　　如果你访问某个属性，例如 object.y​，JavaScript 引擎会在 JSObject​ 中查找键值 &#39;y&#39;​，然后加载相应的属性值，最后返回 [[Value]]​。\n　　但这些属性值在内存中是如何存储的呢？我们是否应该将它们存储为 JSObject​ 的一部分？假设我们稍后会遇到更多同形状的对象，那么在 JSObject​ 自身存储包含属性名和属性值的完整字典便是很浪费（空间）的，因为对具有相同形状的所有对象我们都重复了一遍属性名称。 它太冗余且引入了不必要的内存使用。 作为优化，引擎将对象的 Shape​ 分开存储。\n​\n　　​Shape​ 包含除 [[Value]]​ 之外的所有属性名和其余特性。相反，Shape​ 包含 JSObject​ 内部值的偏移量，以便 JavaScript 引擎知道去哪查找具体值。每个具有相同形状的 JSObject​ 都指向这个 Shape​ 实例。 现在每个 JSObject​ 只需要存储对这个对象来说唯一的那些值。\n​\n　　当我们有多个对象时，优势变得清晰可见。无论有多少个对象，只要它们具有相同的形状，我们只需要将它们的形状与键值属性信息存储一次！\n　　所有的 JavaScript 引擎都使用了形状作为优化，但称呼各有不同：\n\n学术论文称它们为 ​Hidden Classes​（容易与 JavaScript 中的类概念混淆）\nV8 将它们称为 ​Maps​（容易与 JavaScript 中的 Map​ 概念混淆）\nChakra 将它们称为 ​Types​（容易与 JavaScript 中的动态类型和关键字 typeof​ 混淆）\nJavaScriptCore 称它们为 Structures\nSpiderMonkey 称他们为 Shapes\n\n　　本文中，我们会继续称它为 ​shapes​。\n3.2 Transition 链与树　　如果你有一个具有特定形状的对象，但你又向它添加了一个属性，此时会发生什么？ JavaScript 引擎是如何找到这个新形状的？\nconst object = &#123;&#125;;object.x = 5;object.y = 6;\n\n　　在 JavaScript 引擎中，shapes 的表现形式被称作 ​transition 链​。以下展示一个示例：\n​\n　　该对象在初始化时没有任何属性，因此它指向一个空的 shape。下一个语句为该对象添加值为 5​ 的属性 “x”​，所以 JavaScript 引擎转向一个包含属性 “x”​ 的 Shape，并向 JSObject​ 的第一个偏移量为 0 处添加了一个值 5​。 接下来一个语句添加了一个属性 &#39;y&#39;​，引擎便转向另一个包含 &#39;x&#39;​ 和 &#39;y&#39;​ 的 Shape，并将值 6​ 附加到 JSObject​（位于偏移量 1​ 处）。\n　　我们甚至不需要为每个 Shape 存储完整的属性表。相反，每个 Shape 只需要知道它引入的新属性。 例如在此例中，我们不必在最后一个 Shape 中存储关于 &#39;x&#39;​ 的信息，因为它可以在更早的链上被找到。要做到这一点，每一个 Shape 都会与其之前的 Shape 相连：\n​\n　　如果你在 JavaScript 代码中写到了 o.x​，则 JavaScript 引擎会沿着 transition 链去查找属性 “x”​，直到找到引入属性 “x” ​的 Shape。\n　　但是，如果不能只创建一个 transition 链呢？例如，如果你有两个空对象，并且你为每个对象都添加了一个不同的属性？\nconst object1 = &#123;&#125;;object1.x = 5;const object2 = &#123;&#125;;object2.y = 6;\n\n　　在这种情况下我们便必须进行分支操作，此时我们最终会得到一个 transition 树 而不是 transition 链：\n​\n　　在这里，我们创建一个空对象 a​，然后为它添加一个属性 &#39;x&#39;​。 我们最终得到一个包含单个值的 JSObject​，以及两个 Shapes：空 Shape 和仅包含属性 x ​的 Shape。\n　　第二个例子也是从一个空对象 b​ 开始的，但之后被添加了一个不同的属性 &#39;y&#39;​。我们最终形成两个 shape 链，总共是三个 shape。\n　　这是否意味着我们总是需要从空 shape 开始呢？ 并不是。引擎对已包含属性的对象字面量会应用一些优化。比方说，我们要么从空对象字面量开始添加 x​ 属性，要么有一个已经包含属性 x​ 的对象字面量：\nconst object1 = &#123;&#125;;object1.x = 5;const object2 = &#123; x: 6 &#125;;\n\n　　在第一个例子中，我们从空 shape 开始，然后转向包含 x​ 的 shape，这正如我们我们之前所见。\n　　在 object2​ 一例中，直接生成具有属性 x​ 的对象是有意义的，而不是从空对象开始然后进行 transition 连接。\n​\n　　包含属性 &#39;x&#39;​ 的对象字面量从包含 &#39;x&#39;​ 的 shape 开始，可以有效地跳过空的 shape。V8 和 SpiderMonkey （至少）正是这么做的。这种优化缩短了 transition 链，并使得从字面量构造对象更加高效。\n　　Benedikt 的博文 surprising polymorphism in React applications 讨论了这些微妙之处是如何影响实际性能的。\n3.3 Inline Caches (ICs)　　Shapes 背后的主要动机是 Inline Caches 或 ICs 的概念。ICs 是促使 JavaScript 快速运行的关键因素！JavaScript 引擎利用 ICs 来记忆去哪里寻找对象属性的信息，以减少昂贵的查找次数。\n　　这里有一个函数 getX​，它接受一个对象并从中取出属性 x​ 的值：\nfunction getX(o) &#123;    return o.x;&#125;\n\n　　如果我们在 JSC 中执行这个函数，它会生成如下字节码：\n​\n　　指令一 get_by_id​ 从第一个参数（arg1​）中加载属性 &#39;x&#39;​ 值并将其存储到地址 loc0​ 中。 第二条指令返回我们存储到 loc0​ 中的内容。\n　　JSC 还在 get_by_id​ 指令中嵌入了 Inline Cache，它由两个未初始化的插槽组成。\n​\n　　现在让我们假设我们用对象 {x：&#39;a&#39;}​ 调用 getX​ 函数。正如我们所知，这个对象有一个包含属性 &#39;x&#39;​ 的 Shape，该 Shape 存储了属性 x​ 的偏移量和其他特性。当你第一次执行该函数时，get_by_id​ 指令将查找属性 &#39;x&#39;​，然后发现其值存储在偏移量 0​ 处。\n​\n　　嵌入到 get_by_id​ 指令中的 IC 存储该属性的 shape 和偏移量：\n​\n　　对于后续运行，IC 只需要对比 shape，如果它与以前相同，只需从记忆的偏移量处加载该属性值。具体来说，如果 JavaScript 引擎看到一个对象的 shape 之前被 IC 记录过，它则不再需要接触属性信息——而是完全可以跳过昂贵的属性信息查找（过程）。这比每次查找属性要快得多。\n4. 高效存储数组　　对于数组来说，存储属性诸如数组索引等是非常常见的。这些属性的值被称为数组元素。存储每个数组中的每个数组元素的属性特性（property attributes）将是一种很浪费的存储方式。相反，由于数组索引默认属性是可写的、可枚举的并且可以配置的，JavaScript 引擎利用这一点，将数组元素与其他命名属性分开存储。\n　　考虑这个数组：\nconst array = [    &#x27;#jsconfeu&#x27;,];\n\n　　引擎存储了数组长度（1​），并指向包含 offset​ 和 &#39;length&#39;​ 特性属性的 Shape。\n​\n　　这与我们之前见过的类似……但数组值存储在哪里呢？\n​\n　　每个数组都有一个单独的 ​elements backing store​，其中包含所有数组索引的属性值。JavaScript 引擎不必为数组元素存储任何属性特性，因为它们通常都是可写的，可枚举的以及可配置的。\n　　那么如果不是通常的情况呢？如果更改了数组元素的属性，该怎么办？\n// Please don’t ever do this!const array = Object.defineProperty(    [],    &#x27;0&#x27;,    &#123;        value: &#x27;Oh noes!!1&#x27;,        writable: false,        enumerable: false,        configurable: false,    &#125;);\n\n　　上面的代码片段定义了一个名为 &#39;0&#39;​ 的属性（这恰好是一个数组索引），但其特性（value​）被设置为了一个非默认值。\n　　在这种边缘情况下，JavaScript 引擎会将全部的 elements backing store 表示为一个由数组下标映射到属性特性的字典。\n​\n　　即使只有一个数组元素具有非默认属性，整个数组的 backing store 处理也会进入这种缓慢而低效的模式。\n　　避免在数组索引上使用 Object.defineProperty​！\n　　 （我不知道为什么你会想这样做。这看上去似乎是一个奇怪的且毫无价值的事情。）\n5. Take-aways　　我们已经学习了 JavaScript 引擎是如何存储对象和数组的，以及 Shapes 和 IC 是如何优化针对它们的常见操作的。基于这些知识，我们确定了一些有助于提升性能的实用 JavaScript 编码技巧：\n\n始终以相同的方式初始化对象，以确保它们不会走向不同的 shape 方向。\n不要混淆数组元素的属性特性（property attributes），以确保可以高效地存储和操作它们。\n\n　　（完）\n","categories":["进阶"],"tags":["js"]},{"title":"React Hook 和 setInterval一起使用的问题","url":"/blog/React-Hook-%E5%92%8C-setInterval%E4%B8%80%E8%B5%B7%E4%BD%BF%E7%94%A8%E7%9A%84%E9%97%AE%E9%A2%98/","content":"如果仅仅是用一个变量来保存tiner的ID，会导致无法清除timerID如下：\nconst TimerCount = () =&gt; &#123;  let [count,setCount] = useState(0)  let timer  const handleStart =() =&gt; &#123;    timer = setInterval(() =&gt; &#123;      setCount(count++)    &#125;,1000)  &#125;  const handleEnd = () =&gt; &#123;    clearInterval(timer)  &#125;  return (    &lt;&gt;    &lt;button onClick=&#123;handleStart&#125;&gt;start&lt;/button&gt;    &lt;button onClick=&#123;handleEnd&#125;&gt;end&lt;/button&gt;    &lt;div&gt;&#123;count&#125;&lt;/div&gt;    &lt;/&gt;  )&#125;\n\n原因：timer的id是一个number类型，每次在页面展示count时，都会 触发重新渲染，timer会被重新赋值，这是一个基本类型的值，需要清除的timer值已经不是原来的值了，虽然打印出来的是一样的值。\n解决方案用useRef，在整个渲染周期固定一个值\nconst TimerCount = () =&gt; &#123;  let [count,setCount] = useState(0)  let timer = useRef&lt;any&gt;(null)  const handleStart =() =&gt; &#123;    timer.current = setInterval(() =&gt; &#123;      setCount(count++)    &#125;,1000)  &#125;  const handleEnd = () =&gt; &#123;    clearInterval(timer.current)  &#125;  return (    &lt;&gt;    &lt;button onClick=&#123;handleStart&#125;&gt;start&lt;/button&gt;    &lt;button onClick=&#123;handleEnd&#125;&gt;end&lt;/button&gt;    &lt;div&gt;&#123;count&#125;&lt;/div&gt;    &lt;/&gt;  )&#125;\n\n这时timer是一个引用类型，里面的current属性保存了timer的id，并且整个渲染周期不变。使用ref访问DOM节点也是一样的原理\n","categories":["React"]},{"title":"React Hooks","url":"/blog/React-Hooks/","content":"useState返回一个 state，和一个更新 state 的函数\n函数式更新如果新的 state 需要通过先前的 state 计算得出，可以传递一个函数给 setState，如下：\nsetState((prev) =&gt; &#123;  return prev + 1;&#125;);\n\n惰性初始 state如果初始 state 需要通过复杂计算获得，则可以传入一个函数，在函数中计算并返回初始的 state，此函数只在初始渲染时被调用：\nconst [state, setState] = useState(() =&gt; &#123;  const initialState = someExpensiveComputation(props);  return initialState;&#125;);\n\n第一个常见的使用场景是当创建初始 state 很昂贵时：\nfunction Table(props) &#123;  // ⚠️ createRows() 每次渲染都会被调用  const [rows, setRows] = useState(createRows(props.count));  // ...&#125;function Table(props) &#123;  // ✅ createRows() 只会被调用一次  const [rows, setRows] = useState(() =&gt; createRows(props.count));  // ...&#125;\n\nuseEffect使用 useEffect 完成副作用操作。赋值给 useEffect 的函数会在组件渲染到屏幕之后执行。如果想执行只运行一次的 effect（仅在组件挂载和卸载时执行），可以传递一个空数组（[]）作为第二个参数。这就告诉 React 你的 effect 不依赖于 props 或 state 中的任何值，所以它永远都不需要重复执行。\nuseReduceruseState 的替代方案。它接收一个形如 (state, action) =&gt; newState 的 reducer，并返回当前的 state 以及与其配套的 dispatch 方法。在某些场景下，useReducer 会比 useState 更适用，例如 state 逻辑较复杂且包含多个子值，或者下一个 state 依赖于之前的 state 等。\nuseCallbackconst memoizedCallback = useCallback(() =&gt; &#123;  doSomething(a, b);&#125;, [a, b]);\n\n返回一个 memoized 回调函数。该回调函数仅在某个依赖项改变时才会更新。\nuseMemoconst memoizedValue = useMemo(() =&gt; computeExpensiveValue(a, b), [a, b]);\n\n返回一个 memoized 值。把“创建”函数和依赖项数组作为参数传入 useMemo，它仅会在某个依赖项改变时才重新计算 memoized 值。这种优化有助于避免在每次渲染时都进行高开销的计算。\n","categories":["React"]},{"title":"React element，children，parents and re-renders","url":"/blog/React-element%EF%BC%8Cchildren%EF%BC%8Cparents-and-re-renders/","content":"children as a render functionconst MovingComponent = (&#123; children &#125;) =&gt; &#123;  ...  return (    &lt;div ...// callbacks same as before      &gt;      // children as render function with some data      // data doesn&#x27;t depend on the changed state!      &#123;children(&#123; data: &#x27;something&#x27; &#125;)&#125;    &lt;/div&gt;  );&#125;;const SomeOutsideComponent = () =&gt; &#123;  return (    &lt;MovingComponent&gt;      // ChildComponent re-renders when state in MovingComponent changes!      // even if it doesn&#x27;t use the data that is passed from it      &#123;() =&gt; &lt;ChildComponent /&gt;&#125;    &lt;/MovingComponent&gt;  )&#125;\n\nReact.memo behaviormemo parent// wrapping MovingComponent in memo to prevent it from re-renderingconst MovingComponentMemo = React.memo(MovingComponent);const SomeOutsideComponent = () =&gt; &#123;  // trigger re-renders here with state  const [state, setState] = useState();  return (    &lt;MovingComponentMemo&gt;      &lt;!-- ChildComponent will still re-render when SomeOutsideComponent re-renders --&gt;      &lt;ChildComponent /&gt;    &lt;/MovingComponentMemo&gt;  )&#125;\n\nmemo child// wrapping ChildComponent in memo to prevent it from re-renderingconst ChildComponentMemo = React.memo(ChildComponent);const SomeOutsideComponent = () =&gt; &#123;  // trigger re-renders here with state  const [state, setState] = useState();  return (    &lt;MovingComponent&gt;      &lt;!-- ChildComponent won&#x27;t re-render, even if the parent is not memoized --&gt;      &lt;ChildComponentMemo /&gt;    &lt;/MovingComponent&gt;  )&#125;\n\nuseCallback hook behaviorconst SomeOutsideComponent = () =&gt; &#123;  // trigger re-renders here with state  const [state, setState] = useState();  // trying to prevent ChildComponent from re-rendering by memoising render function. Won&#x27;t work!  const child = useCallback(() =&gt; &lt;ChildComponent /&gt;, []);  return (    &lt;MovingComponent&gt;      &lt;!-- Memoized render function. Didn&#x27;t help with re-renders though --&gt;      &#123;child&#125;    &lt;/MovingComponent&gt;  )&#125;\n\nWhy?什么是react 的child？const Parent = (&#123; children &#125;) =&gt; &#123;  return &lt;&gt;&#123;children&#125;&lt;/&gt;;&#125;;&lt;Parent&gt;  &lt;Child /&gt;&lt;/Parent&gt;;\n\n仅仅是一个 prop我们可以将组件作为 elements， functions 或者 Components\n// as prop&lt;Parent children=&#123;() =&gt; &lt;Child /&gt;&#125; /&gt;// &quot;normal&quot; syntax&lt;Parent&gt;  &#123;() =&gt; &lt;Child /&gt;&#125;&lt;/Parent&gt;// implementationconst Parent = (&#123; children &#125;) =&gt; &#123;  return &lt;&gt;&#123;children()&#125;&lt;/&gt;&#125;// even this&lt;Parent children=&#123;Child&#125; /&gt;;const Parent = (&#123; children: Child &#125;) =&gt; &#123;  return &lt;&gt;&#123;&lt;Child /&gt;&#125;&lt;/&gt;;&#125;;\n\n什么是 React element？const child = &lt;Child /&gt;\n\n这里  仅仅是一个 React.createElement 语法糖，它返回一个对象，这个对象是你想要在屏幕上看到的元素的描述\nconst Parent = () =&gt; &#123;  // will just sit there idly  const child = &lt;Child /&gt;;  return &lt;div /&gt;;&#125;;// same asconst Parent = () =&gt; &#123;  // exactly the same as &lt;Child /&gt;  const child = React.createElement(Child, null, null);  return &lt;div /&gt;;&#125;;\n\nconst Parent = () =&gt; &#123;  // render of Child will be triggered when Parent re-renders  // since it&#x27;s included in the return  const child = &lt;Child /&gt;;  return &lt;div&gt;&#123;child&#125;&lt;/div&gt;;&#125;;\n\n更新元素元素是不可变的对象。更新元素并触发其相应组件重新渲染的唯一方法是重新创建对象本身。这正是重新渲染期间发生的事情\nconst Parent = () =&gt; &#123;  // child definition object will be re-created.  // so Child component will be re-rendered when Parent re-renders  const child = &lt;Child /&gt;;  return &lt;div&gt;&#123;child&#125;&lt;/div&gt;;&#125;;\n\n而且仅仅会重新创建和更新存在的组件，我们可以使用 React.memo 或者 useMemo 记忆它：\nconst ChildMemo = React.memo(Child);const Parent = () =&gt; &#123;  const child = &lt;ChildMemo /&gt;;  return &lt;div&gt;&#123;child&#125;&lt;/div&gt;;&#125;;\n\nconst Parent = () =&gt; &#123;  const child = useMemo(() =&gt; &lt;Child /&gt;, []);  return &lt;div&gt;&#123;child&#125;&lt;/div&gt;;&#125;;\n\n定义对象不会被重新创建，React 会认为它不需要更新，Child 的重新渲染也不会发生。\n我们能够知道\n当我们编写const child &#x3D; 时，我们只是在创建一个Element，即组件定义，而不是渲染它。这个定义是一个不可变的对象。\n此定义中的组件仅在它最终出现在实际渲染树中时才会被渲染。对于功能组件，它是您实际从组件中返回它的时候。\n重新创建定义对象会触发对应组件的重新渲染。\n\n为什么作为prop传递的组件不会重新渲染？const MovingComponent = (&#123; children &#125;) =&gt; &#123;  // this will trigger re-render  const [state, setState] = useState();  return (    &lt;div      // ...      style=&#123;&#123; left: state.x, top: state.y &#125;&#125;    &gt;      &lt;!-- those won&#x27;t re-render because of the state change --&gt;      &#123;children&#125;    &lt;/div&gt;  );&#125;;const SomeOutsideComponent = () =&gt; &#123;  return (    &lt;MovingComponent&gt;      &lt;ChildComponent /&gt;    &lt;/MovingComponent&gt;  )&#125;\n\n这是因为  是在 SomeOutsideComponent 中创建的， MovingComponent 重新渲染时它的props并没有改变，child 不会重新创建，也不会重新渲染。\n为什么children 作为一个render function 时会重新渲染呢？const MovingComponent = (&#123; children &#125;) =&gt; &#123;  // this will trigger re-render  const [state, setState] = useState();  return (    &lt;div ///...    &gt;      &lt;!-- those will re-render because of the state change --&gt;      &#123;children()&#125;    &lt;/div&gt;  );&#125;;const SomeOutsideComponent = () =&gt; &#123;  return (    &lt;MovingComponent&gt;      &#123;() =&gt; &lt;ChildComponent /&gt;&#125;    &lt;/MovingComponent&gt;  )&#125;\n\n在这种情况下， children 是一个函数， Element 是这个函数调用的结果，每次调用MovingComponent 时，都会重新创建函数返回定义对象 ，从而触发重新渲染。\n为什么使用 React.memo 包裹父组件会重新渲染？而包裹子组件 （子组件）不会重新渲染呢？// wrapping MovingComponent in memo to prevent it from re-renderingconst MovingComponentMemo = React.memo(MovingComponent);const SomeOutsideComponent = () =&gt; &#123;  // trigger re-renders here with state  const [state, setState] = useState();  return (    &lt;MovingComponentMemo&gt;      &lt;!-- ChildComponent will re-render when SomeOutsideComponent re-renders --&gt;      &lt;ChildComponent /&gt;    &lt;/MovingComponentMemo&gt;  )&#125;// same asconst SomeOutsideComponent = () =&gt; &#123;  // ...  return &lt;MovingComponentMemo children=&#123;&lt;ChildComponent /&gt;&#125; /&gt;;&#125;;\n\n触发重新渲染时，被记忆的父组件会做 prop 检查，查看是否有prop 被改变了，因为  被重新创建了，所以prop改变了，子组件就重新渲染了。\n// wrapping ChildComponent in memo to prevent it from re-renderingconst ChildComponentMemo = React.memo(ChildComponent);const SomeOutsideComponent = () =&gt; &#123;  // trigger re-renders here with state  const [state, setState] = useState();  return (    &lt;MovingComponent&gt;      &lt;!-- ChildComponent won&#x27;t be re-rendered anymore --&gt;      &lt;ChildComponentMemo /&gt;    &lt;/MovingComponent&gt;  )&#125;\n\n子组件被记忆了， MovingComponent 触发重新渲染时，子组件没有改变，被跳过，不会重新渲染。\n为什么将 children 作为函数传递时，记忆这个函数不起作用呢？const SomeOutsideComponent = () =&gt; &#123;  // trigger re-renders here with state  const [state, setState] = useState();  // this memoization doesn&#x27;t prevent re-renders of ChildComponent  const child = useCallback(() =&gt; &lt;ChildComponent /&gt;, []);  return &lt;MovingComponent&gt;&#123;child&#125;&lt;/MovingComponent&gt;;&#125;;// same asconst SomeOutsideComponent = () =&gt; &#123;  // trigger re-renders here with state  const [state, setState] = useState();  // this memoization doesn&#x27;t prevent re-renders of ChildComponent  const child = useCallback(() =&gt; &lt;ChildComponent /&gt;, []);  return &lt;MovingComponent children=&#123;child&#125; /&gt;;&#125;;\n\n这里记忆的仅仅是这个函数，它的返回值并没有被记忆，所以每次都会重新创建一个新的对象，导致子组件重新渲染。有两种方式可以解决：\n\nReact.memo 包裹 MovingComponent\n删掉 useCallback， 使用 React.memo 包裹 ChildComponent\n\n","categories":["React"],"tags":["进阶"]},{"title":"React Props Children 混合插槽","url":"/blog/React-Props-Children-%E6%B7%B7%E5%90%88%E6%8F%92%E6%A7%BD/","content":"当多种 children 一起输入时function Container(props) &#123;  const defaultProps = &#123;    name: &quot;alen&quot;,    msg: &quot;hello&quot;,  &#125;  return props.children.map((item) =&gt; &#123;    // 通过判断 clone 混入props    if (React.isValidElement(item)) &#123;      return React.cloneElement(item, &#123; ...defaultProps &#125;)    &#125; else if (typeof item === &quot;function&quot;) &#123;      return item(defaultProps)    &#125; else &#123;      return null    &#125;  &#125;)&#125;function Child(props) &#123;  return &lt;div&gt;&#123;props.name + props.msg&#125; &lt;/div&gt;&#125;function App() &#123;  return (    &lt;Container&gt;      // 多种方式混入      &lt;Child /&gt;      &#123;(props) =&gt; &lt;Child &#123;...props&#125; /&gt;&#125;    &lt;/Container&gt;  )&#125;render(&lt;App /&gt;, document.getElementById(&quot;root&quot;))\n","categories":["React"]},{"title":"React memo lazy","url":"/blog/React-memo-lazy/","content":"React.memoreact.memo 有第二个参数，可以通过第二个参数来自定义组件的渲染时机。\nReact.memo(Component, compare)\n\nReact.memo 接受两个参数，第一个参数 Component 原始组件本身，第二个参数 compare 是一个函数，可以根据一次更新中 props 是否相同决定原始组件是否重新渲染。\nmemo 的几个特点是：\n\nReact.memo: 第二个参数 返回 true 组件不渲染 ， 返回 false 组件重新渲染。和 shouldComponentUpdate 相反，shouldComponentUpdate : 返回 true 组件渲染 ， 返回 false 组件不渲染。\n\nmemo 当二个参数 compare 不存在时，会用浅比较原则处理 props ，相当于仅比较 props 版本的 pureComponent 。\n\nmemo 同样适合类组件和函数组件。关于第二个参数你可以这样写：\n\n\nconst compare = (prev, next) =&gt;  prev.number === next.number ||  (prev.number !== next.number &amp;&amp; next.number &gt; 1)\n\n这里有两个意思：\n\nnumber 改变时 组件渲染\nnumber 小于 1 时 组件渲染\n\n关于 rander有没有必要在乎组件不必要渲染。在正常情况下，无须过分在乎 React 没有必要的渲染，执行 render 不等于真正的浏览器渲染视图，render 阶段执行是在 js 当中，js 中运行代码远快于浏览器的 Rendering 和 Painting 的，更何况 React 还提供了 diff 算法等手段，去复用真实 DOM 。\n什么时候需要注意渲染节流。但是对于以下情况，值得开发者注意，需要采用渲染节流：\n\n第一种情况数据可视化的模块组件（展示了大量的数据），这种情况比较小心因为一次更新，可能伴随大量的 diff ，数据量越大也就越浪费性能，所以对于数据展示模块组件，有必要采取 memo ， shouldComponentUpdate 等方案控制自身组件渲染。\n第二种情况含有大量表单的页面，React 一般会采用受控组件的模式去管理表单数据层，表单数据层完全托管于 props 或是 state ，而用户操作表单往往是频繁的，需要频繁改变数据层，所以很有可能让整个页面组件高频率 render 。\n第三种情况就是越是靠近 app root 根组件越值得注意，根组件渲染会波及到整个组件树重新 render ，子组件 render ，一是浪费性能，二是可能执行 useEffect ，componentWillReceiveProps 等钩子，造成意想不到的情况发生。\n\n使用 Suspense 和 React.lazy 模拟实现异步加载组件实现效果\n异步请求数据，请求完数据挂载组件，请求过程中展示 loading 效果。\n全程组件只渲染一次\n\n编写function AsyncComp(Comp, asyncFn) &#123;  const AsyncCompPromise = () =&gt;    new Promise(async (resolve) =&gt; &#123;      const data = await asyncFn()      resolve(&#123;        default: (props) =&gt; &lt;Comp value=&#123;data&#125; &#123;...props&#125; /&gt;,      &#125;)    &#125;)  return React.lazy(AsyncCompPromise)&#125;const fetchData = () =&gt; &#123;  return new Promise((resolve) =&gt; &#123;    setTimeout(() =&gt; &#123;      resolve(&#123;        name: &quot;ranxiu&quot;,        msg: &quot;a lot of data&quot;,      &#125;)    &#125;, 1000)  &#125;)&#125;function Test(&#123; value, gender &#125;) &#123;  const &#123; name, msg &#125; = value  return (    &lt;div&gt;      &lt;div&gt;my name is &#123;name&#125;&lt;/div&gt;      &lt;div&gt;this is &#123;msg&#125;&lt;/div&gt;      &lt;div&gt;my gender is &#123;gender&#125;&lt;/div&gt;    &lt;/div&gt;  )&#125;function App() &#123;  const LzayTest = AsyncComp(Test, fetchData)  return (    &lt;Suspense fallback=&#123;&lt;div&gt;loading...&lt;/div&gt;&#125;&gt;      &lt;LzayTest gender=&#x27;男&#x27; /&gt;    &lt;/Suspense&gt;  )&#125;\n\nReact.lazy 要求函数需要返回一个 Promise。大致流程是，react.lazy 第一次渲染时会向外抛个异常 Promise，这个异常会被 Suspense 捕获到，Suspense 处理 Promise，Promise 执行成功后 Susponse 发起渲染，返回真正需要渲染的组件。\n","categories":["React"]},{"title":"React “Key”","url":"/blog/React-%E2%80%9CKey%E2%80%9D/","content":"什么是key属性以及为什么React需要它？如果存在“key”属性，React 使用它作为在重新渲染期间在其兄弟姐妹中识别相同类型元素的一种方式，也就是说，仅在重新渲染期间和相同类型的相邻元素才需要它。\nconst Item = (&#123; country &#125;) =&gt; &#123;  return (    &lt;button className=&quot;country-item&quot;&gt;      &lt;img src=&#123;country.flagUrl&#125; /&gt;      &#123;country.name&#125;    &lt;/button&gt;  );&#125;;const CountriesList = (&#123; countries &#125;) =&gt; &#123;  return (    &lt;div&gt;      &#123;countries.map((country) =&gt; (        &lt;Item country=&#123;country&#125; /&gt;      ))&#125;    &lt;/div&gt;  );&#125;;// same as countries.map((country, index) =&gt; &lt;Item country=&#123;country&#125; key=&#123;index&#125; /&gt;);\n\nReact 会发现那里没有“键”，然后回退到使用countries数组的索引作为键\n什么情况下可以使用 index 作为 key呢？分页列表如果你希望在相同大小的列表中显示相同类型的不同项目。如果您采用key&#x3D;”id”方法，那么每次更改页面时，都会加载具有完全不同 ID 的全新项目集。这意味着 React 将无法找到任何“现有”项目，卸载整个列表，并安装全新的项目集。但！如果你采用key&#x3D;”index”这种方法，React 会认为新“页面”上的所有项目都已经存在，并且只会用新数据更新这些项目，而实际组件会被挂载。\n","categories":["React"]},{"title":"React typescript cheatsheet","url":"/blog/React-typescript-cheatsheet/","content":"React Typescript Cheetsheet\nJSX.Element vs React.ReactNode\njsx.element -&gt; React.createElement 的返回值\nReact.ReactNode -&gt; ​ 组件返回值的集合 ​\n\ninterface or type?使用 Interface 直到你需要 Type\n\n在编写库或第 3 方环境类型定义时，始终 interface 用于公共 API 的定义，因为这允许消费者在缺少某些定义时通过声明合并来扩展它们。\n在你的 React 组件 Props 和 State 使用 Type，以保持一致性并且因为它受到更多限制。\n\ncustom hooksimport &#123; useState &#125; from &quot;react&quot;;export function useLoading() &#123;  const [isLoading, setState] = useState(false);  const load = (aPromise: Promise&lt;any&gt;) =&gt; &#123;    setState(true);    return aPromise.finally(() =&gt; setState(false));  &#125;;  return [isLoading, load] as const; // infers [boolean, typeof load] instead of (boolean | typeof load)[]&#125;\n\n当你解构时，你会在解构的位置获取正确的类型或者编写一个自动类型推断的函数\n// 这个函数仅仅为了让TS自动推断参数类型function tuplify&lt;T extends any[]&gt;(...elements: T) &#123;  return elements;&#125;function useArray() &#123;  const numberValue = useRef(3).current;  const functionValue = useRef(() =&gt; &#123;&#125;).current;  return [numberValue, functionValue]; // type is (number | (() =&gt; void))[]&#125;function useTuple() &#123;  const numberValue = useRef(3).current;  const functionValue = useRef(() =&gt; &#123;&#125;).current;  return tuplify(numberValue, functionValue); // type is [number, () =&gt; void]&#125;\n\nclass Componenttype MyProps = &#123;  // using `interface` is also ok  message: string,&#125;;type MyState = &#123;  count: number, // like this&#125;;class App extends React.Component&lt;MyProps, MyState&gt; &#123;  state: MyState = &#123;    // optional second annotation for better type inference    count: 0,  &#125;;  render() &#123;    return (      &lt;div&gt;        &#123;this.props.message&#125; &#123;this.state.count&#125;      &lt;/div&gt;    );  &#125;&#125;\n\n为什么要注释两次 state？对类属性进行注释不是必要的，但它允许在访问 this.state 和初始化状态时更好地进行类型推断。注释以两种不同的方式工作，第二个泛型类型参数将允许 this.setState() 正常工作，因为该方法来自基类，但 state 在组件内部初始化时可能会覆盖基类的实现，因此您必须确保告诉编译器你实际上并没有做任何不同的事情。不需要添加 readonly\ntype MyProps = &#123;  readonly message: string;&#125;;type MyState = &#123;  readonly count: number;&#125;;\n\nReact.Component&lt;P,S&gt; 已经默认标记它们为不可变。\n","categories":["React"]},{"title":"React中海量数据加载","url":"/blog/React%E4%B8%AD%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD/","content":"对于项目中大量数据通常存在两种情况：\n第一种就是数据可视化，比如像热力图，地图，大量的数据点位的情况。\n第二种情况是长列表渲染。\n\n1.时间分片不使用分片\n.circle &#123;  position: absolute;  width: 10px;  height: 10px;  border-radius: 50%;&#125;.box &#123;  width: 100vm;  height: 100vh;&#125;\n\nimport &#123; useEffect, useMemo, useRef, useState &#125; from &quot;react&quot;;import &quot;./index.css&quot;;/* 获取随机颜色 */function getColor() &#123;  const r = Math.floor(Math.random() * 255);  const g = Math.floor(Math.random() * 255);  const b = Math.floor(Math.random() * 255);  return &quot;rgba(&quot; + r + &quot;,&quot; + g + &quot;,&quot; + b + &quot;,0.8)&quot;;&#125;/* 获取随机位置 */function getPostion(position) &#123;  const &#123; width, height &#125; = position;  return &#123;    left: Math.ceil(Math.random() * width) + &quot;px&quot;,    top: Math.ceil(Math.random() * height) + &quot;px&quot;,  &#125;;&#125;function Circle(&#123; position &#125;) &#123;  const style = useMemo(() =&gt; &#123;    return &#123;      background: getColor(),      ...getPostion(position),    &#125;;  &#125;, [position]);  return &lt;div style=&#123;style&#125; className=&quot;circle&quot;&gt;&lt;/div&gt;;&#125;function Box() &#123;  const [state, setState] = useState(&#123;    dataList: [],    renderList: [],    position: &#123; width: 0, height: 0 &#125;,  &#125;);  const boxRef = useRef(null);  useEffect(() =&gt; &#123;    if (!boxRef.current) &#123;      return;    &#125;    const &#123; offsetHeight, offsetWidth &#125; = boxRef.current;    const originList = Array.from(&#123; length: 20000 &#125;);    setState(&#123;      position: &#123; height: offsetHeight, width: offsetWidth &#125;,      dataList: originList,      renderList: originList,    &#125;);  &#125;, []);  return (    &lt;div className=&quot;box&quot; ref=&#123;boxRef&#125;&gt;      &#123;state.renderList.map((item, index) =&gt; (        &lt;Circle position=&#123;state.position&#125; key=&#123;item + index + &quot;&quot;&#125; /&gt;      ))&#125;    &lt;/div&gt;  );&#125;export default function Index() &#123;  const [show, setShow] = useState(false);  return (    &lt;div      style=&#123;&#123;        width: &quot;100%&quot;,        height: &quot;100%&quot;,      &#125;&#125;    &gt;      &lt;button onClick=&#123;() =&gt; setShow(true)&#125;&gt;show&lt;/button&gt;      &#123;show &amp;&amp; &lt;Box /&gt;&#125;    &lt;/div&gt;  );&#125;\n\n效果：\n​​\n时间分片// 修改box文件class Box extends React.Component &#123;  state = &#123;    dataList: [], //数据源列表    renderList: [], //渲染列表    position: &#123; width: 0, height: 0 &#125;, // 位置信息    chunk: 500, // 每次渲染数量  &#125;;  box = React.createRef&lt;HTMLDivElement&gt;();  componentDidMount() &#123;    const &#123; offsetHeight, offsetWidth &#125; = this.box.current;    const originList = Array.from(&#123; length: 20000 &#125;);    /* 计算需要渲染此次数*/    const times = Math.ceil(      originList.length / this.state.chunk    );    let index = 1;    this.setState(      &#123;        dataList: originList,        position: &#123; height: offsetHeight, width: offsetWidth &#125;,      &#125;,      () =&gt; &#123;        this.toRenderList(index, times);      &#125;    );  &#125;  toRenderList = (index, times) =&gt; &#123;    if (index &gt; times) return; /* 如果渲染完成，那么退出 */    const &#123; renderList &#125; = this.state;    /* 通过缓存element把所有渲染完成的list缓存下来，下一次更新，直接跳过渲染 */    renderList.push(this.renderNewList(index));    this.setState(&#123;      renderList,    &#125;);    /* 用 requestIdleCallback 代替 setTimeout 浏览器空闲执行下一批渲染 */    requestIdleCallback(() =&gt; &#123;      this.toRenderList(++index, times);    &#125;);  &#125;;  renderNewList(index) &#123;    /* 得到最新的渲染列表 */    const &#123; dataList, position, chunk &#125; = this.state;    const list = dataList.slice((index - 1) * chunk, index * chunk);    return (      &lt;React.Fragment key=&#123;index&#125;&gt;        &#123;list.map((item, index) =&gt; (          &lt;Circle key=&#123;index&#125; position=&#123;position&#125; /&gt;        ))&#125;      &lt;/React.Fragment&gt;    );  &#125;  render() &#123;    return (      &lt;div className=&quot;box&quot; ref=&#123;this.box&#125;&gt;        &#123;this.state.renderList&#125;      &lt;/div&gt;    );  &#125;&#125;\n\n效果：\n​​\n虚拟列表​​\n\n视图区：视图区就是能够直观看到的列表区，此时的元素都是真实的 DOM 元素。\n缓冲区：缓冲区是为了防止用户上滑或者下滑过程中，出现白屏等效果。（缓冲区和视图区为渲染真实的 DOM ）\n虚拟区：对于用户看不见的区域（除了缓冲区），剩下的区域，不需要渲染真实的 DOM 元素。虚拟列表就是通过这个方式来减少页面上 DOM 元素的数量。\n\nexport default function VirtualList() &#123;  const [dataList, setDataList] = useState([]);  /* 截取缓冲区 + 视图区索引 */  const [position, setPosition] = useState([0, 0]);  const scroll = useRef(null);  const box = useRef(null);  /* 用于移动视图区域，形成滑动效果。 */  const context = useRef(null);  const scrollInfo = useRef(&#123;    height: 500 /* 容器高度 */,    bufferCount: 8 /* 缓冲区个数 */,    itemHeight: 60 /* 每一个item高度 */,    renderCount: 0 /* 渲染区个数 */,  &#125;);  useEffect(() =&gt; &#123;    if (!box.current) return;    const height = box.current.offsetHeight;    const &#123; itemHeight, bufferCount &#125; = scrollInfo.current;    const renderCount = Math.ceil(height / itemHeight) + bufferCount;    scrollInfo.current = &#123; renderCount, height, bufferCount, itemHeight &#125;;    const dataList = Array.from(&#123; length: 5000 &#125;).map((_, index) =&gt; index + 1);    setDataList(dataList);    setPosition([0, renderCount]);  &#125;, []);  const handleScroll = () =&gt; &#123;    const &#123; scrollTop &#125; = scroll.current;    const &#123; itemHeight, renderCount &#125; = scrollInfo.current;    const currentOffset = scrollTop - (scrollTop % itemHeight);    const start = Math.floor(scrollTop / itemHeight);    context.current.style.transform = `translate3d(0, $&#123;currentOffset&#125;px, 0)`; /* 偏移，造成下滑效果 */    const end = Math.floor(scrollTop / itemHeight + renderCount + 1);    /* 如果render内容发生改变，那么截取  */    if (end !== position[1] || start !== position[0]) &#123;      setPosition([start, end]);    &#125;  &#125;;  const &#123; itemHeight, height &#125; = scrollInfo.current;  const [start, end] = position;  /* 渲染区间 */  const renderList = dataList.slice(start, end);  console.log(&quot;渲染区间&quot;, position);  return (    &lt;div className=&quot;list_box&quot; ref=&#123;box&#125;&gt;      &lt;div        className=&quot;scroll_box&quot;        style=&#123;&#123; height: height + &quot;px&quot; &#125;&#125;        onScroll=&#123;handleScroll&#125;        ref=&#123;scroll&#125;      &gt;        &lt;div          className=&quot;scroll_hold&quot;          style=&#123;&#123; height: `$&#123;dataList.length * itemHeight&#125;px` &#125;&#125;        /&gt;        &lt;div className=&quot;context&quot; ref=&#123;context&#125;&gt;          &#123;renderList.map((item, index) =&gt; (            &lt;div className=&quot;list&quot; key=&#123;index&#125;&gt;              &#123;`$&#123;item&#125; Item`&#125;            &lt;/div&gt;          ))&#125;        &lt;/div&gt;      &lt;/div&gt;    &lt;/div&gt;  );&#125;\n\n.list_box &#123;  width: 500px;  height: 500px;&#125;.list_box .scroll_box &#123;  width: 500px;  position: relative;  overflow-y: scroll;&#125;.list &#123;  height: 40px;  width: calc(100% - 50px);  padding-left: 23px;  margin: 5px;  text-align: left;  line-height: 40px;  background-color: salmon;  border-radius: 40px;  color: white;  font-weight: bolder;&#125;.context &#123;  position: absolute;  top: 0;  width: 400px;&#125;\n\n效果：\n​\n‍\n","categories":["React"]},{"title":"React的diff","url":"/blog/React%E7%9A%84diff/","content":"React 的 diff一个DOM节点在某一时刻最多会有 4 个节点和它相关。\n\ncurrent Fiber。如果该DOM节点已在页面中，current Fiber代表该DOM节点对应的Fiber节点。\nworkInProgress Fiber。如果该DOM节点将在本次更新中渲染到页面中，workInProgress Fiber代表该DOM节点对应的Fiber节点。\nDOM节点本身。\nJSX对象。即ClassComponent的render方法的返回结果，或FunctionComponent的调用结果。JSX对象中包含描述DOM节点的信息。\n\nDiff算法的本质是对比 1 和 4，生成 2\ndiff 算法的优化由于 diff 算法本身会带来性能损耗，前后两颗树完全比对的算法复杂度为 O(n3)，其中 n 是树中元素的的数量。\n为了降低算法复杂度，React的diff会预设三个限制：\n\n只对同级元素进行Diff。如果一个DOM节点在前后两次更新中跨越了层级，那么React不会尝试复用他。\n两个不同类型的元素会产生出不同的树。如果元素由div变为p，React 会销毁div及其子孙节点，并新建p及其子孙节点。\n开发者可以通过  key prop来暗示哪些子元素在不同的渲染下能保持稳定。\n\n考虑如下例子：\n// 更新前&lt;div&gt;  &lt;p key=&quot;ran&quot;&gt;ran&lt;/p&gt;  &lt;h1 key=&quot;xiu&quot;&gt;xiu&lt;/h1&gt;&lt;/div&gt;// 更新后&lt;div&gt;  &lt;h1 key=&quot;xiu&quot;&gt;xiu&lt;/h1&gt;  &lt;p key=&quot;ran&quot;&gt;ran&lt;/p&gt;&lt;/div&gt;\n\n如果没有key，React会认为div的第一个子节点由p变为h1，第二个子节点由h1变为p。这符合限制 2 的设定，会销毁并新建。\n但是当我们用key指明了节点前后对应关系后，React知道key === &quot;ran&quot;的p在更新后还存在，所以DOM节点可以复用，只是需要交换下顺序。\nreconcileChildFibers 函数会根据不同的 newChild（JSX 对象）调用不同的处理函数。\n单节点 diff当 newChild 类型为 object、number、string，代表同级只有一个节点。\n\n先判断 key 是否相同，然后 type，都相同时 DOM 才能复用。\n当 child !&#x3D;&#x3D; null 且 key 相同且 type 不同时，执行 deleteRemainingChildren 将 child 及其兄弟 fiber 都标记删除。\n当 child !&#x3D;&#x3D; null 且 key 不同时，仅将 child 标记删除。\n\n关于 2，3 步，当 key 相同但 type 不同，说明已经完全无法复用了，都需要删除。但 key 不同只代表该 fiber 不能复用，后面的兄弟 fiber 还有复用的可能性。\n多节点 diff当 newChild 类型为 Array，同级有多个节点。\n多节点 diff 有多种情况需要处理\n1. 节点更新节点更新又包含两种情况：\n&lt;div&gt;  &lt;p key=&quot;p&quot;&gt;&lt;/p&gt;&lt;/div&gt;// 属性变化&lt;div&gt;  &lt;p key=&quot;p&quot; className=&quot;p&quot;&gt;&lt;/p&gt;&lt;/div&gt;// 类型变化&lt;div&gt;  &lt;h1 key=&quot;p&quot; className=&quot;p&quot;&gt;&lt;/h1&gt;&lt;/div&gt;\n\n2. 节点新增或删除&lt;div&gt;  &lt;p key=&quot;1&quot;&gt;1&lt;/p&gt;  &lt;p key=&quot;2&quot;&gt;2&lt;/p&gt;&lt;/div&gt;// 新增&lt;div&gt;  &lt;p key=&quot;1&quot;&gt;1&lt;/p&gt;  &lt;p key=&quot;2&quot;&gt;2&lt;/p&gt;  &lt;p key=&quot;3&quot;&gt;3&lt;/p&gt;&lt;/div&gt;//删除&lt;div&gt;  &lt;p key=&quot;1&quot;&gt;1&lt;/p&gt;&lt;/div&gt;\n\n3. 节点位置变化&lt;div&gt;  &lt;p key=&quot;1&quot;&gt;1&lt;/p&gt;  &lt;p key=&quot;2&quot;&gt;2&lt;/p&gt;&lt;/div&gt;//&lt;div&gt;  &lt;p key=&quot;2&quot;&gt;2&lt;/p&gt;  &lt;p key=&quot;1&quot;&gt;1&lt;/p&gt;&lt;/div&gt;\n\n不同的情况执行不同的逻辑，React 团队发现更新比其他两种的频率更高，于是 diff 优先判断更新情况。又因为 fiber 是单链表结构的，所以无法使用双指针优化遍历。diff 会经过两轮遍历：\n\n第一轮：处理更新节点。\n第二轮：处理不为更新的节点。\n\nReact 中触发更新除了 SSR 相关，触发更新的方法：\n\nReactDOM.render\nthis.setState\nthis.forceUpdate\nuseState\nuseReducer\n\n调度更新render 阶段从 rootFiber 开始向下遍历，触发更新的 fiber 调用 markUpdateLaneFromFiberToRoot 一直向上遍历到 rootFiber 并返回 rootFiber。触发更新的 fiber 中保存了一个 Update 的对象。\n之后通知 Scheduler 根据更新的优先级，决定以同步还是异步的方式调度本次更新。\n高优更新中断正在进行中的低优更新，先完成render - commit流程。\n待高优更新完成后，低优更新基于高优更新的结果重新更新。\n","categories":["进阶"],"tags":["js","react"]},{"title":"better-scroll结合vue遇到图片引起的问题","url":"/blog/better-scroll%E7%BB%93%E5%90%88vue%E9%81%87%E5%88%B0%E5%9B%BE%E7%89%87%E5%BC%95%E8%B5%B7%E7%9A%84%E9%97%AE%E9%A2%98/","content":"使用better-scroll遇到的问题原来项目中只使用了better-scroll来做轮播图和滑动组件，但是头部和标签栏是固定的，只滑动下面部分，于是设置 scroll-warpper样式如下：\n.scroll-wrapper &#123;  position: absolute;  top: 80px;  left: 0;  right: 0;  bottom: 0;&#125;\n但是想要实现下部组件与上部标签的联动，仅仅靠better-scroll就不够了，于是项目中按需引入了vant的的标签组件，来实现移动端的左右滑动（不得不说，封装好的东西就是香）。紧接着就产生了问题，\n\n一是：下部组件无法滑动，\n二是：better-scroll滑不到底部，只能滑一部分。刷新页面后可以滑动了\n\n分析问题：\n\n查看dom发现vant的content__wrap没有高度，而scroll-warpper和内容高度一致。这是由于content__wrap的定位是relative，而scroll-wrapper是相对于content__wrap而定位的，并不是相对整个页面定位，所有内容是被里面撑开的。\n页面中有大量图片，当dom加载完成后图片并没有加载完成，scroll已经初始化了，所以滑不到底部。刷新页面可以滑动是因为图片已经被浏览器缓存了，刷新直接拿到图片不需要重新请求。\n\n解决问题：\n\n第一个问题是定位的原因，那我们把wrapper的高度写死就好了，  但是由于头部和标签是自适应的，高度是不确定的，就没法写死了。使用动态获取设置wrapper的style：\n\nsetScrollWrapperHeight() &#123;      this.$refs.scroll.$el.style.height =        window.innerHeight - this.topHeight + &#x27;px&#x27;    &#125;,\n\n由于多个页面都需要这个配置，放到mixin中，在mounted方法中调用此方法。解决wrapper高度问题。\n第二个问题是图片加载时content的高度设置错误问题，可以通过img的load方法判断图片是否加载完成。 子组件：\n\n imgAllLoad() &#123;      const mulitImg = document.querySelectorAll(&#x27;.suggest-item-img&#x27;)      const promiseAll = []      const imgTotal = mulitImg.length      for (let i = 0; i &lt; imgTotal; i++) &#123;        promiseAll[i] = new Promise((resolve, reject) =&gt; &#123;          mulitImg[i].onload = function () &#123;            // 第i张加载完成            resolve(mulitImg[i])          &#125;        &#125;)      &#125;      return promiseAll    &#125;,\n在子组件mounted中：派发一个imgLoad方法\nPromise.all(this.imgAllLoad()).then(() =&gt; &#123;      this.$emit(&#x27;imgLoad&#x27;)    &#125;)\n在父组件监听此方法，并刷新scroll组件\nmethods: &#123;    imgLoad() &#123;      this.$refs.scroll.refresh()    &#125;  &#125;,\n这样体验就不错了。\n","categories":["vue"]},{"title":"express三大概念","url":"/blog/express%E4%B8%89%E5%A4%A7%E6%A6%82%E5%BF%B5/","content":"Express 三大基础概念中间件中间件是一个函数，在请求和响应周期中被顺序调用\nconst myLogger = function(req, res, next) &#123;  console.log(&#x27;myLogger&#x27;)  next()&#125;app.use(myLogger)\n提示：中间件需要在响应结束前被调用\n路由应用如何响应请求的一种规则响应 &#x2F; 路径的 get 请求：\napp.get(&#x27;/&#x27;, function(req, res) &#123;  res.send(&#x27;hello node&#x27;)&#125;)\n响应 &#x2F; 路径的 post 请求：\napp.post(&#x27;/&#x27;, function(req, res) &#123;  res.send(&#x27;hello node&#x27;)&#125;)\n规则主要分两部分：\n\n请求方法：get、post……\n请求的路径：&#x2F;、&#x2F;user、&#x2F;.*fly$&#x2F;……\n\n异常处理通过自定义异常处理中间件处理请求中产生的异常\napp.get(&#x27;/&#x27;, function(req, res) &#123;  throw new Error(&#x27;something has error...&#x27;)&#125;)const errorHandler = function (err, req, res, next) &#123;  console.log(&#x27;errorHandler...&#x27;)  res.status(500).json(&#123;    error:&#x27;Error...&#x27;  &#125;)&#125;app.use(errorHandler)\n使用时需要注意两点：\n\n第一，参数一个不能少，否则会视为普通的中间件\n第二，中间件需要在请求之后引用\n\n","categories":["后端"],"tags":["express"]},{"title":"dL／dz 的推导","url":"/blog/dL%EF%BC%8Fdz%20%E7%9A%84%E6%8E%A8%E5%AF%BC/","content":"🎯 目标　　推导在二分类逻辑回归（使用 sigmoid 激活函数 + 交叉熵损失）中，损失函数 $L$ 对线性输出 $z$ 的导数：\n$$\\frac{dL}{dz} &#x3D; a - y$$\n　　其中：\n\n$a &#x3D; \\sigma(z)$ 是 sigmoid 激活输出，\n$y \\in {0,1}$ 是真实标签，\n$L &#x3D; -\\big[y \\log(a) + (1 - y)\\log(1 - a)\\big]$ 是二元交叉熵损失。\n\n\n🔗 推导步骤（使用链式法则）　　根据链式法则：\n$$\\frac{dL}{dz} &#x3D; \\frac{dL}{da} \\cdot \\frac{da}{dz}$$\n第一步：计算 $\\frac{dL}{da}$　　损失函数：\n$$L &#x3D; -\\big( y \\log a + (1 - y) \\log(1 - a) \\big)$$\n　　对 $a$ 求导：\n$$\\frac{dL}{da} &#x3D; -\\left( \\frac{y}{a} - \\frac{1 - y}{1 - a} \\right) &#x3D; \\frac{-y}{a} + \\frac{1 - y}{1 - a}$$\n　　通分后化简：\n$$\\frac{dL}{da} &#x3D; \\frac{a - y}{a(1 - a)}$$\n第二步：计算 $\\frac{da}{dz}$　　因为 $a &#x3D; \\sigma(z)$，而 sigmoid 函数的导数为：\n$$\\frac{d}{dz} \\sigma(z) &#x3D; \\sigma(z)(1 - \\sigma(z)) &#x3D; a(1 - a)$$\n　　所以：\n$$\\frac{da}{dz} &#x3D; a(1 - a)$$\n第三步：相乘得到 $\\frac{dL}{dz}$$$\\frac{dL}{dz} &#x3D; \\frac{a - y}{a(1 - a)} \\cdot a(1 - a) &#x3D; a - y$$\n　　✅ 最终结果：\n$$\\boxed{\\frac{dL}{dz} &#x3D; a - y}$$\n\n💡 补充说明\n在 Andrew Ng 的课程中，常将 $\\frac{dL}{dz}$ 简记为 ​dz​​，因此你会看到代码或笔记中写成 dz = a - y。\n这个简洁的结果是 sigmoid + 交叉熵损失 组合的一个重要优点——梯度形式简单，训练更稳定。\n\n","categories":["神经网络与深度学习"]},{"title":"requestAnimationFrame思考","url":"/blog/requestAnimationFrame%E6%80%9D%E8%80%83/","content":"关于setTimeout首先要明白，setTimeout 的执行只是在内存中对元素属性进行改变，这个变化必须要等到屏幕下次绘制时才会被更新到屏幕上。如果两者的步调不一致，就可能会导致中间某一帧的操作被跨越过去，而直接更新下一帧的元素。假设屏幕每隔16.7ms刷新一次，而setTimeout 每隔10ms设置图像向左移动1px， 就会出现如下绘制过程（表格）：\n\n第    0  ms：屏幕未绘制，  等待中，setTimeout 也未执行，等待中；\n第   10 ms：屏幕未绘制，等待中，setTimeout 开始执行并设置元素属性 left&#x3D;1px；\n第 16.7 ms：屏幕开始绘制，屏幕上的元素向左移动了 1px， setTimeout 未执行，继续等待中；\n第   20 ms：屏幕未绘制，等待中，setTimeout 开始执行并设置 left&#x3D;2px;\n第   30 ms：屏幕未绘制，等待中，setTimeout 开始执行并设置 left&#x3D;3px;\n第33.4 ms：屏幕开始绘制，屏幕上的元素向左移动了 3px， setTimeout 未执行，继续等待中；…\n\n从上面的绘制过程中可以看出，屏幕没有更新 left&#x3D;2px 的那一帧画面，元素直接从left&#x3D;1px 的位置跳到了 left&#x3D;3px 的的位置，这就是丢帧现象，这种现象就会引起动画卡顿。\n关于requestAnimationFrame与 setTimeout 相比，rAF 最大的优势是 由系统来决定回调函数的执行时机。具体一点讲就是，系统每次绘制之前会主动调用 rAF 中的回调函数，如果系统绘制率是 60Hz，那么回调函数就每16.7ms 被执行一次，如果绘制频率是75Hz，那么这个间隔时间就变成了 1000&#x2F;75&#x3D;13.3ms。换句话说就是，rAF 的执行步伐跟着系统的绘制频率走。它能保证回调函数在屏幕每一次的绘制间隔中只被执行一次，这样就不会引起丢帧现象，也不会导致动画出现卡顿的问题。\n但是rAF并不能保证每次绘制都会执行,如果有个计算任务执行了  20ms，那么再一次回调会在 16.7 * 3 ms时执行，跳过了一次绘制。16.7+20 &#x3D; 36.7，36.7+16.7 &#x3D; 53.4， 16.7 * 3 &#x3D; 50.1, 50.1&lt;53.4\nrAF的优势\nCPU节能：使用 setTimeout 实现的动画，当页面被隐藏或最小化时，setTimeout 仍然在后台执行动画任务，由于此时页面处于不可见或不可用状态，刷新动画是没有意义的，而且还浪费 CPU 资源。而 rAF 则完全不同，当页面处理未激活的状态下，该页面的屏幕绘制任务也会被系统暂停，因此跟着系统步伐走的 rAF 也会停止渲染，当页面被激活时，动画就从上次停留的地方继续执行，有效节省了 CPU 开销。像是埋点也可以使用这个特性，当页面不可见时，不需要上报埋点，等页面可见时再上报。\n\n函数节流：在高频率事件(resize,scroll 等)中，为了防止在一个刷新间隔内发生多次函数执行，使用 rAF 可保证每个绘制间隔内，函数只被执行一次，这样既能保证流畅性，也能更好的节省函数执行的开销。一个绘制间隔内函数执行多次时没有意义的，因为显示器每16.7ms 绘制一次，多次绘制并不会在屏幕上体现出来。\n\n\n","categories":["js"]},{"title":"js语法细节","url":"/blog/js%E8%AF%AD%E6%B3%95%E7%BB%86%E8%8A%82/","content":"箭头函数中的this它们没有 this。在箭头函数内部访问到的 this 都是从外部获取的。\n可选链\n通常我们这样写\n\nlet user = &#123;&#125;; // user 没有 addressalert( user &amp;&amp; user.address &amp;&amp; user.address.street ); // undefined（不报错）\n依次对整条路径上的属性使用与运算进行判断，以确保所有节点是存在的（如果不存在，则停止计算），但是写起来很麻烦。\n\n通过可选链可以这样\n\nlet user = null;alert( user?.address ); // undefinedalert( user?.address.street ); // undefined\n\n不要过度使用可选链\n\n\n我们应该只将 ?. 使用在一些东西可以不存在的地方。例如，如果根据我们的代码逻辑，user 对象必须存在，但 address 是可选的，那么 user.address?.street 会更好。所以，如果 user 恰巧因为失误变为 undefined，我们会看到一个编程错误并修复它。否则，代码中的错误在不恰当的地方被消除了，这会导致调试更加困难。\n\n### 总结可选链 ?. 语法有三种形式：- obj?.prop —— 如果 obj 存在则返回 obj.prop，否则返回 undefined。- obj?.[prop] —— 如果 obj 存在则返回 obj[prop]，否则返回 undefined。- obj.method?.() —— 如果 obj.method 存在则调用 obj.method()，否则返回 undefined。&gt;正如我们所看到的，这些语法形式用起来都很简单直接。?. 检查左边部分是否为 null/undefined，如果不是则继续运算。?. 链使我们能够安全地访问嵌套属性。&gt;但是，我们应该谨慎地使用 ?.，仅在当左边部分不存在也没问题的情况下使用为宜。以保证在代码中有编程上的错误出现时，也不会对我们隐藏。## Symbol如果我们要在对象字面量 &#123;...&#125; 中使用 Symbol，则需要使用方括号把它括起来。就像这样：```jslet id = Symbol(&quot;id&quot;);let user = &#123;  name: &quot;John&quot;,  [id]: 123 // 而不是 &quot;id&quot;：123&#125;;\n这是因为我们需要变量 id 的值作为键，而不是字符串 “id”。\n\nSymbol 属性不参与 for..in 循环。\n\n\nObject.assign 会同时复制字符串和 symbol 属性\n\n\n参考：symbol\n\n对象原始值的转换如果没有 Symbol.toPrimitive，那么 JavaScript 将尝试找到它们，并且按照下面的顺序进行尝试：\n\n对于 “string” hint，toString -&gt; valueOf。\n其他情况，valueOf -&gt; toString。\n\n默认情况下，普通对象具有 toString 和 valueOf 方法：\n\ntoString 方法返回一个字符串 “[object Object]”。\nvalueOf 方法返回对象自身。\n如果没有 Symbol.toPrimitive 和 valueOf，toString 将处理所有原始转换。\n\n总结对象到原始值的转换，是由许多期望以原始值作为值的内建函数和运算符自动调用的。\n这里有三种类型（hint）：\n\n“string”（对于 alert 和其他需要字符串的操作）\n“number”（对于数学运算）\n“default”（少数运算符）规范明确描述了哪个运算符使用哪个 hint。很少有运算符“不知道期望什么”并使用 “default” hint。通常对于内建对象，”default” hint 的处理方式与 “number” 相同，因此在实践中，最后两个 hint 常常合并在一起。\n\n转换算法是：\n1.调用 objSymbol.toPrimitive 如果这个方法存在，\n2.否则，如果 hint 是 “string”\n\n尝试 obj.toString() 和 obj.valueOf()，无论哪个存在。\n\n3.否则，如果 hint 是 “number” 或者 “default”\n\n尝试 obj.valueOf() 和 obj.toString()，无论哪个存在。在实践中，为了便于进行日志记录或调试，对于所有能够返回一种“可读性好”的对象的表达形式的转换，只实现以 obj.toString() 作为全能转换的方法就够了。\n\n\n参考 Symbol.toPrimitive\n\n关于数组的length当我们修改数组的时候，length 属性会自动更新。准确来说，它实际上不是数组里元素的个数，而是最大的数字索引值加一。\n例如，一个数组只有一个元素，但是这个元素的索引值很大，那么这个数组的 length 也会很大：\nlet fruits = [];fruits[123] = &quot;Apple&quot;;alert( fruits.length ); // 124\n要知道的是我们通常不会这样使用数组。\nlength 属性的另一个有意思的点是它是可写的。\n如果我们手动增加它，则不会发生任何有趣的事儿。但是如果我们减少它，数组就会被截断。该过程是不可逆的，下面是例子：\nlet arr = [1, 2, 3, 4, 5];arr.length = 2; // 截断到只剩 2 个元素alert( arr ); // [1, 2]arr.length = 5; // 又把 length 加回来alert( arr[3] ); // undefined：被截断的那些数值并没有回来\n\n所以，清空数组最简单的方法就是：arr.length &#x3D; 0;\n\n关于JSON的转换JSON 是语言无关的纯数据规范，因此一些特定于 JavaScript 的对象属性会被 JSON.stringify 跳过。\n即：\n\n函数属性（方法）。\nSymbol 类型的属性。\n存储 undefined 的属性。\n\njs中函数就是对象\n被赋值给函数的属性，比如 sayHi.counter &#x3D; 0，不会 在函数内定义一个局部变量 counter。换句话说，属性 counter 和变量 let counter 是毫不相关的两个东西。\n\n\n我们可以把函数当作对象，在它里面存储属性，但是这对它的执行没有任何影响。变量不是函数属性，反之亦然。它们之间是平行的。\n\n关于this和箭头函数箭头函数\n\n没有 this\n没有 arguments\n不能使用 new 进行调用\n它们也没有 super\n\n所以箭头函数里的 this 的查找与常规变量的搜索方式完全相同：在外部词法环境中查找。\n关于__proto__和prototype\n初学者常犯一个普遍的错误，就是不知道 __proto__ 和 [[Prototype]] 的区别。请注意，__proto__ 与内部的 [[Prototype]] 不一样。__proto__ 是 [[Prototype]] 的 getter&#x2F;setter。稍后，我们将看到在什么情况下理解它们很重要，在建立对 JavaScript 语言的理解时，让我们牢记这一点。\n\n属性有点过时了。它的存在是出于历史的原因，现代编程语言建议我们应该使用函数 Object.getPrototypeOf/Object.setPrototypeOf 来取代 ```__proto__``` 去 get/set 原型。稍后我们将介绍这些函数。根据规范，```__proto__``` 必须仅受浏览器环境的支持。但实际上，包括服务端在内的所有环境都支持它，因此我们使用它是非常安全的。重要：[this的值](https://zh.javascript.info/prototype-inheritance#this-de-zhi)### 设置和直接访问原型的现代方法设置和直接访问原型的现代方法有：- Object.create(proto, [descriptors]) —— 利用给定的 proto 作为 [[Prototype]]（可以是 null）和可选的属性描述来创建一个空对象。- Object.getPrototypeOf(obj) —— 返回对象 obj 的 [[Prototype]]（与 ```__proto__``` 的 getter 相同）。- Object.setPrototypeOf(obj, proto) —— 将对象 obj 的 [[Prototype]] 设置为 proto（与 ```__proto__``` 的 setter 相同）。如果要将一个用户生成的键放入一个对象，那么内建的 ```__proto__``` getter/setter 是不安全的。因为用户可能会输入 &quot;```__proto__```&quot; 作为键，这会导致一个 error，虽然我们希望这个问题不会造成什么大影响，但通常会造成不可预料的后果。因此，我们可以使用 Object.create(null) 创建一个没有 ```__proto__``` 的 “very plain” 对象，或者对此类场景坚持使用 Map 对象就可以了。此外，Object.create 提供了一种简单的方式来浅拷贝一个对象的所有描述符：```jslet clone = Object.create(Object.getPrototypeOf(obj), Object.getOwnPropertyDescriptors(obj));\n\n此外，我们还明确了 __proto__ 是 [[Prototype]] 的 getter&#x2F;setter，就像其他方法一样，它位于 Object.prototype。\n我们可以通过 Object.create(null) 来创建没有原型的对象。这样的对象被用作 “pure dictionaries”，对于它们而言，使用 “__proto__“ 作为键是没有问题的。\n其他方法：\n\nObject.keys(obj) &#x2F; Object.values(obj) &#x2F; Object.entries(obj) —— 返回一个可枚举的由自身的字符串属性名&#x2F;值&#x2F;键值对组成的数组。\nObject.getOwnPropertySymbols(obj) —— 返回一个由自身所有的 symbol 类型的键组成的数组。\nObject.getOwnPropertyNames(obj) —— 返回一个由自身所有的字符串键组成的数组。\nReflect.ownKeys(obj) —— 返回一个由自身所有键组成的数组。\nobj.hasOwnProperty(key)：如果 obj 拥有名为 key 的自身的属性（非继承而来的），则返回 true。\n\n所有返回对象属性的方法（如Object.keys 及其他）—— 都返回“自身”的属性。如果我们想继承它们，我们可以使用 for…in。\n关于类继承1.想要扩展一个类：class Child extends Parent：\n\n这意味着 Child.prototype.proto 将是 Parent.prototype，所以方法会被继承。\n\n2.重写一个 constructor：\n\n在使用 this 之前，我们必须在 Child 的 constructor 中将父 constructor 调用为 super()。\n\n3.重写一个方法：\n\n我们可以在一个 Child 方法中使用 super.method() 来调用 Parent 方法。\n\n4.内部：\n\n方法在内部的 [[HomeObject]] 属性中记住了它们的类&#x2F;对象。这就是 super 如何解析父方法的。\n因此，将一个带有 super 的方法从一个对象复制到另一个对象是不安全的。\n\n补充：\n箭头函数没有自己的 this 或 super，所以它们能融入到就近的上下文中，像透明似的。\n类检查”instanceof”\n\n\n\n用于\n返回值\n\n\n\ntype\n原始数据类型\nstring\n\n\n{}.toString.call\n原始数据类型，内建对象，包含Symbol.toStringTag属性的对象\nstring\n\n\ninstanceof\n对象\ntrue&#x2F;false\n\n\n如表所示：{}.toString.call (Object.prototype.toString) 可以检查对象的类型并返回字符串，而不是像toString仅仅返回 [Object,Object]\nlet s = Object.prototype.toString;alert( s.call(123) ); // [object Number]alert( s.call(null) ); // [object Null]alert( s.call(alert) ); // [object Function]\n\n模块的导入和导出\n在声明一个 class&#x2F;function&#x2F;… 之前：\nexport [default] class&#x2F;function&#x2F;variable …\n\n\n独立的导出：\nexport {x [as y], …}.\n\n\n重新导出：\nexport {x [as y], …} from “module”\nexport * from “module”（不会重新导出默认的导出）。\nexport {default [as y]} from “module”（重新导出默认的导出）。\n\n\n\n导入：\n\n模块中命名的导入：\nimport {x [as y], …} from “module”\n\n\n默认的导入：\nimport x from “module”\nimport {default as x} from “module”\n\n\n所有：\nimport * as obj from “module”\n\n\n导入模块（它的代码，并运行），但不要将其赋值给变量：\nimport “module”\n\n\n\n我们把 import&#x2F;export 语句放在脚本的顶部或底部，都没关系。\n处理程序选项 “passive”addEventListener 的可选项 passive: true 向浏览器发出信号，表明处理程序将不会调用 preventDefault()。\n为什么需要这样做？\n移动设备上会发生一些事件，例如 touchmove（当用户在屏幕上移动手指时），默认情况下会导致滚动，但是可以使用处理程序的 preventDefault() 来阻止滚动。\n因此，当浏览器检测到此类事件时，它必须首先处理所有处理程序，然后如果没有任何地方调用 preventDefault，则页面可以继续滚动。但这可能会导致 UI 中不必要的延迟和“抖动”。\npassive: true 选项告诉浏览器，处理程序不会取消滚动。然后浏览器立即滚动页面以提供最大程度的流畅体验，并通过某种方式处理事件。\n对于某些浏览器（Firefox，Chrome），默认情况下，touchstart 和 touchmove 事件的 passive 为 true。\nasync和defer\n\n\n\n顺序\nDOMContentLoaded\n\n\n\nasync\n加载优先顺序。脚本在文档中的顺序不重要 —— 先加载完成的先执行\n不相关。可能在文档加载完成前加载并执行完毕。如果脚本很小或者来自于缓存，同时文档足够长，就会发生这种情况。\n\n\ndefer\n文档顺序（它们在文档中的顺序）\n在文档加载和解析完成之后（如果需要，则会等待），即在 DOMContentLoaded 之前执行。\n\n\n","categories":["js"]},{"title":"一些Vue小技巧","url":"/blog/%E4%B8%80%E4%BA%9B%E5%B0%8F%E6%8A%80%E5%B7%A7/","content":"关于 vue.filters可以写在单个组件内，也可以单独写全局的然后加到 main.js 中，像是日期格式，数字格式就可以写在全局\n~~和！！&#126;是按位取反运算，&#126;&#126;是取反两次。&#126;&#126;的作用是去掉小数部分，因为位运算的操作值要求是整数，其结果也是整数，所以经过位运算的都会自动变成整数。！一个！是取反，！！两个再取反，就是强制转换成 Boolen 类型\n关于 markdown 语法如果要使用 Markdown 保留字，可以使用 Unicode 字符。如上面的&#126;&#126;,两边加&#126;&#126;会导致形成文字之间产生删除线，把&#126;&#126;换成&amp;#126;&amp;#126;就可以了。Unicode 在线转义\njs 和 css 两用样式template 中需要动态定义样式，通常做法：\n&lt;template&gt;  &lt;div :style=&quot;&#123; color: textColor &#125;&quot;&gt;Text&lt;/div&gt;&lt;/template&gt;&lt;script&gt;  export default &#123;    data() &#123;      return &#123;        textColor: &quot;#ff5000&quot;,      &#125;    &#125;,  &#125;&lt;/script&gt;\n\n高端做法：\n\n定义 scss 文件\n\n$menuActiveText: #409eff;:export &#123;  menuActiveText: $menuActiveText;&#125;\n\n\n在 js 中引用：\n使用 import 引用 scss 文件\n定义 computed 将 styles 对象变成响应式对象\n在 template 中使用 styles 对象\n\n\n\n&lt;template&gt;  &lt;div :style=&quot;&#123; color: styles.menuActiveText &#125;&quot;&gt;Text&lt;/div&gt;&lt;/template&gt;&lt;script&gt;  import styles from &quot;@/styles/variables.scss&quot;  export default &#123;    computed: &#123;      styles() &#123;        return styles      &#125;,    &#125;,  &#125;&lt;/script&gt;\n\n连续解构从数组第一个对象元素中提取某个属性，比如：err 对象中包含一个 errors 数组，errors 数组每一个对象都包含一个 msg 属性\nerr = &#123;  errors: [    &#123;      msg: &quot;this is a message&quot;,    &#125;,  ],&#125;\n\n快速的提取方法为：\nconst [&#123; msg &#125;] = err.errors\n\n如果不用解构写法为：\nconst msg = err.errors[0].msg\n\n真不错！\nvm.$nextTickvue 更新 DOM 是异步的，如果你想基于更新后的 DOM 状态来做点什么，为了在数据变化之后等待 Vue 完成更新 DOM，可以在数据变化之后立即使用 Vue.nextTick(callback)。这样回调函数将在 DOM 更新完成后被调用。详情参见:异步更新队列\ncolumns 分页利用 columns 实现小说分页效果，每一列的高度与父元素相同\n绝对定位居中.demo &#123;  position: absolute;  top: 0;  left: 0;  right: 0;  bottom: 0;  margin: auto;&#125;\n\n使页面的左右边距相同可以父元素加 padding：15px, 子元素加 margin：15px， 这样所有间隙都是 30px。\nmath.floor 和 | 0;(Math.floor(10 / 3) === 10 / 3) | 0\n","categories":["vue"]},{"title":"一图搞懂 Unit8Array ImageData Blob","url":"/blog/%E4%B8%80%E5%9B%BE%E6%90%9E%E6%87%82%20Unit8Array%20ImageData%20Blob/","content":"　　在做一个工具内截图的功能时发现的问题，Unit8Array 类型的数据转换成 blob 二进制数据然后上传到后端时出现错误。这里记录一下解决方法\n​Uint8Array​​ 和 ​ImageData​​ 的关系\n​​Uint8Array​​ 是一个存储 8 位无符号整数的数组，常用于表示二进制数据（如图像的像素数据）。\n​​ImageData​​ 是浏览器提供的一个专门用于表示图像数据的对象，通常用于 &lt;canvas&gt;​ 元素的图像操作。它的数据结构是一个包含像素数据的 Uint8ClampedArray​（类似于 Uint8Array​，但值会被限制在 0-255 之间）。\n\n为什么可以转换？\n​ImageData​ 的像素数据本质上是一个一维数组，每个像素由 4 个值（RGBA）表示，每个值是一个 8 位无符号整数（0-255）。\n如果 Uint8Array​ 中的数据是按照 RGBA 顺序排列的，并且长度与图像的宽度和高度匹配，那么可以直接将其转换为 ImageData​。\n\n转换示例：// 假设有一个 2x2 的图像，每个像素有 RGBA 四个通道let width = 2;let height = 2;let pixelData = new Uint8Array([    255, 0, 0, 255,   // 红色像素    0, 255, 0, 255,   // 绿色像素    0, 0, 255, 255,   // 蓝色像素    255, 255, 255, 255 // 白色像素]);// 创建 ImageData 对象let imageData = new ImageData(new Uint8ClampedArray(pixelData), width, height);console.log(imageData);\n\n​Uint8Array​​ 和 ​Blob​​ 的关系\n​​Blob​​ 是一种表示不可变二进制数据的对象，通常用于文件操作（如上传、下载）或存储任意类型的二进制数据。\n​Blob​ 的数据可以是任意格式的二进制数据（如图片、音频、视频、文本等），而不仅仅是图像数据。\n\n为什么不能直接转换？\n​Uint8Array​ 只是一个存储 8 位无符号整数的数组，它本身没有描述数据的格式或类型（例如，是图像、音频还是其他数据）。\n要将 Uint8Array​ 转换为 Blob​，需要明确指定数据的 MIME 类型（如 image/png​、application/octet-stream​ 等），以便 Blob​ 知道如何解释这些数据。\n\n如何转换为 ​Blob​​ ？　　虽然不能直接转换，但可以通过指定 MIME 类型将 Uint8Array​ 包装成 Blob​：\nlet uint8Array = new Uint8Array([72, 101, 108, 108, 111]); // &quot;Hello&quot; 的二进制数据let blob = new Blob([uint8Array], &#123; type: &#x27;application/octet-stream&#x27; &#125;); // 创建 Blobconsole.log(blob);\n\n3. 关键区别\n\n\n特性\n​ImageData​\n​Blob​\n\n\n\n用途\n专门用于表示图像像素数据\n用于表示任意类型的二进制数据\n\n\n数据结构\n必须是 RGBA 格式的像素数据\n可以是任意格式的二进制数据\n\n\nMIME 类型\n不需要指定 MIME 类型\n需要明确指定 MIME 类型\n\n\n浏览器支持\n主要用于 &lt;canvas&gt;​ 图像操作\n用于文件操作（上传、下载等）\n\n\n图像的数据类型DOM&lt;img&gt;​　　​&amp;lt;img&amp;gt;​ 元素从 URL（Data URL，HTTP URL 或 Object URL）加载图像。\n&lt;canvas&gt;​　　​&amp;lt;canvas&amp;gt;​ 元素通过 canvas API drawImage​ 来获取 &lt;img&gt;​ 元素上的图像数据。\nURLData URL　　Data URL 带有 base64 编码的图像数据。可以从 Data URL 数据中解码出图像的二进制数据。Data URL 数据的大小比原始的二进制数据大一些。\nHTTP URL　　HTTP URL 代表存储在服务器上的图像。HTTP URL 用于从服务器获取图像数据。\nObject URL　　Object URL 用来代表存储在浏览器内存中的 File​ 或 Blob​ 对象。Object URL 可以由 createObjectURL​ API 来创建，并由 revokeObjectURL​ API 释放。\n文件Blob​　　​Blob​ 是带有二进制数据的类文件对象。它包含一个只读的 size​ 属性和一个只读的 type​ 属性。你可以通过 slice​，stream​，text​ 等方法来读取二进制数据。\nFile​　　一个 File​ 对象是一个特殊的 Blob​ 对象。除了 Blob​ 的属性和方法外，File​ 对象还包含 lastModified​，name​ 等属性。\n​ImageData​　　一个 ImageData​ 对象是一个 JavaScript 对象，包含 width​，height​ 和 data​ 属性，分别表示图像宽度，高度和像素数据。 data​ 属性是一个一维数组，包含 R，G，B，A，R，G，B，A​ 这样格式的数据。每个 R，G，B，A​ 代表一个像素。可以通过 &lt;canvas&gt;​ API createImageData​ 或 ImageData​ 构造函数来创建 ImageData​。\nBufferArrayBuffer​　　​ArrayBuffer​ 是在浏览器中唯一一种访问二进制数据的方法。ArrayBuffer​ 代表图像的原始二进制数据缓冲区。我们无法读取和写入 ArrayBuffer​ ，只能将 ArrayBuffer​ 转换为 DataView​ 或 TypedArray 来读取和写入二进制数据。\nBuffer​　　​Buffer​ 是 Node.js 中特殊的一种 Uint8Array​，Node.js 对其进行了一些优化。\n在 ArrayBuffer​，DataView​，TypedArray 和 Buffer​ 之间转换​​\n在 DOM，URL，Blob(File)，ImageData​ 和 Buffer 之间转换​​\n总结：更全的一图流​"},{"title":"从代码实现方式优化性能","url":"/blog/%E4%BB%8E%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%E4%BC%98%E5%8C%96%E6%80%A7%E8%83%BD/","content":"\n使用多态代替条件判断\n\n参数传入使用平铺参数代替对象参数没有必要包裹一层对象，增加创建和 GC 开销 benchmark\n\n高频调用函数避免使用 rest&#x2F;spread 运算符,编译到 ES5 要使用循环，还要创建数组，要避免在高频场景下使用（相比正常写法相差 6 倍） benchmark，还有额外的 GC 开销\n\n手写 map 性能不如原生 benchmark\n\n局部化极高频变量， 例如原来是 o.a.b，优化后直接访问 a benchmark\n\ninstanceof 的条件判断可以用 map 优化\n\n\n// setup.js&quot;use strict&quot;;var __extends = (this &amp;&amp; this.__extends) || (function () &#123;    var extendStatics = function (d, b) &#123;        extendStatics = Object.setPrototypeOf ||            (&#123; __proto__: [] &#125; instanceof Array &amp;&amp; function (d, b) &#123; d.__proto__ = b; &#125;) ||            function (d, b) &#123; for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; &#125;;        return extendStatics(d, b);    &#125;;    return function (d, b) &#123;        if (typeof b !== &quot;function&quot; &amp;&amp; b !== null)            throw new TypeError(&quot;Class extends value &quot; + String(b) + &quot; is not a constructor or null&quot;);        extendStatics(d, b);        function __() &#123; this.constructor = d; &#125;        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());    &#125;;&#125;)();var Origin = /** @class */ (function () &#123;    function Origin() &#123;    &#125;    return Origin;&#125;());var Base = /** @class */ (function (_super) &#123;    __extends(Base, _super);    function Base() &#123;        return _super !== null &amp;&amp; _super.apply(this, arguments) || this;    &#125;    return Base;&#125;(Origin));var A = /** @class */ (function (_super) &#123;    __extends(A, _super);    function A() &#123;        return _super !== null &amp;&amp; _super.apply(this, arguments) || this;    &#125;    return A;&#125;(Base));var B = /** @class */ (function (_super) &#123;    __extends(B, _super);    function B() &#123;        return _super !== null &amp;&amp; _super.apply(this, arguments) || this;    &#125;    return B;&#125;(Base));var C = /** @class */ (function (_super) &#123;    __extends(C, _super);    function C() &#123;        return _super !== null &amp;&amp; _super.apply(this, arguments) || this;    &#125;    return C;&#125;(Base));var D = /** @class */ (function (_super) &#123;    __extends(D, _super);    function D() &#123;        return _super !== null &amp;&amp; _super.apply(this, arguments) || this;    &#125;    return D;&#125;(Base));var E = /** @class */ (function (_super) &#123;    __extends(E, _super);    function E() &#123;        return _super !== null &amp;&amp; _super.apply(this, arguments) || this;    &#125;    return E;&#125;(Base));var F = /** @class */ (function (_super) &#123;    __extends(F, _super);    function F() &#123;        return _super !== null &amp;&amp; _super.apply(this, arguments) || this;    &#125;    return F;&#125;(Base));var list = [];for (var i = 0; i &lt; 1000; i++) &#123;    list.push(new D());&#125;function a() &#123;&#125;function b() &#123;&#125;function c() &#123;&#125;function d() &#123;&#125;function e() &#123;&#125;function f() &#123;&#125;const HANDLER_BY_CONSTRUCTOR = new Map([    [A, a],    [B, b],    [C, c],    [D, d],    [E, e],    [F, f]]);function getCommonElementCreator(element) &#123;    // 对于大多数单层继承的类，使用更快的方法    if (HANDLER_BY_CONSTRUCTOR.get(element.constructor) !== undefined) &#123;        return HANDLER_BY_CONSTRUCTOR.get(element.constructor);    &#125;    // 其他情况使用循环查找    let prototype = Object.getPrototypeOf(Object.getPrototypeOf(element));    while (prototype &amp;&amp; prototype !== Base.prototype) &#123;        const elementType = HANDLER_BY_CONSTRUCTOR.get(prototype.constructor);        if (elementType !== undefined) &#123;            return elementType;        &#125;        prototype = Object.getPrototypeOf(prototype);    &#125;    return;&#125;// case 1list.forEach(function (element) &#123;    if (element instanceof A) &#123;        a();    &#125;    else if (element instanceof B) &#123;        b();    &#125;    else if (element instanceof C) &#123;        c();    &#125;    else if (element instanceof D) &#123;        d();    &#125;    else if (element instanceof E) &#123;        e();    &#125;    else if (element instanceof F) &#123;        f();    &#125;&#125;);// case 2list.forEach(function (element) &#123;    const handler = getCommonElementCreator(element);        if (handler)(        handler()    )&#125;);\n\n\nES6 的迭代器经过编译性能都很差，而且 helper 函数会创建多余的数组，造成 GC 开销。\n\n\n遍历数组: TS 编译的 for of 循环比 for 循环和 forEach 慢了 70% 和 50% benchmark\n\n多元素 push 到数组: TS 编译的比 Array.prototype.push.apply 慢了 90%，即 a.push(…b) 和 Array.prototype.push.apply(a, b) 的差别。benchmark\n\n数组拼接：[…a, …b] 比 a.concat(b) 慢了 95% benchmark\n\n数组复制：[…a] 比 a.slice() 慢了 95% benchmark\n\nSet 转换到 Array：TS 编译的比 Array.from 慢了 95%，即 […set] 和 Array.from(set) 的差别 benchmark\n\n遍历 Map: forEach 比 for of 快 50% benchmark\n\n\n\n每个源文件编译后都要加入一份 helper 函数，造成体积浪费，对 JS 引擎优化也不友好。可以开启 tsconfig 的 importHelpers 选项，将 helper 函数从每个文件中移除，放到一个单独的文件中，而且可以减少代码体积。\n\n\nimportHelpers 是 TypeScript 编译器的一个配置选项，用于优化生成的 JavaScript 代码。具体来说，当 TypeScript 进行某些向下兼容的操作（如类的扩展、数组或对象的展开、异步操作等）时，它会插入一些辅助函数。默认情况下，这些辅助函数会被插入到每个使用它们的文件中，这可能导致代码重复。通过启用 importHelpers 选项，这些辅助函数会被从 tslib 模块中导入，从而避免重复代码。\n\n","categories":["js"],"tags":["性能优化"]},{"title":"三次握手和四次挥手","url":"/blog/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/","content":"三次握手• 第一次握手([SYN], Seq &#x3D; x)客户端发送一个SYN标记的包，Seq初始序列号x，发送完成后客户端进入SYN_SEND状态。• 第二次握手([SYN,ACK], Seq &#x3D; y, ACK &#x3D; x + 1)服务器返回确认包(ACK)应答，同时还要发送一个SYN包回去。ACK &#x3D; x + 1,表示确认收到(客户端发来的Seq值 + 1)，Seq &#x3D; y, 表示让客户端确认是否能收到。发送完成后服务端进入SYN_RCVD状态。• 第三次握手([ACK], ACK &#x3D; y + 1)客户端再次发送确认包(ACK),ACK &#x3D; y + 1, 表示确认收到服务器的包（服务端发来的Seq值 + 1）。客户端发送完毕后，进入ESTABLISHED状态，服务端接收到这个包，也进入ESTABLISHED状态, TCP握手结束。\n四次挥手• 第一次挥手（[FIN], Seq &#x3D; x）客户端发送一个FIN标记的包，告诉服务器需要关闭连接，表示自己不用发送数据了，但是还可以接收数据。发送完成后，客户端进入FIN_WAIT_1状态。• 第二次挥手 ([ACK], ACK &#x3D; x + 1)服务端发送一个ACK的确认包，告诉客户端接收到关闭的请求，但是还没有准备好。发送完成后，服务端进入CLOSE_WAIT状态，客户端收到这个包后，进入FIN_WAIT_2，等待服务器关闭连接。• 第三次挥手 ([FIN], Seq &#x3D; y)服务端准备好关闭连接时，发送FIN标记的包，告诉客户端准备关闭了。发送完成后，服务端进入LAST_ACK状态，等待客户端确认。• 第四次挥手 ([ACK], ACK &#x3D; y + 1)客户端接收到服务端的关闭请求，再发送ACK标记的确认包，进入TIME_WAIT状态，等待服务端可能请求重传的ACK包。服务端接收到ACK包后，关闭连接，进入CLOSED状态。客户端在等待固定时间(两个最大段生命周期)后，没有接收到服务的ACK包，认为服务器已关闭连接，自己也关闭连接，进入CLOSED状态。\n为什么三次握手“3次握手”的作用就是双方都能明确自己和对方的收、发能力是正常的。第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。 从客户端的视角来看，我接到了服务端发送过来的响应数据包，说明服务端接收到了我在第一次握手时发送的网络包，并且成功发送了响应数据包，这就说明，服务端的接收、发送能力正常。而另一方面，我收到了服务端的响应数据包，说明我第一次发送的网络包成功到达服务端，这样，我自己的发送和接收能力也是正常的。第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力，服务端的发送、接收能力是正常的。 第一、二次握手后，服务端并不知道客户端的接收能力以及自己的发送能力是否正常。而在第三次握手时，服务端收到了客户端对第二次握手作的回应。从服务端的角度，我在第二次握手时的响应数据发送出去了，客户端接收到了。所以，我的发送能力是正常的。而客户端的接收能力也是正常的。\n为什么建立连接是三次握手，而关闭连接却是四次挥手呢？这是因为服务端在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。而关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方是否现在关闭发送数据通道，需要上层应用来决定，因此，己方ACK和FIN一般都会分开发送。\n","categories":["网络"]},{"title":"createObjectURL","url":"/blog/%E5%85%B3%E4%BA%8EcreateObjectURL/","content":"createObjectURL 是什么\nURL.createObjectURL() 静态方法会创建一个 DOMString，其中包含一个表示参数中给出的对象的 URL。这个 URL 的生命周期和创建它的窗口中的 document 绑定。这个新的 URL 对象表示指定的 File 对象或 Blob 对象。 — MDN\n\n\n\nBlob URL&#x2F;Object URLBlob URL&#x2F;Object URL 是⼀种伪协议，允许 Blob 和 File 对象⽤作图像，下载⼆进制数据链接等的 URL源。在浏览器中，我们使⽤ URL.createObjectURL ⽅法来创建 Blob URL，该⽅法接收⼀个 Blob 对象，并为其创建⼀个唯⼀的 URL，其形式为 blob:&lt;origin&gt;/&lt;uuid&gt; ，对应的示例如下：\nblob:https://example.org/40a5fb5a-d56d-4a33-b4e2-0acf6a8e5f641\n\n浏览器内部为每个通过 URL.createObjectURL ⽣成的 URL 存储了⼀个 URL → Blob 映射。因此，此类 URL 较短，但可以访问 Blob 。⽣成的 URL 仅在当前⽂档打开的状态下才有效。它允许引⽤&lt;img&gt; 、 &lt;a&gt; 中的 Blob ，但如果你访问的 Blob URL 不再存在，则会从浏览器中收到 404 错误。\n上述的 Blob URL 看似很不错，但实际上它也有副作⽤。虽然存储了 URL → Blob 的映射，但 Blob 本身仍驻留在内存中，浏览器⽆法释放它。映射在⽂档卸载时⾃动清除，因此 Blob 对象随后被释放。但是，如果应⽤程序寿命很⻓，那不会很快发⽣。因此，如果我们创建⼀个 Blob URL，即使不再需要该Blob，它也会存在内存中。\n针对这个问题，我们可以调⽤ URL.revokeObjectURL(url) ⽅法，从内部映射中删除引⽤，从⽽允许删除 Blob（如果没有其他引⽤），并释放内存。\ncreateObjectURL 可以用来做什么比如显示上传的预览图\n&lt;body&gt;  &lt;input    type=&quot;file&quot;    multiple    id=&quot;fileInput&quot;    onchange=&quot;previewFiles(this.files)&quot;  /&gt;  &lt;ul id=&quot;preview&quot;&gt;&lt;/ul&gt;  &lt;script&gt;    const inputEl = document.getElementById(&#x27;fileInput&#x27;) const ulEle =    document.getElementById(&#x27;preview&#x27;) function previewFiles(files)&#123;&quot; &quot;&#125;    &#123;Array.from(files).forEach((file) =&gt; &#123;      const li = document.createElement(&quot;li&quot;)      ulEle.appendChild(li)      const img = document.createElement(&quot;img&quot;)      img.src = URL.createObjectURL(file)      img.height = 100      img.width = 100      img.onload = function () &#123;        // 当图片加载完成之后对象URL就不再需要了        URL.revokeObjectURL(this.src)      &#125;      li.appendChild(img)    &#125;)&#125;  &lt;/script&gt;&lt;/body&gt;\n\n来看看效果：\n\n\n在每次调用  createObjectURL()  方法时，都会创建一个新的 URL 对象，即使你已经用相同的对象作为参数创建过。当不再需要这些 URL 对象时，每个对象必须通过调用  URL.revokeObjectURL() 方法来释放。\n\n浏览器在 document 卸载的时候，会自动释放它们，但是为了获得最佳性能和内存使用状况，你应该在安全的时机主动释放掉它们。\nFileReader 的 readAsDataURL\nreadAsDataURL 方法会读取指定的 Blob 或 File 对象。读取操作完成的时候，readyState 会变成已完成 DONE，并触发 loadend 事件，同时 result 属性将包含一个 data:URL 格式的字符串（base64 编码）以表示所读取文件的内容。\n\n还是上一个例子\nfunction useFileReaderPreivewFiles(files) &#123;  Array.from(files).forEach((file) =&gt; &#123;    const reader = new FileReader()    const li = document.createElement(&quot;li&quot;)    ulEle.appendChild(li)    reader.onload = function (e) &#123;      const img = new Image()      img.height = 100      img.width = 100      img.src = e.target.result      li.appendChild(img)    &#125;    reader.readAsDataURL(file)  &#125;)&#125;\n\n同样的效果:\n\n来一张终极图：\n\n","categories":["js"]},{"title":"关于vue的mixin","url":"/blog/%E5%85%B3%E4%BA%8Evue%E7%9A%84mixin/","content":"vue的mixin当有多个组件写了多个同样的语句时，可以使用vue的mixin机制创建一个utils&#x2F;mixin.js文件，内容如下：\nimport &#123;  mapGetters,  mapActions&#125; from &#x27;vuex&#x27;export const bookMixin = &#123;  computed: &#123;    ...mapGetters([&#x27;bookName&#x27;, &#x27;bookCover&#x27;]),  &#125;,  methods: &#123;    ...mapActions([&#x27;setBookName&#x27;, &#x27;setBookCover&#x27;])  &#125;&#125;\n\n接下来就可以在组件内这样写：\nimport &#123; bookMixin &#125; from &#x27;utils/mixin&#x27;  mixins:[bookMixin]  methods: &#123;&#125;\n这样可以将vuex的内容在一处增加，多处复用。\nmapActions是写到methods里的，这样就可以替换这种写法\n// 原来写法this.$store.dispatch(&#x27;setBookName&#x27;,this.bookName)// 优雅写法this.setBookName(this.bookName)","categories":["vue"]},{"title":"关于中间件","url":"/blog/%E5%85%B3%E4%BA%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/","content":"使用 node 构建 web 应用时，并不单单响应一个简单的 hello world，在一个实际的业务中，我们也许会做这些：\n\n请求方法的判断。\nURL 的路径解析。\nURL 中查询字符串解析。\nCookie 的解析。\nBasic 认证。\n表单数据的解析。\n任意格式文件的上传处理。\n\n\n这样一个完整的项目中需要处理很多的细节，当然你也可以都写在一起，但这样代码的耦合程度太高了，而且以后维护起来也令人头大。\n为此引入**中间件（middleware）**来简化和隔离这些基础设施与业务逻辑之间的细节，让开发者能够关注在业务的开发上，以达到提升开发效率的目的。\n理解中间件的最简单的方式是实现一个基础的中间件模式，一个中间件其实就是一个函数。\n一个简单的中间件模式需要一个 use 方法来进行中间件的注册，需要一个 run 来执行这些注册的中间件\nconst app = &#123;  fns: [],  callback(ctx) &#123;    console.log(ctx)  &#125;,  use(fn) &#123;    this.fns.push(fn)  &#125;,  run(ctx) &#123;    let index = 0    const next = () =&gt; &#123;      index++    &#125;    this.fns.forEach((fn, idx) =&gt; &#123;      if (index === idx) fn(ctx, next)    &#125;)    index === this.fns.length &amp;&amp; this.callback(ctx)  &#125;,&#125;\n\n使用一下：\napp.use((ctx, next) =&gt; &#123;  ctx.name = &quot;ranxiu&quot;  next()&#125;)app.use((ctx, next) =&gt; &#123;  ctx.gender = &quot;girl&quot;  next()&#125;)app.run(&#123;&#125;)// 打印：&#123;name:&quot;ranxiu&quot;,gender:&quot;girl&quot;&#125;\n\n关于 run 函数还有更加优雅的写法：\nfunction run(ctx, stack) &#123;  const next = () =&gt; &#123;    const middleware = stack.shift()    if (middleware) &#123;      middleware(ctx, next) // 递归调用    &#125;  &#125;  next()&#125;\n\n再来看看 koa-compose 的中间件：\nfunction compose(middleware) &#123;  // 提前判断中间件类型,防止后续错误  if (!Array.isArray(middleware))    throw new TypeError(&quot;Middleware stack must be an array!&quot;)  for (const fn of middleware) &#123;    // 中间件必须为函数类型    if (typeof fn !== &quot;function&quot;)      throw new TypeError(&quot;Middleware must be composed of functions!&quot;)  &#125;  return function (context, next) &#123;    // 采用闭包将索引缓存,来实现调用计数    let index = -1    return dispatch(0)    function dispatch(i) &#123;      // 防止next()方法重复调用      if (i &lt;= index)        return Promise.reject(new Error(&quot;next() called multiple times&quot;))      index = i      let fn = middleware[i]      if (i === middleware.length) fn = next      if (!fn) return Promise.resolve()      try &#123;        // 包装next()返回值为Promise对象        return Promise.resolve(fn(context, dispatch.bind(null, i + 1)))      &#125; catch (err) &#123;        // 异常处理        return Promise.reject(err)      &#125;    &#125;  &#125;&#125;\n\n两个字：优雅。有时不得不感慨人和人的差距有时比人和狗的差距还大。\n拿这个 🌰 来说：\nfunction wait(ms) &#123;  return new Promise((resolve) =&gt; setTimeout(resolve, ms || 1))&#125;const arr = []const stack = []// type Middleware&lt;T&gt; = (context: T, next: Koa.Next) =&gt; any;stack.push(async (context, next) =&gt; &#123;  arr.push(1)  await wait(1)  await next()  await wait(1)  arr.push(6)&#125;)stack.push(async (context, next) =&gt; &#123;  arr.push(2)  await wait(1)  await next()  await wait(1)  arr.push(5)&#125;)stack.push(async (context, next) =&gt; &#123;  arr.push(3)  await wait(1)  await next()  await wait(1)  arr.push(4)&#125;)await compose(stack)(&#123;&#125;)// arr = [1,2,3,4,5,6]\n\n当 i 为 3 时，\nlet fn = middleware[i] //fn=undefinedif (i === middleware.length) fn = nextif (!fn) return Promise.resolve() //!fn为true\n\n直接返回 resolve，之后就执行 next()后面的函数\nstack.push(async (context, next) =&gt; &#123;  arr.push(3)  await wait(1)  await next()  await wait(1)  arr.push(4)&#125;)\n\n执行完后返回第二个 next() 后面继续往下执行，知道所有的中间件执行完毕。\n这便是众人皆知的“洋葱模型”。你也可以选择只添加前置的处理，就是 await next()前面的操作\n，或者后面的处理。\n每个中间件足够的小而美，职责单一，同时多个中间件又具备良好的逻辑拓展性和可组合性，并且易于测试。这个设计模式真是太“漂亮”了。\n","categories":["node"],"tags":["进阶"]},{"title":"前端性能优化方法","url":"/blog/%E5%89%8D%E7%AB%AF%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/","content":"最佳实践按需做事-不提前做按需做事，即在代码中计算和取值应该在需要的地方进行，而不是提前进行。这是因为如果在逻辑判断之前就进行计算，而后面的逻辑判断没有进入，那么这段代码就会白白消耗时间，从而降低了代码的效率。因此，按需做事是一种更加高效的编程方式。\n在函数中，有时我们会提前获取或计算所有属性，但是如果后面的逻辑判断没有用到这些属性，那么这部分计算就是无效的，浪费了时间和资源。因此，我们应该尽可能地按需获取和计算属性，以提高代码的效率和性能。此外，我们还可以通过使用缓存等技术来避免重复计算，从而进一步提高代码的效率。\nconst a = obj.a;const b = slowFn();if (xxxx) &#123;  return a;&#125; else if (xxx) &#123;  return b;&#125;\n\nV8 优化机制\n脚本流 边加载边解析\n字节码缓存 多个页面使用相同解析后的字节码会缓存\n懒解析 函数不用会先不解析\n\n函数解析优化懒解析 vs 饥饿解析\n饥饿解析 使用 一对 ‘()’ .\n对象优化\n以相同顺序初始化对象成员，避免隐藏类的调整\n实例化后避免添加新的属性 像这样 person.age &#x3D; 17\n尽量使用 Array 代替 array-like 对象\n避免读取超过数组的长度\n避免元素类型的转换\n\nHTML 优化\n减少 iframes 的使用\n压缩空白符\n避免节点深层级嵌套\nCSS&amp;Javascript 尽量使用外链\n删除元素默认属性\n\nul &gt; li 可以不写闭合\nCSS 优化\n降低 CSS 对渲染的阻塞\n利用 GPU 完成动画\ncontain：layout 开发者和浏览器沟通的一个属性，告诉浏览器只影响当前盒子\n使用 font-display 属性\n\nwebpack 构建优化Tree-shaking\n上下文未用到的代码（dead code）\n基于 ES6 import export\npackage.json 中配置 sideEffects ：有些代码有副作用可能不想打包时去掉，可以配置这个属性\n注意 Babel 默认配置的影响 会转换 ES6 的语法，可能导致上面基于 ES6 的 shaking 失效，可以配置 modules: false\n\nJS 压缩\nwebpack4 引入的 uglifyjs-webpack-plugin\n支持 ES6 的 terser-webpack-plugin\n\n作用域提升（scope hoisting）​​\n默认是开启的\n\n代码体积减小\n提高执行效率\nBabel 的 modules 也要设置成 hoist\n\nBabel7 优化配置\n在需要的地方引入 polyfill\n辅助函数按需引入 useBuiltIns: usage\n根据目标浏览器按需转换代码\n\nWebpack 依赖优化noParse\n提高构建速度\n直接通知 webpack 忽略较大的库\n被忽略的库不能有 import、require、define 的引入方式，就是不能是模块化的\n\nDllPlugin- 动态链接库\n避免打包时对不变的库重复构建\n提高构建速度\n针对开发环境\n\n‍\n// webpack.dll.config.jsoutput: &#123;    filename: &quot;[name].dll.js&quot;,    path: resolve(__dirname, &quot;dll&quot;),    library: &quot;[name]&quot;&#125;,plugin: [    new webpack.DllPlugin(&#123;        name: &quot;[name]&quot;,        path: resolve(__dirname, &quot;dll/[name].manifest.json&quot;) // 描述文件    &#125;)]\n\n在 config 文件直接引用描述文件\n代码拆分 （code splitting)\n把单个 bundle 文件拆分成几个小的 bundles&#x2F;chunks\n缩短首屏加载时间\n手工定义入口\nsplitChunks 提取公共代码，拆分业务代码和第三方库\n\noptimization: &#123;    splitChunks: &#123;        cacheGroups: &#123;            vendor: &#123;                name: &#x27;vendor&#x27;,                test: /[\\\\/]node_modules[\\\\/]/,                minSize: 0,                minChunks: 1,                priority: 10,                chunks: &#x27;initial&#x27;            &#125;,            common: &#123;                name: &#x27;common&#x27;,                test: /[\\\\/]src[\\\\/]/,                chunks: &#x27;all&#x27;            &#125;        &#125;    &#125;&#125;\n\n\n动态加载\n\n基于 webpack 的资源压缩（minification）\nTerser\nmini-css-extract-plugin 压缩 css\nHtmlWebpackPlugin- 压缩 html\n\n基于 webpack 的资源持久化缓存\n每个打包的资源文件有唯一的 hash 值\n修改后只有受影响的文件 hash 变化\n充分利用浏览器缓存\n\n基于 webpack 应用大小监测与分析\nstats 分析与可视化图\nwebpack-bundle-analyzer 体积分析 或者 source-map-explorer 可以直接显示大小和占比，需要生成 sourcemap\nspeed-measure-webpack-plugin 速度分析，可以检测使用的插件效率如何\n\nReact 按需加载\nReact Router 基于 webpack 动态引入\n使用 Reloadable 高级组件\n\n传输优化Gzip\ngzip_comp_level 压缩级别，越高压缩比越大也越耗性能\n\ngzip_min_length 当返回内容大于此值时才会使用 gzip 进行压缩\n\ngzip_types 设置需要压缩的 MIME 类型,如果不在设置类型范围内的请求不进行压缩\n\n对传输资源进行体积压缩，可达 90%\n\n\nKeep Alive\nkeeplive_timeout 0 不启用\nkeepalive_requests 设置一个 keep-alive 连接上可以服务的请求的最大数量，当最大请求数量达到时，连接被关闭。默认是 100\n\nHttp 缓存\nCache-Control&#x2F;Expires\nLast-Modified + If-Modified-Since\nEtag+ If-None-Match\n\nService Workers\n加速重复访问\n离线支持\n\n原理​​\n离线的时候是从 service worker 拿资源\n注意\n延长了首屏时间，但是页面总加载时间减少\n兼容性\n只能在 localhost 或 https 下使用\n\nHttp2\n二进制传输\n请求响应多路复用\nServer push\n适合较高请求量\n\n本地开发时，如果提示不安全网站，可以直接键盘输入 “thisisunsafe”\n​​​\n服务端渲染 SSR\n加速首屏加载\n更好的 SEO\n\n什么时候用 SSR\n架构- 大型、动态页面、面向公众\n搜索引擎排名很重要\n\n‍\n","categories":["js"]},{"title":"前端路由","url":"/blog/%E5%89%8D%E7%AB%AF%E8%B7%AF%E7%94%B1/","content":"URL 是由几个部分组成：\n​protocol: // hostname:port / pathname ? query # hash​\n路由模块需要实现的功能就是 —— 解析 URL 中的 pathname，根据不同的路径将请求分配给相应的模块去处理。\n一个简单的路由是一个类，它的方法能够返回不同的拦截切面，这样的类叫做 HTTP 服务中间件​**（Middleware）**。具体实现代码如下：\n// Router类const url = require(&quot;url&quot;);const path = require(&quot;path&quot;);/*@rule：路径规则@pathname：路径名*/function check(rule, pathname) &#123;  /*   解析规则，比如：/test/:course/:lecture  paraMatched = [&#x27;/test/:course/:lecture&#x27;, &#x27;:course&#x27;, &#x27;:lecture&#x27;]  */  const paraMatched = rule.match(/:[^/]+/g);  const ruleExp = new RegExp(`^$&#123;rule.replace(/:[^/]+/g, &quot;([^/]+)&quot;)&#125;$`);  /*  解析真正的路径，比如：/test/123/abc  ruleMatched = [&#x27;/test/123/abs&#x27;, &#x27;123&#x27;, &#x27;abs&#x27;]  */  const ruleMatched = pathname.match(ruleExp);  /*  将规则和路径拼接为对象：  ret = &#123;course: 123, lecture: abc&#125;  */  if (ruleMatched) &#123;    const ret = &#123;&#125;;    if (paraMatched) &#123;      for (let i = 0; i &lt; paraMatched.length; i++) &#123;        ret[paraMatched[i].slice(1)] = ruleMatched[i + 1];      &#125;    &#125;    return ret;  &#125;  return null;&#125;/*@method: GET/POST/PUT/DELETE@rule: 路径规则，比如：test/:course/:lecture@aspect: 拦截函数*/function route(method, rule, aspect) &#123;  return async (ctx, next) =&gt; &#123;    const req = ctx.req;    if (!ctx.url) ctx.url = url.parse(`http://$&#123;req.headers.host&#125;$&#123;req.url&#125;`);    const checked = check(rule, ctx.url.pathname); // 根据路径规则解析路径    if (!ctx.route &amp;&amp; (method === &quot;*&quot; || req.method === method) &amp;&amp; !!checked) &#123;      ctx.route = checked;      await aspect(ctx, next);    &#125; else &#123;      // 如果路径与路由规则不匹配，则跳过当前拦截切面，执行下一个拦截切面      await next();    &#125;  &#125;;&#125;class Router &#123;  constructor(base = &quot;&quot;) &#123;    this.baseURL = base;  &#125;  get(rule, aspect) &#123;    return route(&quot;GET&quot;, path.join(this.baseURL, rule), aspect);  &#125;  post(rule, aspect) &#123;    return route(&quot;POST&quot;, path.join(this.baseURL, rule), aspect);  &#125;  put(rule, aspect) &#123;    return route(&quot;PUT&quot;, path.join(this.baseURL, rule), aspect);  &#125;  delete(rule, aspect) &#123;    return route(&quot;DELETE&quot;, path.join(this.baseURL, rule), aspect);  &#125;  all(rule, aspect) &#123;    return route(&quot;*&quot;, path.join(this.baseURL, rule), aspect);  &#125;&#125;module.exports = Router;\n\n可以这样使用\nconst Server = require(&quot;./lib/server&quot;);const Router = require(&quot;./lib/middleware/router&quot;);const app = new Server();const router = new Router();app.listen(&#123;  port: 9090,  host: &quot;0.0.0.0&quot;,&#125;);app.use(  router.all(&quot;/test/:course/:lecture&quot;, async (&#123; route, res &#125;, next) =&gt; &#123;    res.setHeader(&quot;Content-Type&quot;, &quot;application/json&quot;);    res.body = route;    await next();  &#125;));app.use(  router.all(&quot;.*&quot;, async (&#123; req, res &#125;, next) =&gt; &#123;    res.setHeader(&quot;Content-Type&quot;, &quot;text/html&quot;);    res.body = &quot;&lt;h1&gt;Hello world&lt;/h1&gt;&quot;;    await next();  &#125;));\n","categories":["js"]},{"title":"前端调试通关","url":"/blog/%E5%89%8D%E7%AB%AF%E8%B0%83%E8%AF%95%E9%80%9A%E5%85%B3/","content":"各类调试工具原理Chrome DevTools 原理Chrome DevTools 分为两部分，backend 和 frontend：\n\nbackend 和 Chrome 集成，负责把 Chrome 的网页运行时状态通过调试协议暴露出来。\nfrontend 是独立的，负责对接调试协议，做 UI 的展示和交互。\n\n两者之间的调试协议叫做 Chrome DevTools Protocol，简称 CDP。\n传输协议数据的方式叫做信道（message channel）。\n​​\nVSCode Debugger 原理VSCode Debugger 的原理和 Chrome DevTools 差不多，也是分为 frontend、backend、调试协议这几部分，只不过它多了一层适配器协议。\n​​\n因为 VSCode 不是 JS 专用编辑器呀，它可能用来调试 Python 代码、Rust 代码等等，自然不能和某一种语言的调试协议深度耦合，所以多了一个适配器层。\n​​\nVue&#x2F;React DevToolsChrome 插件中可以访问网页的 DOM 的部分叫做 Content Script，随页面启动而生效，可以写一些操作 DOM 的逻辑。还有一部分是后台运行的，叫做 Background，浏览器启动就生效了，生命周期比较长，可以做一些常驻的逻辑。如果是扩展 DevTools 的 Chrome 插件，那还有一部分 DevTools Page，是在 DevTools 里显示的页面。\n​​\nContent Script 部分可以操作 DOM，可以监听 DOM Event。\nBackgroud 部分可以访问 extension api，可以和 Content Script 还有 DevTools Page 通信。\nDevTools Page 部分可以访问 devtools api，可以向当前 window 注入 JS 执行。\nfrontend、backend、调试协议、信道，这是调试工具的四要素。\n不过，不同的调试工具都会有不同的设计，比如 VSCode Debugger 为了跨语言复用，多了一层 Debugger Adapter，React DevTools 有独立的 electron 应用，用自定义调试协议，可以调试 React Native 代码。\n使用 vscode 调试 chrome\n打开项目目录，创建 .vscode&#x2F;launch.json 文件：​\n\n点击右下角的 Add Configuration… 按钮，选择 Chrome: Launch​\n\n把访问的 url 改为开发服务器启动的地址：​\n\n然后进入 Debug 窗口，点击启动：​\n\n在代码打个断点，然后点击刷新：\n\n可以看到在断点处暂停​\n\n想访问 this 的某个属性，可以在 Debug Console 里输入 this 看下它的值，然后再来写代码：​\n\n\nVscode Snippets语法\n指定光标位置：$x\n多光标编辑：$x $x\n指定 placeholder 文本：${x:placeholder}\n指定多选值：${x|aaa,bbb|}\n取变量：$VariableName vscode 变量\n对变量做转换：${VariableName&#x2F;正则&#x2F;替换的文本&#x2F;}\n\nPerformancefiber 测试页面\nMain 主线程​​\n灰色的是宏任务，橙色的是浏览器内部的 js，紫色的是 reflow、repaint， 绿色的是渲染。\n其它的是用户执行的 js。\n放大后可以看到先执行的 requestAnimationFrame 的回调，然后是回流重绘，最后是渲染。\n​​​​\n而且这种任务是每 13.3ms 执行一次，因为我的电脑是 75hz 的刷新率，1000 &#x2F; 75 &#x3D; 13.3 ms。如果一个任务执行时间超长，比如 50 多 ms，那它就相当于垮了好几帧，就会发生卡顿掉帧，因为阻塞了渲染的宏任务执行。\n性能优化就是为了优化长的宏任务\n长任务会标红\n​​\n\nrequestIdleCallback 回调是宏任务\n​​\n\n垃圾回收也是\n​\n\n定时器也是\n​\n\n执行 script\n​​\n\nparse Html\n​\n\nmicro tasks 是 task 的一部分\n​​\n\n\nrAF 调用栈末尾还有个 requestAnimationFrame 的调用，是浏览器把下次 rAF 回调加入 Event Loop。\n​\n在一帧里面，先执行 rAF，然后再执行 rIC。\n​​\n这种很长的看着像是递归\n​​​​\nFrames​​\n\n白色：没有变化\n绿色：按预期及时渲染\n黄色：浏览器尽最大努力及时呈现至少一些视觉更新，比如滚动了但主线程没空\n红色：掉帧，无法在合理的时间内渲染帧，比如：scroll​，resize ​ 事件触发过于频繁,浏览器来不及处理导致在下一个事件被触发之前无法完成\n\n‍\n","categories":["js"]},{"title":"前端错误监控","url":"/blog/%E5%89%8D%E7%AB%AF%E9%94%99%E8%AF%AF%E7%9B%91%E6%8E%A7/","content":"常见错误类型\n\n\n错误\n解释\n示例\n\n\n\nSyntaxError\n解析时发生语法错误\nconst x\n\n\nTypeError\n值不是所期待的类型\nconst person &#x3D; 1; person.name\n\n\nReferenceError\n引用未声明的变量\nx\n\n\nRangeError\n一个值不在其所允许的范围中\nnew Array(-1)\n\n\nResourceError\n资源加载错误\nnew Image().src &#x3D; ‘&#x2F;remote&#x2F;null.jpg’\n\n\nHttpError\nhttp 请求错误\nfetch(‘&#x2F;remote&#x2F;null’)\n\n\n\n\n如何捕获错误try&#x2F;catch能够捕获常规运行时错误，语法错误和异步错误无法捕获\n// 常规运行时错误，可以捕获 ✅try &#123;  console.log(notdefined);&#125; catch(e) &#123;  console.log(&#x27;捕获到异常：&#x27;, e);&#125;// 语法错误，不能捕获 ❌try &#123;  const notdefined,&#125; catch(e) &#123;  console.log(&#x27;捕获到异常：&#x27;, e);&#125;// 异步错误，不能捕获 ❌try &#123;  setTimeout(() =&gt; &#123;    console.log(notdefined);  &#125;, 0)&#125; catch(e) &#123;  console.log(&#x27;捕获到异常：&#x27;,e);&#125;\n\nwindow.onerror\n混合事件 GlobalEventHandlers 的 onerror 属性是用于处理 error 的事件Error 事件的事件处理程序，在各种目标对象的不同类型错误被触发：\n\n\n\n当 JavaScript 运行时错误（包括语法错误）发生时，window 会触发一个 ErrorEvent 接口的 error 事件，并执行 window.onerror()。\n当一项资源（如&lt;img&gt;或&lt;script&gt;）加载失败，加载资源的元素会触发一个 Event 接口的 error 事件，并执行该元素上的 onerror() 处理函数。这些 error 事件不会向上冒泡到 window，不过（至少在 Firefox 中）能被单一的 window.addEventListener 捕获。\n\n\nwindow.onerror = function(message, source, lineno, colno, error) &#123; ... &#125;\n\n函数参数：\n\nmessage：错误信息（字符串）。可用于 HTML onerror&#x3D;””处理程序中的 event。\nsource：发生错误的脚本 URL（字符串）\nlineno：发生错误的行号（数字）\ncolno：发生错误的列号（数字）\nerror：Error 对象（对象）\n\n若该函数返回 true，则阻止执行默认事件处理函数。\n// 常规运行时错误，可以捕获 ✅window.onerror = function(message, source, lineno, colno, error) &#123;  console.log(&#x27;捕获到异常：&#x27;,&#123;message, source, lineno, colno, error&#125;);&#125;console.log(notdefined);// 语法错误，不能捕获 ❌window.onerror = function(message, source, lineno, colno, error) &#123;  console.log(&#x27;捕获到异常：&#x27;,&#123;message, source, lineno, colno, error&#125;);&#125;const notdefined,// 异步错误，可以捕获 ✅window.onerror = function(message, source, lineno, colno, error) &#123;  console.log(&#x27;捕获到异常：&#x27;,&#123;message, source, lineno, colno, error&#125;);&#125;setTimeout(() =&gt; &#123;  console.log(notdefined);&#125;, 0)// 资源错误，不能捕获 ❌&lt;script&gt;  window.onerror = function(message, source, lineno, colno, error) &#123;  console.log(&#x27;捕获到异常：&#x27;,&#123;message, source, lineno, colno, error&#125;);  return true;&#125;&lt;/script&gt;&lt;img src=&quot;https://unknown/image/null.png&quot;&gt;\n\nwindow.addEventListener// 图片、script、css加载错误，都能被捕获 ✅&lt;script&gt;  window.addEventListener(    &quot;error&quot;,    (error) =&gt; &#123;      console.log(&quot;捕获到异常：&quot;, error)    &#125;,    true  )&lt;/script&gt;&lt;img src=&quot;https://unknown/image/null.png&quot; /&gt;&lt;script src=&quot;https://unknown/foundnull.js&quot;&gt;&lt;/script&gt;&lt;link href=&quot;https://unknown/foundnull.css&quot; rel=&quot;stylesheet&quot; /&gt;// new Image错误，不能捕获 ❌&lt;script&gt;  window.addEventListener(    &quot;error&quot;,    (error) =&gt; &#123;      console.log(&quot;捕获到异常：&quot;, error)    &#125;,    true  )&lt;/script&gt;&lt;script&gt;  new Image().src = &quot;https://unknown/image/null.png&quot;&lt;/script&gt;// fetch错误，不能捕获 ❌&lt;script&gt;  window.addEventListener(    &quot;error&quot;,    (error) =&gt; &#123;      console.log(&quot;捕获到异常：&quot;, error)    &#125;,    true  )&lt;/script&gt;&lt;script&gt;  fetch(&quot;https://unknown/test&quot;)&lt;/script&gt;\n\n异步错误如果使用 try&#x2F;catch 能捕获 await 的错误普通 Promise 错误 使用 catch\n全局捕获错误 - unhandledrejection// 全局统一处理Promisewindow.addEventListener(&quot;unhandledrejection&quot;, function (e) &#123;  console.log(&quot;捕获到异常：&quot;, e)&#125;)fetch(&quot;https://unknown/test&quot;)\n\nVue 的错误vue 的错误会被 vue 自动捕获，并且抛给 Vue.config.errorHandler。\n/** * 全局捕获Vue错误，直接扔出给onerror处理 */Vue.config.errorHandler = function (err) &#123;  setTimeout(() =&gt; &#123;    throw err  &#125;)&#125;\n\nReact 错误react 通过 componentDidCatch，声明一个错误边界的组件\n数据上报接口使用 1*1 像素的 gif 图片进行上报，有以下几点好处\n\n不会阻塞页面渲染\n图片天然跨域\n不会携带 Cookie\n不需等待服务器返回数据\ngif 图片所需流量最小\n\n但数据太大，最好还是用 post\n","categories":["js"],"tags":["监控"]},{"title":"原型与原型链","url":"/blog/%E5%8E%9F%E5%9E%8B%E4%B8%8E%E5%8E%9F%E5%9E%8B%E9%93%BE/","content":"原型与原型链实例与构造函数原型之间有直接的联系，但实例与构造函数之间没有。\n每个函数都有一个属性，就是 prototype，函数的 prototype 指向了一个对象，这个对象就是调用该构造函数创建的实例的原型。\n可以这么理解：每一个 JavaScript 对象(null 除外)在创建的时候就会与之关联另一个对象，这个对象就是我们所说的原型，每一个对象都会从原型“继承”属性。实例 person 与 Person.prototype 之间的关系通过 proto 连接这是每一个 JavaScript 对象(除了 null )都具有的一个属性，叫proto，这个属性会指向该对象的原型。\n\nfunction Person() &#123;&#125;var person = new Person()console.log(person.__proto__ === Person.prototype) // true\n\n\n每个原型都有一个 constructor 属性指向关联的构造函数。\nfunction Person() &#123;&#125;console.log(Person === Person.prototype.constructor) // true\n\n\n原型也是一个对象，那就可以通过 Object 构造函数生成，所以\n\nObject.prototype.proto 的值为 null 跟 Object.prototype 没有原型，其实表达了一个意思。\n一些细节\nconstructorfunction Person() &#123;&#125;var person = new Person()console.log(person.constructor === Person) // true\n\n当获取 person.constructor 时，其实 person 中并没有 constructor 属性,当不能读取到 constructor 属性时，会从 person 的原型也就是 Person.prototype 中读取，正好原型中有该属性，所以：\nperson.constructor === Person.prototype.constructor\n\nproto绝大部分浏览器都支持这个非标准的方法访问原型，然而它并不存在于 Person.prototype 中，实际上，它是来自于 Object.prototype ，与其说是一个属性，不如说是一个 getter&#x2F;setter，当使用 obj.proto 时，可以理解成返回了 Object.getPrototypeOf(obj)。\n真的是继承吗？最后是关于继承，前面我们讲到“每一个对象都会从原型‘继承’属性”，实际上，继承是一个十分具有迷惑性的说法，引用《你不知道的 JavaScript》中的话，就是：\n继承意味着复制操作，然而 JavaScript 默认并不会复制对象的属性，相反，JavaScript 只是在两个对象之间创建一个关联，这样，一个对象就可以通过委托访问另一个对象的属性和函数，所以与其叫继承，委托的说法反而更准确些。\nFunction.proto &#x3D;&#x3D;&#x3D; Function.prototypeFunction 作为一个内置对象，是运行前就已经存在的东西，所以根本就不会根据自己生成自己，就是先有的 Function，然后实现上把原型指向了 Function.prototype，但是我们不能倒过来推测因为 Function.proto &#x3D;&#x3D;&#x3D; Function.prototype，所以 Function 调用了自己生成了自己。\n完整的原型链\n什么是原型链？\n当对象查找一个属性的时候，如果没有在自身找到，那么就会查找自身的原型，如果原型还没有找到，那么会继续查找原型的原型，直到找到 Object.prototype 的原型时，此时原型为 null，查找停止。 这种通过原型链接的逐级向上的查找链被称为原型链\n什么是原型继承？\n一个对象可以使用另外一个对象的属性或者方法，就称之为继承。具体是通过将这个对象的原型设置为另外一个对象，这样根据原型链的规则，如果查找一个对象属性且在自身不存在时，就会查找另外一个对象，相当于一个对象可以使用另外一个对象的属性和方法了。\n使用 Object.prototype.toString.call() 判断数据类型\nproto 与内部的 [[Prototype]] 不一样。\nproto 是 [[Prototype]] 的 getter&#x2F;setter。\n","categories":["js"]},{"title":"四种移除事件监听的方式","url":"/blog/%E5%9B%9B%E7%A7%8D%E7%A7%BB%E9%99%A4%E4%BA%8B%E4%BB%B6%E7%9B%91%E5%90%AC%E7%9A%84%E6%96%B9%E5%BC%8F/","content":"在运行时清理代码是构建高效、可预测应用程序的必不可少的部分。在 JavaScript 中，合理管理事件监听器，在不再需要监听事件的时候将它们移除是必要的。\n用下面代码进行实验 ：\n&lt;button id=&quot;button&quot;&gt;Do Something&lt;/button&gt;&lt;script&gt;document.getElementById(&#x27;button&#x27;).addEventListener(&#x27;click&#x27;, () =&gt; &#123;  console.log(&#x27;clicked!&#x27;);&#125;);&lt;/script&gt;\n\n使用 Chrome getEventListeners() 函数，您将看到只有一个监听器附加到该元素：\n​​\n使用 removeEventListener​removeEventListener​ 方法接受三个参数：要移除的监听器类型、该监听器的回调函数以及一个选项对象。\n但是棘手之处在于：这些参数必须和设置监听器时使用的参数完全匹配，包括相同的回调引用。否则removeEventListener()​ 将不起作用。鉴于此，以下操作将是完全无效的：\ndocument.getElementById(&quot;button&quot;).addEventListener(&quot;click&quot;, () =&gt; &#123;  console.log(&quot;clicked!&quot;);&#125;);document.getElementById(&quot;button&quot;).removeEventListener(&quot;click&quot;, () =&gt; &#123;  console.log(&quot;clicked!&quot;);&#125;);\n\n尽管移除监听的回调看起来与最初绑定的回调完全相同，但它们并不是相同的引用。解决此问题的方法是将回调函数设置为变量，并在.addEventListener()​ 和 .removeEventListener()​ 中使用它。\nconst myCallback = () =&gt; &#123;  console.log(&quot;clicked!&quot;);&#125;;document.getElementById(&quot;button&quot;).addEventListener(&quot;click&quot;, myCallback);document.getElementById(&quot;button&quot;).removeEventListener(&quot;click&quot;, myCallback);\n\n或者，对于特定的场景，您还可以使用在函数内部使用函数名来删除监听器：\ndocument  .getElementById(&quot;button&quot;)  .addEventListener(&quot;click&quot;, function myCallback() &#123;    console.log(&quot;clicked!&quot;);    this.removeEventListener(&quot;click&quot;, myCallback);  &#125;);\n\n使用 addEventListener 的 once 选项​addEventListener()​ 方法的第二个对象参数有一个选项：once​ 选项，可以用来设置在仅打算使用一次的情况下自行清除事件绑定。它的使用和听起来一样简单，如果将其设置为 true​，则监听器在第一次被调用后会自动被移除：\nconst button = document.getElementById(&quot;button&quot;);button.addEventListener(  &quot;click&quot;,  () =&gt; &#123;    console.log(&quot;clicked!&quot;);  &#125;,  &#123; once: true &#125;);// &#x27;clicked!&#x27;button.click();// No more listeners!getEventListeners(button); // &#123;&#125;\n\n即使使用匿名函数，这种方法也是有效的，你的监听器只会被调用一次。\n克隆和替换节点有时，你可能不知道给定节点上的所有活动监听器，但你想要将它们全部移除。在这种情况下，可以克隆整个节点并用该克隆节点替换自身。使用 .cloneNode() 方法，通过 .addEventListener()​ 附加的任何监听器都不会被保留，从而获得一个干净的节点。\n在客户端 JavaScript 的石器时代，您会看到通过查询父节点，并替换特定子节点以进行此操作：\nbutton.parentNode.replaceChild(button.cloneNode(true), button);\n\n但在现代浏览器中，可以使用 .replaceWith()​ 进行简化：\nbutton.replaceWith(button.cloneNode(true));\n\n这里唯一可能让你困扰的是，行内监听器会被保留，这意味着 onclick​ 事件仍会被触发：\n&lt;button id=&quot;button&quot; onclick=&quot;console.log(&#x27;clicked!&#x27;)&quot;&gt;  Do Something&lt;/button&gt;\n\n总的来说，如果你需要删除任何类型的监听器，这是一个不错的选择。它的缺点是目的不明显，有些讨巧。\n使用 AbortController()​.addEventListener()​ 可以配置一个信号，用于命令式地中止&#x2F;删除监听器。当相应的控制器调用 .abort()​ 时，监听器会被移除：\nconst button = document.getElementById(&quot;button&quot;);const controller = new AbortController();const &#123; signal &#125; = controller;button.addEventListener(&quot;click&quot;, () =&gt; console.log(&quot;clicked!&quot;), &#123; signal &#125;);// Remove the listener!controller.abort();\n\n上面的方法是一种更明了的方式，可以在不需要处理 .removeEventListener()​ 的潜在陷阱的情况下移除监听器。还有一个更大的优势：您可以使用一个信号一次性删除多个监听器，使用匿名函数也可以：\nconst button = document.getElementById(&quot;button&quot;);const controller = new AbortController();const &#123; signal &#125; = controller;button.addEventListener(&quot;click&quot;, () =&gt; console.log(&quot;clicked!&quot;), &#123; signal &#125;);window.addEventListener(&quot;resize&quot;, () =&gt; console.log(&quot;resized!&quot;), &#123; signal &#125;);document.addEventListener(&quot;keyup&quot;, () =&gt; console.log(&quot;pressed!&quot;), &#123; signal &#125;);// Remove all listeners at once:controller.abort();\n\n唯一需要考虑的是浏览器支持。\n​​\n我应该选择哪种方法？一般来说，“视情况而定”。不过我可能会这样选择：\n\n如果回调函数分配给变量，并且在添加监听器的地方容易访问，请使用 .removeEventListener()​。\n如果只需要触发一次回调，请在 .addEventListener()​ 中使用 once​ 选项。\n如果需要在一次操作中无差别地删除所有的监听器，请使用克隆替换方法。\n如果有一系列监听器希望命令式地一次性删除，请使用 AbortController()​\n\n原文地址：\nYou’ve Got Options for Removing Event Listeners\n‍\n","categories":["js"]},{"title":"复现 musicforprogramming.net 的音乐可视化效果","url":"/blog/%E5%A4%8D%E7%8E%B0musicForProgramming%E7%BD%91%E7%AB%99%E7%9A%84%E9%9F%B3%E4%B9%90%E5%8F%AF%E8%A7%86%E5%8C%96%E6%95%88%E6%9E%9C/","content":"最近，我尝试复现了 musicforprogramming.net 网站上的音乐可视化效果。这个网站为程序员提供了一个独特的音乐播放体验，伴随着音乐的播放，屏幕上会显示动态的 ASCII 艺术效果。本文将详细介绍如何通过 HTML、CSS 和 JavaScript 来实现这一效果。\nHTML 结构在 index.html 文件中，我们定义了一个简单的网页结构。页面包含一个音频播放器（目前被注释掉了）和四个 &lt;span&gt; 元素，用于显示不同颜色的 ASCII 艺术效果。此外，还有一个播放按钮，用于控制音乐的播放和暂停。\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;    &lt;title&gt;musicforprogramming&lt;/title&gt;    &lt;link rel=&quot;stylesheet&quot; href=&quot;style.css&quot;&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=&quot;pad grey pr-0 pb-0 pt-0&quot;&gt;        &lt;span id=&quot;fuschia&quot;            class=&quot;fuschia&quot;&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;br&gt;        &lt;span id=&quot;orange&quot;            class=&quot;orange&quot;&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;br&gt;        &lt;span id=&quot;yellow&quot;            class=&quot;yellow&quot;&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;br&gt;        &lt;span id=&quot;green&quot; class=&quot;green&quot;&gt;________________________________&lt;/span&gt;&lt;br&gt;        &lt;br&gt;        &lt;br&gt;        &lt;button id=&quot;play&quot; class=&quot;green hover&quot; disabled:true=&quot;false&quot;&gt;[play]&lt;/button&gt;        &lt;br&gt;    &lt;/div&gt;    &lt;script src=&quot;index.js&quot;&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;\n\nJavaScript 逻辑index.js 文件包含了实现音乐播放和可视化效果的核心逻辑。我们使用 AudioContext 和 AnalyserNode 来处理音频数据，并通过 requestAnimationFrame 实现动态的可视化效果。\n// 获取页面上的元素const F = document.getElementById(&quot;fuschia&quot;); // 获取紫色区域的元素const O = document.getElementById(&quot;orange&quot;); // 获取橙色区域的元素const Y = document.getElementById(&quot;yellow&quot;); // 获取黄色区域的元素const G = document.getElementById(&quot;green&quot;);   // 获取绿色区域的元素const play = document.getElementById(&quot;play&quot;); // 获取播放按钮元素// 创建音频上下文和音频对象const audioCtx = new AudioContext(); // 创建音频上下文const audio = new Audio(&#x27;./daoxiang.mp3&#x27;); // 创建音频对象，加载音频文件// 为播放按钮添加点击事件监听器play.addEventListener(&#x27;click&#x27;, () =&gt; &#123;    if (!audio.paused) &#123; // 如果音频正在播放        audio.pause(); // 暂停音频        play.innerText = &quot;[play]&quot;; // 将按钮文本改为 &quot;[play]&quot;        return;    &#125;    audio.play(); // 播放音频    play.innerText = &quot;[pause]&quot;; // 将按钮文本改为 &quot;[pause]&quot;&#125;);// 创建音频分析器const analyser = audioCtx.createAnalyser(); // 创建音频分析器analyser.minDecibels = -114; // 设置分析器的最小分贝值analyser.maxDecibels = -30;  // 设置分析器的最大分贝值analyser.fftSize = 2048;     // 设置 FFT（快速傅里叶变换）的大小analyser.smoothingTimeConstant = .666; // 设置平滑时间常数，控制音频数据的平滑程度// 设置音频属性audio.type = &quot;audio/mp3&quot;; // 设置音频类型audio.crossOrigin = &quot;anonymous&quot;; // 设置跨域属性，允许跨域请求audio.volume = .5; // 设置音频音量audio.autoplay = true; // 设置音频自动播放// 当音频可以播放时，执行以下操作audio.addEventListener(&#x27;canplaythrough&#x27;, () =&gt; &#123;    // 创建音频源节点    const source = audioCtx.createMediaElementSource(audio);    // 创建增益节点（用于控制音量）    const gainNode = audioCtx.createGain();    // 将音频源连接到分析器    source.connect(analyser);    // 将音频源连接到增益节点    source.connect(gainNode);    // 将增益节点连接到音频上下文的输出（通常是扬声器）    gainNode.connect(audioCtx.destination);    // 创建一个数组来存储频率数据    const dataArray = new Uint8Array(analyser.frequencyBinCount);    // 调用可视化函数，开始渲染音频可视化效果    visualize(dataArray);&#125;)// 可视化函数，用于渲染音频的 ASCII 艺术效果function visualize(dataArray) &#123;    // 获取当前频率数据    analyser.getByteFrequencyData(dataArray);    // 初始化四个颜色的 ASCII 字符串    let fuschia = &quot;&quot;, orange = &quot;&quot;, yellow = &quot;&quot;, green = &quot;&quot;,        index = 0, adjustValue = -40, multiplier = 1.08, offset = 1;    // 遍历频率数据，生成 ASCII 字符    for (i = 0; i &lt; 32; i++) &#123;        // 计算当前字符的索引，把当前频率数据映射到字符集范围中        index = Math.max(dataArray[~~offset + i] + adjustValue &gt;&gt; 3, 0);        offset *= multiplier; // 调整偏移量        adjustValue += 1.5;    // 调整值        multiplier += .01;    // 调整乘数        // 根据索引从字符集中选择字符        fuschia += &quot;                       _.-•:*^º&#x27;&quot;[index];        orange += &quot;               _.-•:*^º&#x27;        &quot;[index];        yellow += &quot;       _.-•:*^º&#x27;                &quot;[index];        green += &quot;_.-•:*^º&#x27;                       &quot;[index];    &#125;    // 将生成的 ASCII 字符显示在页面上    F.innerText = fuschia;    O.innerText = orange;    Y.innerText = yellow;    G.innerText = green;    // 使用 requestAnimationFrame 递归调用 visualize 函数，实现动态效果    requestAnimationFrame(() =&gt; visualize(dataArray));&#125;\n\n可视化效果在 visualize 函数中，我们通过分析音频的频率数据，动态生成 ASCII 字符并将其显示在页面上。每个 &lt;span&gt; 元素对应不同的颜色和字符集，从而在页面上呈现出动态的视觉效果。\n\n\n总结通过这个项目，我们成功复现了 musicforprogramming.net 的音乐可视化效果。这个项目不仅展示了如何使用 Web Audio API 处理音频数据，还展示了如何通过 JavaScript 和 HTML 实现动态的视觉效果。希望这篇文章对你有所帮助，欢迎在评论区分享你的想法和改进建议。\n你可以访问 GitHub 仓库 查看完整的代码和效果展示。\nHappy coding! 🎵\n","categories":["js"]},{"title":"如何实现全局图片监控","url":"/blog/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%85%A8%E5%B1%80%E5%9B%BE%E7%89%87%E7%9B%91%E6%8E%A7/","content":"为什么要做这个？\n图片过大占用 CDN 资源\n拖慢加载速度，体验不好\n\n要怎么做？\n\nPerformanceObserver 可以获取已缓存图片的 entry 信息，多个相同请求 entry 只会报告一次，能够拿到 decodedBodySize。但在跨域且未使用 Timing-Allow-Origin ​HTTP 相应标头情况下，这个值为 0 。\n主要拿到图片的原始宽高和图片显示的实际宽高，超出一定比例，图片大小超过一定阈值（比如 1M），基本可以判断图片不太符合规范，上报该数据。上报的数据可以是图片的 DOM 路径，用于定位排查。\n实现思路针对不同情况，有不同的监控手段\n一些工具函数\nconst getNodeKey = (src: string, path: string[]) =&gt; `$&#123;src&#125;::$&#123;path.join(&#x27;/&#x27;)&#125;`;const getNodeName = (node: Node) =&gt; node.nodeName?.toLowerCase() ?? &#x27;unknown&#x27;;const isElement = (node: any): node is Element =&gt; !!(node.tagName &amp;&amp; node.classList);const isHTMLImageElement = (node: Node): node is HTMLImageElement =&gt; getNodeName(node) === &#x27;img&#x27;;const getNodePath = (node: Node, path: string[] = []): string[] =&gt; &#123;        if (!isElement(node)) &#123;            return path;        &#125;        const nodeName = getNodeName(node);        const &#123; id &#125; = node;        const &#123; className &#125; = node;        const key = `$&#123;nodeName&#125;$&#123;id ? `#$&#123;id&#125;` : &#x27;&#x27;&#125;$&#123;className ? `.$&#123;className&#125;` : &#x27;&#x27;&#125;`;        path.push(key);        return node.parentElement ? getNodePath(node.parentElement, path) : path;&#125;;\n\n利用 PerformanceObserver 获取图片大小\nconst perfWatchSet = new Set([&#x27;img&#x27;, &#x27;css&#x27;, &#x27;body&#x27;]);const perfObserver = new PerformanceObserver(    list =&gt; &#123;        const entries = list.getEntries();        for (let index = 0, len = entries.length; index &lt; len; index++) &#123;           const entry = entries[index] as PerformanceResourceTiming;        const &#123; initiatorType, encodedBodySize, decodedBodySize, transferSize, name &#125; = entry;        const src = filterImgSrc(name);        if (perfWatchSet.has(initiatorType) &amp;&amp; src &amp;&amp; decodedBodySize &gt; 0) &#123;        perfEntries.set(src, entry);        if (transferSize === 0 &amp;&amp; encodedBodySize &gt; 0) &#123;            // 处理逻辑        &#125;        &#125;,&#125;);// 浏览器默认是250，不设置大点前面的会被丢弃，监听不到performance.setResourceTimingBufferSize(2000);perfObserver.observe(&#123; type: &#x27;resource&#x27;, buffered: true &#125;);\n\n场景一：在 HTML DOM 上的 &lt;img&gt; 标签分为初始处理和增量处理\n// 工具函数const getImgSrc = (node: HTMLImageElement) =&gt; node.src;const getBgSrc = (node: Element): string =&gt; &#123;     const &#123; backgroundImage &#125; = window.getComputedStyle(node);     return ((backgroundImage &amp;&amp; regex4BgImage.exec(backgroundImage)) || [])[1] || &#x27;&#x27;;&#125;;const handleNode = (node: Node) =&gt; &#123;      // 处理 img.src      handleImageElements(node);      // 处理backgorundimg style      handleBgImageElements(node);&#125;;const visitedNodeSet = new WeakSet&lt;Node&gt;();const handleNodes = (nodeList: ArrayLike&lt;Node&gt;) =&gt; &#123;    for (let index = 0, len = nodeList.length; index &lt; len; index++) &#123;        const node = nodeList[index];        if (visitedNodeSet.has(node)) &#123;            continue;        &#125;        visitedNodeSet.add(node);        if (isElement(node)) &#123;            handleNodes(node.children);            handleNode(node);        &#125;    &#125;&#125;// 1、初始处理handleNodes([document.documentElement]);// 2、增量处理const observer = new MutationObserver((mutations: MutationRecord[])=&gt; &#123;    for (let index = 0, len = mutations.length; index &lt; len; index++) &#123;        const mutation = mutations[index];        handleNodes(mutation.addedNodes);    &#125;&#125;);observer.observe(document.documentElement, &#123; attributes: false, childList: true, subtree: true &#125;);\n\n还有 img.src 属性变化的情况，也需要用 MutationObserver 监听处理一下\n// 省略处理流程const imgSrcObserver = new MutationObserver(() =&gt; &#123;&#125;);const handleImageElements = (node: Node) =&gt; &#123;        if (isHTMLImageElement(node)) &#123;            const src = filterImgSrc(getImgSrc(node));            if (src) &#123;                imgByImageElement.push(&#123; node, src &#125;);            &#125;            imgSrcObserver.observe(node, &#123; attributeFilter: [&#x27;src&#x27;] &#125;);            //         &#125;&#125;;\n\n场景二：添加到 HTML DOM 上的有 backgroundImage 的标签const handleBgImageElements = (node: Node) =&gt; &#123;      if (isElement(node)) &#123;         const src = filterImgSrc(getBgSrc(node));         if (src) &#123;            imgByBgImageElement.push(&#123; src, node &#125;);         &#125;         //  &#125;&#125;;// 其他代码参考上面场景一\n\n场景三: 使用 API 动态创建拦截并重写 原生方法\nconst oCreateElement = document.createElement.bind(document);document.createElement = function (tagName: string, options?: ElementCreationOptions) &#123;            const newElement = oCreateElement(tagName, options);            if (isHTMLImageElement(newElement)) &#123;                handleLoaded(newElement, &#x27;createElement&#x27;);            &#125;            return newElement;&#125;;const oCreateElementNS = document.createElementNS.bind(document);document.createElementNS = function (            namespaceURI: string,            qualifiedName: string,            options?: ElementCreationOptions,) &#123;            const newElement = oCreateElementNS(namespaceURI, qualifiedName, options);            if (isHTMLImageElement(newElement)) &#123;                handleLoaded(newElement, &#x27;createElementNS&#x27;);            &#125;            return newElement;&#125; as typeof document.createElementNS;const oImage = window.Image;window.Image = function (width?: number, height?: number) &#123;            const newImage: HTMLImageElement = new oImage(width, height);            handleLoaded(newImage, &#x27;Image&#x27;);            return newImage;&#125; as unknown as typeof window.Image;// Preserve static propertiesObject.assign(window.Image, oImage);\n\nhandleLoaded\n function handleLoaded(node: HTMLImageElement, sourceFrom: string) &#123;      const loadListener = (event: Event) =&gt; &#123;          onLoaded(event, sourceFrom);      &#125;;      const errorListener = () =&gt; &#123;          //      &#125;;      node.addEventListener(&#x27;load&#x27;, loadListener, &#123; once: true &#125;);      node.addEventListener(&#x27;error&#x27;, errorListener, &#123; once: true &#125;);&#125;\n\n以上是基本框架，还有一些上报逻辑，缓存清理逻辑需要补充，完成后便可以得到一个全局的图片监控。\n性能因为全局的监听图片的使用，拿图片的 width、height 还有 backgroundImage 等信息时会强制触发重排重绘，会影响到加载和操作性能，所以不能大批量的全部监控，可以每天挑选部分高性能用户开启，降低影响面。\n‍\n‍\n","tags":["监控"]},{"title":"如何缩小js代码","url":"/blog/%E5%A6%82%E4%BD%95%E7%BC%A9%E5%B0%8Fjs%E4%BB%A3%E7%A0%81/","content":"写在前面相较于简写形式带来的代码体积减小，易于理解的代码书写方式能显著提升可维护性，因此在选择简写方案时需谨慎。\nArgumentssetInterval(function () &#123;  console.log(&quot;z&quot;);&#125;, 100); // beforesetInterval(&#x27;console.log(&quot;z&quot;)&#x27;, 100); // after\n\nVariablesvar o = &#123;&#125;; // Object literalvar a = []; // New Arrayvar r = /.*/; // New Regexvar s = &quot;&quot; + 0; // Convert to stringvar n = +&quot;7&quot;; // Convert to number (7)var b = !!b; // Converts to a booleanvar f = ~~3.434; // Same as Math.floor(3.434)var g = -~3.434; // Same as Math.ceil(3.434)var x = 5e3; // Same as 5000var c = c || z; // Coalesce, if c is null then set it to z.&quot;abcde&quot;[1]; // charAt shorthand, results in &#x27;b&#x27;.+new Date(); // Shorthand for (new Date()).getTime();Date.now(); // Even shorter shorthand for the abovevar a = x ? y : z; // Ternary operator, short for: var a;if(x)&#123;a=y;&#125;else&#123;a=z;&#125;!0; // Shorthand for true!1; // Shorthand for falsevoid 0; // Shorthand for undefined\n\n隐式转换a = &quot;30&quot;;b = &quot;10&quot;;c = a + b; // failurec = parseInt(a) + parseInt(b); // too longc = -(-a - b); // try thesec = ~~a + ~~b;c = +a + +b;c = a - -b;\n\n运算符hasAnF = &quot;This sentence has an f.&quot;.indexOf(&quot;f&quot;) &gt;= 0; // beforehasAnF = ~&quot;This sentence has an f.&quot;.indexOf(&quot;f&quot;); // after// ==================================// Longhandif (str.indexOf(ndx) == -1) &#123;  // Char not found&#125;// Shorthandif (~str.indexOf(ndx)) &#123;  // Char not found.&#125;//===========================================rand10 = Math.floor(Math.random() * 10); // beforerand10 = 0 | (Math.random() * 10); // after// ~ 优先级低于|//===========================================Math.floor(a / 2); // beforea &gt;&gt; 1; // afterMath.floor(a / 4); // beforea &gt;&gt; 2; // after//==========================================million = 1000000; // beforemillion = (1e6)[ // after  //==========================================  (Infinity, -Infinity)][(1 / 0, -1 / 0)]; // before // after//=============================================if (isFinite(a))  if (1 / a)    // before    // after    //==========================================    //使用当前日期生成随机整数    new Date() &amp; 1; // Equivalent to Math.random()&lt;0.5new Date() % 1337; // Equivalent to Math.floor(Math.random()*1337))i = 0 | (Math.random() * 100); // beforei = new Date() % 100; // after//=============================================\n\nstringhtml = &quot;&lt;a href=&#x27;&quot; + url + &quot;&#x27;&gt;&quot; + text + &quot;&lt;/a&gt;&quot;; // beforehtml = text.link(url); // after//&#x27;abc&#x27;.link(&#x27;www.baidu.com&#x27;) -&gt; &#x27;&lt;a href=&quot;www.baidu.com&quot;&gt;abc&lt;/a&gt;&#x27;//==================================================// Longhand&quot;myString&quot;.charAt(0);// Shorthand&quot;myString&quot;[0]; // returns &#x27;m&#x27;//Pretty useful for RGB declarations.&quot;rgb(&quot; + (x + 8) + &quot;,&quot; + (y - 20) + &quot;,&quot; + z + &quot;)&quot;; // before&quot;rgb(&quot; + [x + 8, y - 20, z] + &quot;)&quot;; // after&quot;rgb(255,&quot; + (y - 20) + &quot;,0)&quot;; // before&quot;rgb(255,&quot; + [y - 20, &quot;0)&quot;]; // after\n\n条件语句// Longhandvar big;if (x &gt; 10) &#123;  big = true;&#125; else &#123;  big = false;&#125;// Shorthandvar big = (x &gt; 10) ? true : false;var big = (x &gt; 10);//further nested examplesvar x = 3,big = (x &gt; 10) ? &#x27;greater 10&#x27; : (x &lt; 5) ? &#x27;less 5&#x27; : &#x27;between 5 and 10&#x27;;console.log(big); // &quot;less 5&quot;var x = 20,big = &#123; true: x &gt; 10, false : x&lt; =10 &#125;;console.log(big); // &quot;Object &#123;true=true, false=false&#125;&quot;//==================================================// Longhandif(myvar == 1 || myvar == 5 || myvar == 7 || myvar == 22)  &#123;  console.log(&#x27;ya&#x27;);&#125;// Shorthand([1,5,7,22].indexOf(myvar) !=- 1) &amp;&amp; alert(&#x27;yeah baby!&#x27;);//=====================================================// Longhandif (type === &#x27;aligator&#x27;) &#123;  aligatorBehavior();&#125;else if (type === &#x27;parrot&#x27;) &#123;  parrotBehavior();&#125;else if (type === &#x27;dolphin&#x27;) &#123;  dolphinBehavior();&#125;else if (type === &#x27;bulldog&#x27;) &#123;  bulldogBehavior();&#125; else &#123;  throw new Error(&#x27;Invalid animal &#x27; + type);&#125;// Shorthandvar types = &#123;  aligator: aligatorBehavior,  parrot: parrotBehavior,  dolphin: dolphinBehavior,  bulldog: bulldogBehavior&#125;;var func = types[type];(!func) &amp;&amp; throw new Error(&#x27;Invalid animal &#x27; + type); func();//========================================================//Longhandif (x == a) &#123; x = b;&#125;else if (x == b) &#123; x = a;&#125;// x = 1, a = 1, b = 2// 1st run: x = 2// 2nd run: x = 1// 3rd run: x = 2// 4th run: x = 1// ...// Shorthandx = a ^ b ^ x;//====================================================\n","categories":["js"]},{"title":"如果一个npm包不满足需求，如何修改其部分功能","url":"/blog/%E5%A6%82%E6%9E%9C%E4%B8%80%E4%B8%AAnpm%E5%8C%85%E4%B8%8D%E6%BB%A1%E8%B6%B3%E9%9C%80%E6%B1%82%EF%BC%8C%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9%E5%85%B6%E9%83%A8%E5%88%86%E5%8A%9F%E8%83%BD/","content":"一、使用 ForkFork 源代码，通过在 GitHub 上或其他托管平台上 Fork 第三方包的源代码库。对其源代码进行修改，修改完成后将修改后的包发布到 npm 上。如果你不希望它是公开的，那么你可以搭建一个 npm 的私有包。直接将项目中的包切换我们自己发布的包。\n\n\n二、提交 PR如果你认为你的修改对其他用户也有帮助，可以向原始包的维护者提交 Pull Request（PR）。如果 PR 被接受并合并，那么你就可以直接使用未来版本的官方包。\n三、本地修改和补丁这种方式可以避免直接修改 node_modules 目录下的代码，也确保了项目的其他成员或在其他环境中部署时能够应用同样的修改。\n\n在本地对包进行修改：直接在项目的 node_modules 目录下找到并修改对应的第三方包文件。\n\n创建补丁文件：一旦完成了必要的修改，你可以使用 git diff 或其他差异比较工具来生成一个补丁文件。\ngit diff &gt; patches/third-party-package.patch\n\n应用补丁：为了自动化地在每次安装依赖时应用这个补丁，你可以使用如 patch-package 这样的工具。patch-package 允许在 node_modules 中的包上应用补丁，并且这些补丁可以和你的项目代码一起被版本控制。\n\n\n安装 patch-pacakge ，然后，将应用补丁的步骤添加到 package.json 中的 scripts 字段：\n&quot;scripts&quot;: &#123;  &quot;postinstall&quot;: &quot;patch-package&quot;&#125;\n\n这样，每次运行 npm install 时，postinstall 脚本都会执行，自动应用保存在 patches&#x2F;目录下的所有补丁。\n生成补丁假设我们要要修改 axios 包，那么我们可以直接在项目的 node_modules&#x2F;axios 目录下对 axios 进行必要的修改。这些修改可以是任何东西，从简单的配置更改到函数逻辑的更新。\n使用 patch-package 生成一个补丁文件。这个命令会比较你对 node_modules 中 axios 的修改，并将这些修改保存为一个补丁文件。\nnpx patch-package axios\n\n执行这个命令后，patch-package 会在项目的根目录下创建一个 patches 目录（如果还没有的话），并在里面生成一个名为 axios+ 版本号.patch 的文件，其中版本号是你项目中使用的 axios 的版本。\n四、包装三方包创建一个新的文件（如 third-party-wrapper.js），在这个文件中导入第三方包，并实现需要修改或扩展的功能。\n在项目中的其他部分，你可以直接引入并使用这个封装模块，而不是直接使用第三方包。这样，你就可以利用修改后的功能，同时避免了对第三方包的直接修改。\n这种方法的好处是，它提供了一个清晰的隔离层，使得第三方包的任何更新不会直接影响到你对功能的定制。同时，这也使得维护和升级第三方包变得更加容易，因为你只需要在封装层中做出相应的调整。\n总结以上 4 种方式，通常提交 PR 和使用 Fork 是最推荐的，因为它们可以避免维护自定义修改所带来的长期负担。但是由于业务的紧急性，我们也可以选择后两种方式。\n‍\n","categories":["js"]},{"title":"材质贴图属性介绍","url":"/blog/%E6%9D%90%E8%B4%A8%E8%B4%B4%E5%9B%BE%E5%B1%9E%E6%80%A7%E4%BB%8B%E7%BB%8D/","content":"​diffuse&#x2F;base colos&#x2F;albedo颜色贴图： 漫反射可以简单理解成物体表面固有的颜色\nreflection&#x2F;specular反射贴图：白色全反射黑色不反射（排除金银铜等金属）\nmetalness金属度： 纯白金属 黑色电解质\nglossiness光泽度： 材质的粗糙程度 白色光滑，黑色粗糙\nroughness粗糙度： 与上面相反\nnormal蓝色法线 用rgb代表xyz三个方向上的位移值，本质改变了光线在材质表面的传播方式，没有产生模型形变， OpenGl（+X, +Y, +Z), DirectX（+X， -Y，+Z）\ndisplacement&#x2F;height置换贴图： 黑色不变，白色凸起\nbump凹凸： 与置换相同但只改变光线效果，没有改变模型，使之产生形变\nAO环境光遮蔽： 物体相交或者靠近时遮挡附近漫反射光线，前提是发生了置换效果\n\n颜色信息（漫反射）\n反射信息（反射、光泽度）\n高度信息（法线、凹凸、置换）\n\n","categories":["图形学"]},{"title":"性能优化的一般性原则","url":"/blog/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E4%B8%80%E8%88%AC%E6%80%A7%E5%8E%9F%E5%88%99/","content":"一般性原则依据数据而不是凭空猜测这是前端性能优化的第一原则，当我们怀疑前端性能有问题的时候，应该通过测试、浏览器开发者工具、性能分析工具来分析出哪里有问题，有的放矢，而不是凭感觉、撞运气。一个前端页面有了性能问题，瓶颈有可能是 JavaScript 执行时间过长，有可能是网络请求过多或请求资源过大，有可能是 DOM 操作频繁导致重排重绘，大方向的定位可以使用浏览器开发者工具的 Performance 面板来定位，针对具体的代码块，可以使用 console.time 和 console.timeEnd 来分析执行时间。\n忌过早优化\nThe real problem is that programmers have spent far too much time worrying about efficiency in the wrong places and at the wrong times; premature optimization is the root of all evil (or at least most of it) in programming.\n\n我并不十分清楚 Donald Knuth 说出这句名言的上下文环境，但我自己是十分认同这个观念的。在我的工作环境（以及典型的互联网应用开发）与编程模式下，追求的是快速的迭代与试错，过早的优化往往是无用功。而且，过早的优化很容易拍脑袋，优化的点往往不是真正的性能瓶颈。\n忌过度优化\nAs performance is part of the specification of a program – a program that is unusably slow is not fit for purpose\n\n性能优化的目标是追求合适的性价比。\n在不同的阶段，我们对系统的性能会有一定的要求，比如吞吐量要达到多少多少。如果达不到这个指标，就需要去优化。如果能满足预期，那么就无需花费时间精力去优化，比如只有几十个人使用的内部系统，就不用按照十万在线的目标去优化。\n而且，一些优化方法是“有损”的，可能会对代码的可读性、可维护性有副作用。这个时候，就更不能过度优化。\n深入理解业务代码是服务于业务的，也许是服务于最终用户，也许是服务于其他程序员。不了解业务，很难理解系统的流程，很难找出系统设计的不足之处。\n性能优化是持久战当核心业务方向明确之后，就应该开始关注性能问题，当项目上线之后，更应该持续的进行性能检测与优化。\n现在的互联网产品，不再是一锤子买卖，在上线之后还需要持续的开发，用户的涌入也会带来性能问题。因此需要自动化的检测性能问题，保持稳定的测试环境，持续的发现并解决性能问题，而不是被动地等到用户的投诉。\n选择合适的衡量指标、测试用例、测试环境正因为性能优化是一个长期的行为，所以需要固定衡量指标、测试用例、测试环境，这样才能客观反映性能的实际情况，也能展现出优化的效果。\n衡量性能有很多指标，比如系统响应时间、系统吞吐量、系统并发量。不同的系统核心指标是不一样的，首先要明确本系统的核心性能诉求，固定测试用例；其次也要兼顾其他指标，不能顾此失彼。\n测试环境也很重要，有一次突然发现我们的 QPS 高了许多，但是程序压根儿没优化，查了半天，才发现是换了一个更牛逼的物理机做测试服务器。\n性能优化的层次可以分为需求阶段，设计阶段，实现阶段；越上层的阶段优化效果越明显，同时也更需要对业务、需求的深入理解。\n需求阶段程序员的需求可能来自 PM、UI 的业务需求（或者说是功能性需求），也可能来自 Team Leader 的需求。当我们拿到一个需求的时候，首先需要的是思考、讨论需求的合理性，而不是立刻去设计、去编码。\n需求是为了解决某个问题，问题是本质，需求是解决问题的手段。那么需求是否能否真正的解决问题，程序员也得自己去思考，产品经理（特别是知道一点技术的产品经理）的某个需求可能只是某个问题的解决方案，他认为这个方法可以解决他的问题，于是把解决方案当成了需求，而不是真正的问题。\n需求讨论的前提对业务的深入了解，如果不了解业务，根本没法讨论。即使需求已经实现了，当我们发现有性能问题的时候，首先也可以从需求出发。\n需求分析对性能优化有什么帮助呢，第一，为了达到同样的目的，解决同样问题，也许可以有性能更优（消耗更小）的办法。这种优化是无损的，即不改变需求本质的同时，又能达到性能优化的效果；第二种情况，有损的优化，即在不明显影响用户的体验，稍微修改需求、放宽条件，就能大大解决性能问题。PM 退步一小步，程序前进一大步。\n需求讨论也有助于设计时更具扩展性，应对未来的需求变化。\n设计阶段高手都是花 80% 时间思考，20% 时间实现；新手写起代码来很快，但后面是无穷无尽的修 bug\n设计的概念很宽泛，包括架构设计、技术选型、接口设计等等。架构设计约束了系统的扩展、技术选型决定了代码实现。编程语言、框架都是工具，不同的系统、业务需要选择适当的工具集。如果设计的时候做的不够好，那么后面就很难优化，甚至需要推到重来。\n实现阶段实现是把功能翻译成代码的过程，这个层面的优化，主要是针对一个调用流程，一个函数，一段代码的优化。各种 profile 工具也主要是在这个阶段生效。除了静态的代码的优化，还有编译时优化，运行时优化。后二者要求就很高了，程序员可控性较弱。\n代码层面，造成性能瓶颈的原因通常是高频调用的函数、或者单次消耗非常高的函数、或者二者的结合。\n一般性方法缓存\n没有什么性能问题是缓存解决不了的，如果有，那就再加一级缓存\n\n缓存的本质是加速访问，访问的数据要么是其他数据的副本 – 让数据离用户更近；要么是之前的计算结果 – 避免重复计算.\n缓存需要用空间换时间，在缓存空间有限的情况下，需要优秀的置换换算来保证缓存有较高的命中率。\n数据的缓存这是我们最常见的缓存形式，将数据缓存在离使用者更近的地方。比如操作系统中的 CPU cache、disk cache。对于一个 web 应用，前端会有浏览器缓存，有 CDN，有反向代理提供的静态内容缓存；后端则有本地缓存、分布式缓存。\n数据的缓存，很多时候是设计层面的考虑。\n对于数据缓存，需要考虑的是缓存一致性问题。对于分布式系统中有强一致性要求的场景，可行的解决办法有 lease，版本号。\n计算结果的缓存对于消耗较大的计算，可以将计算结果缓存起来，下次直接使用。\n我们知道，对递归代码的一个有效优化手段就是缓存中间结果，lookup table，避免了重复计算。python 中的 method cache 就是这种思想.\n对于可能重复创建、销毁，且创建销毁代价很大的对象，比如进程、线程，也可以缓存，对应的缓存形式如单例、资源池（连接池、线程池）。\n对于计算结果的缓存，也需要考虑缓存失效的情况，对于 pure function，固定的输入有固定的输出，缓存是不会失效的。\n并发一个人干不完的活，那就找两个人干。并发既增加了系统的吞吐，又减少了用户的平均等待时间。\n惰性将计算推迟到必需的时刻，这样很可能避免了多余的计算，甚至根本不用计算。\nCopyOnWrite、Dirty flag\n批量，合并前端开发中经常会有资源的压缩和合并。\n当涉及到网络请求的时候，网络传输的时间可能远大于请求的处理时间，因此合并网络请求就很有必要。\n更高效的实现同一个算法，肯定会有不同的实现，那么就会有不同的性能；有的实现可能是时间换空间，有的实现可能是空间换时间，那么就需要根据自己的实际情况权衡。\n程序员都喜欢早轮子，用于练手无可厚非，但在项目中，使用成熟的、经过验证的轮子往往比自己造的轮子性能更好。当然不管使用别人的轮子，还是自己的工具，当出现性能的问题的时候，要么优化它，要么替换掉他。\n缩小解空间缩小解空间的意思是说，在一个更小的数据范围内进行计算，而不是遍历全部数据。最常见的就是索引，通过索引，能够很快定位数据，对数据库的优化绝大多数时候都是对索引的优化。\n如果有本地缓存，那么使用索引也会大大加快访问速度。不过，索引比较适合读多写少的情况，毕竟索引的构建也是需有消耗的。\n性能优化与代码质量衡量代码质量的标准是可读性、可维护性、可扩展性，但性能优化有可能会违背这些特性，比如为了屏蔽实现细节与使用方式，我们会可能会加入接口层（虚拟层），这样可读性、可维护性、可扩展性会好很多，但是额外增加了一层函数调用，如果这个地方调用频繁，那么也是一笔开销；又如前面提到的 C 扩展，也是会降低可维护性、\n这种有损代码质量的优化，应该放到最后，不得已而为之，同时写清楚注释与文档。\n为了追求可扩展性，我们经常会引入一些设计模式，如状态模式、策略模式、模板方法、装饰器模式等，但这些模式不一定是性能友好的。所以，为了性能，我们可能写出一些反模式的、定制化的、不那么优雅的代码，这些代码其实是脆弱的，需求的一点点变动，对代码逻辑可能有至关重要的影响，所以还是回到前面所说，不要过早优化，不要过度优化。​\n‍\n","tags":["性能优化"]},{"title":"浅谈SOLID原则在前端的使用","url":"/blog/%E6%B5%85%E8%B0%88SOLID%E5%8E%9F%E5%88%99%E5%9C%A8%E5%89%8D%E7%AB%AF%E7%9A%84%E4%BD%BF%E7%94%A8/","content":"简介​SOLID​ 原则是由 Robert C. Martin​ 在 2000 年提出的一套软件开发准则，最初用于面向对象编程（OOP），旨在解决软件开发中的复杂性和维护问题。随着时间推移，它不仅在传统 OOP 语言中广泛应用，也被引入到 JavaScript 和 TypeScript 等现代编程语言和框架中，如 React​ 和 Angular​。\n\nSOLID 原则包括以下五个方面：\n\n单一职责原则（Single Responsibility Principle - SRP​）\n开闭原则（Open/Closed Principle - OCP​）\n里氏替换原则（Liskov Substitution Principle - LSP​）\n接口隔离原则（Interface Segregation Principle - ISP​）\n依赖倒置原则（Dependency Inversion Principle - DIP​）\n\n在 JavaScript​ 和 TypeScript​ 中，尽管它们是动态语言且不以类为核心，但这些原则可融入组件化和模块化架构，开发者能借此确保代码简洁、可扩展、易维护和测试\n一、 单一职责原则 (SRP)原则一个类或模块应只有一个发生变化的原因，仅负责一项特定功能。在前端开发中，尤其是在 React​ 等组件化框架中，我们经常会看到组件承担了太多职责——不仅负责 UI​ 渲染，还处理业务逻辑和数据请求。这种情况很容易导致代码难以维护和测试，违反了 SRP​ 原则。\n反例(js-react)function UserProfile(&#123; userId &#125;) &#123;  const [user, setUser] = useState(null);  useEffect(() =&gt; &#123;    fetchUserData();  &#125;, [userId]);  async function fetchUserData() &#123;    const response = await fetch(`/api/users/$&#123;userId&#125;`);    const data = await response.json();    setUser(data);  &#125;  return &lt;div&gt;&#123;user?.name&#125;&lt;/div&gt;;&#125;\n\n此例中，UserProfile​ 组件既负责 UI​ 渲染又负责数据获取，违反 SRP​ 原则，当修改数据获取或界面渲染逻辑时，可能影响组件其他部分，增加维护复杂性。\n重构后代码为了遵循 SRP​ 原则，我们可以将数据获取逻辑提取到一个自定义的 Hook​ 中，让组件 UserProfile​ 只关注 UI​ 渲染。\n// 自定义 Hook 用于获取用户数据function useUserData(userId) &#123;  const [user, setUser] = useState(null);  useEffect(() =&gt; &#123;    async function fetchUserData() &#123;      const response = await fetch(`/api/users/$&#123;userId&#125;`);      const data = await response.json();      setUser(data);    &#125;    fetchUserData();  &#125;, [userId]);  return user;&#125;// UI 组件function UserProfile(&#123; userId &#125;) &#123;  const user = useUserData(userId); // 将数据获取逻辑移到了 Hook 中  return &lt;div&gt;&#123;user?.name&#125;&lt;/div&gt;;&#125;\n\n通过自定义 Hook​（useUserData​）将数据获取逻辑与 UI​ 逻辑分离，符合 SRP​ 原则，提升了代码的可维护性和复用性。\n反例(ts-angular)@Injectable()export class UserService &#123;  constructor(private http: HttpClient) &#123;&#125;  getUser(userId: string) &#123;    return this.http.get(`/api/users/$&#123;userId&#125;`);  &#125;  updateUserProfile(userId: string, data: any) &#123;    // 更新用户信息并处理通知    return this.http.put(`/api/users/$&#123;userId&#125;`, data).subscribe(() =&gt; &#123;      console.log(&#x27;User updated&#x27;);      alert(&#x27;Profile updated successfully&#x27;);    &#125;);  &#125;&#125;\n\n​UserService​ 类承担多个职责，包括获取和更新用户信息以及处理通知，违背 SRP​ 原则，导致维护困难。\n重构后代码@Injectable()export class UserService &#123;  constructor(private http: HttpClient) &#123;&#125;  getUser(userId: string) &#123;    return this.http.get(`/api/users/$&#123;userId&#125;`);  &#125;  updateUserProfile(userId: string, data: any) &#123;    return this.http.put(`/api/users/$&#123;userId&#125;`, data);  &#125;&#125;// 独立的通知服务@Injectable()export class NotificationService &#123;  notify(message: string) &#123;    alert(message);  &#125;&#125;\n\n通过将通知逻辑分离到一个独立的 NotificationService​ 中，我们遵循了 单一职责原则（SRP）​，将通知逻辑分离到 NotificationService​ 中，遵循 SRP​ 原则，每个类职责明确，带来诸多好处：\n\n职责明确，增强可维护性。修改通知方式只需更改 NotificationService​，不影响用户服务其他功能。\n提高复用性。NotificationService​ 可在其他服务或组件中复用。\n测试更加方便。可单独为 UserService​ 和 NotificationService​ 编写测试。\n代码扩展更加灵活。如需更改通知方式，只需修改或扩展 NotificationService​。\n\n// **职责明确，增强可维护性：**修改通知为弹出窗口通知@Injectable()export class NotificationService &#123;  notify(message: string) &#123;    showModal(message);  // 假设我们有一个 showModal 函数用于展示弹窗  &#125;&#125;\n\n// 提高复用性。NotificationService 可在其他服务或组件中复用@Injectable()export class OrderService &#123;  constructor(private notificationService: NotificationService) &#123;&#125;  placeOrder(orderData: any) &#123;    // 订单处理逻辑    this.notificationService.notify(&#x27;Order placed successfully&#x27;);  &#125;&#125;\n\n// 测试更加方便。可单独为 UserService 和 NotificationService 编写测试。it(&#x27;should fetch user data&#x27;, () =&gt; &#123;  const userService = new UserService(httpClientMock);  userService.getUser(&#x27;1&#x27;).subscribe(data =&gt; &#123;    expect(data).toEqual(mockUserData);  &#125;);&#125;);// NotificationService 测试it(&#x27;should notify the user&#x27;, () =&gt; &#123;  const notificationService = new NotificationService();  spyOn(window, &#x27;alert&#x27;);  notificationService.notify(&#x27;Test message&#x27;);  expect(window.alert).toHaveBeenCalledWith(&#x27;Test message&#x27;);&#125;);\n\n//代码扩展更加灵活。如需更改通知方式，只需修改或扩展 NotificationService@Injectable()export class EmailNotificationService extends NotificationService &#123;  notify(message: string) &#123;    sendEmail(message);  // 假设我们有一个 sendEmail 函数发送邮件  &#125;&#125;\n\n二、开闭原则（OCP）原则软件实体应能在不修改模块源代码的情况下扩展其行为，即对扩展开放，对修改封闭。\n反例(js-react)假设我们有一个表单验证函数，它目前工作正常，但未来可能需要添加更多的验证逻辑。\nfunction validateForm(values) &#123;  let errors = &#123;&#125;;  if (!values.name) &#123;    errors.name = &quot;Name is required&quot;;  &#125;  if (!values.email) &#123;    errors.email = &quot;Email is required&quot;;  &#125; else if (!/\\S+@\\S+\\.\\S+/.test(values.email)) &#123;    errors.email = &quot;Email is invalid&quot;;  &#125;  return errors;&#125;\n\n​validateForm​ 函数包含所有验证逻辑，添加新验证规则需修改现有代码，违背 OCP​ 原则，增加维护难度和出错风险。\n重构后代码// 基础验证器接口class Validator &#123;  validate(value) &#123;    throw new Error(&quot;validate method must be implemented&quot;);  &#125;&#125;// 具体的验证器class RequiredValidator extends Validator &#123;  validate(value) &#123;    return value ? null : &quot;This field is required&quot;;  &#125;&#125;class EmailValidator extends Validator &#123;  validate(value) &#123;    return /\\S+@\\S+\\.\\S+/.test(value) ? null : &quot;Email is invalid&quot;;  &#125;&#125;// 验证表单函数function validateForm(values, validators) &#123;  let errors = &#123;&#125;;  for (let field in validators) &#123;    const error = validators[field].validate(values[field]);    if (error) &#123;      errors[field] = error;    &#125;  &#125;  return errors;&#125;// 使用示例const validators = &#123;  name: new RequiredValidator(),  email: new EmailValidator(),&#125;;const errors = validateForm(&#123; name: &quot;&quot;, email: &quot;invalid email&quot; &#125;, validators);console.log(errors);\n\n通过将验证逻辑封装到独立的类（如 RequiredValidator​ 和 EmailValidator​）中，我们使得验证器符合 ​**开放&#x2F;封闭原则（OCP）**​。现在，如果需要添加新的验证规则（例如电话号码验证），只需创建一个新的验证器类，而无需修改现有的验证逻辑；换句话说，应该允许在不修改现有核心代码的情况下添加新功能。\n反例(ts-angular)在 Angular​ 中，服务和组件的设计应允许添加新功能，而无需修改核心逻辑。\nexport class NotificationService &#123;  send(type: &#x27;email&#x27; | &#x27;sms&#x27;, message: string) &#123;    if (type === &#x27;email&#x27;) &#123;      // 发送电子邮件    &#125; else if (type === &#x27;sms&#x27;) &#123;      // 发送短信    &#125;  &#125;&#125;\n\n在这个例子中，NotificationService​ 类违反了 ​**开放&#x2F;封闭原则（OCP）**​，因为每次需要支持新类型的通知（例如推送通知）时，必须修改 send​ 方法。这不仅会增加维护成本，还容易引发错误，尤其是当代码变得越来越复杂时。\n重构后代码interface Notification &#123;  send(message: string): void;&#125;@Injectable()export class EmailNotification implements Notification &#123;  send(message: string) &#123;    // 发送电子邮件的逻辑  &#125;&#125;@Injectable()export class SMSNotification implements Notification &#123;  send(message: string) &#123;    // 发送短信的逻辑  &#125;&#125;@Injectable()export class NotificationService &#123;  constructor(private notifications: Notification[]) &#123;&#125;  notify(message: string) &#123;    this.notifications.forEach(n =&gt; n.send(message));  &#125;&#125;\n\n通过将通知发送逻辑封装到各自独立的类（EmailNotification​ 和 SMSNotification​）中，我们实现了符合 开放&#x2F;封闭原则（OCP） 的设计。这个设计的核心思想是，所有新功能（例如新的通知类型）都可以通过创建新的类来扩展，而不需要修改现有的 NotificationService​ 类。好处：对扩展开放，对修改封闭、提高复用性、测试更加简单、增强代码的灵活性与维护性。\n\n三、 里氏替换原则 (LSP)原则子类型必须可以替换其基类型。派生类或组件应该能够替换基类，而不会影响程序的正确性。\n反例(js-react)当使用高阶组件 (HOC​) 或有条件地渲染不同组件时，LSP​ 有助于确保所有组件的行为都可预测。\nfunction Button(&#123; onClick &#125;) &#123;  return &lt;button onClick=&#123;onClick&#125;&gt;Click me&lt;/button&gt;;&#125;function LinkButton(&#123; href &#125;) &#123;  return &lt;a href=&#123;href&#125;&gt;Click me&lt;/a&gt;;&#125;&lt;Button onClick=&#123;() =&gt; &#123;&#125;&#125; /&gt;;&lt;LinkButton href=&quot;/home&quot; /&gt;;\n\n这里 Button ​和 LinkButton ​不一致，一个用 onClick​，一个用 href​，替换起来比较困难。\n重构后代码function Clickable(&#123; children, onClick &#125;) &#123;  return &lt;div onClick=&#123;onClick&#125;&gt;&#123;children&#125;&lt;/div&gt;;&#125;function Button(&#123; onClick &#125;) &#123;  return &lt;Clickable onClick=&#123;onClick&#125;&gt;    &lt;button&gt;Click me&lt;/button&gt;  &lt;/Clickable&gt;;&#125;function LinkButton(&#123; href &#125;) &#123;  return &lt;Clickable onClick=&#123;() =&gt; window.location.href = href&#125;&gt;    &lt;a href=&#123;href&#125;&gt;Click me&lt;/a&gt;  &lt;/Clickable&gt;;&#125;\n\n现在，Button​ 和 LinkButton​ 的行为类似，均遵循 LSP​。\n反例(ts-angular)class Rectangle &#123;  constructor(protected width: number, protected height: number) &#123;&#125;  area() &#123;    return this.width * this.height;  &#125;&#125;class Square extends Rectangle &#123;  constructor(size: number) &#123;    super(size, size);  &#125;  setWidth(width: number) &#123;    this.width = width;    this.height = width; // Breaks LSP  &#125;&#125;\n\n修改 Square​ 中的 setWidth​ 违反了 LSP​，因为 Square​ 的行为与 Rectangle​ 不同。\n重构后代码class Shape &#123;  area(): number &#123;    throw new Error(&#x27;Method not implemented&#x27;);  &#125;&#125;class Rectangle extends Shape &#123;  constructor(private width: number, private height: number) &#123;    super();  &#125;  area() &#123;    return this.width * this.height;  &#125;&#125;class Square extends Shape &#123;  constructor(private size: number) &#123;    super();  &#125;  area() &#123;    return this.size * this.size;  &#125;&#125;\n\n现在，Square ​和 Rectangle ​可以相互替代而不违反 LSP。\n\n四、接口隔离原则 (ISP)原则客户端不应被迫依赖他们不使用的接口\n反例(js-react)​React​ 组件有时会收到不必要的 props​，导致代码紧密耦合且庞大。\nfunction MultiPurposeComponent(&#123; user, posts, comments &#125;) &#123;  return (    &lt;div&gt;      &lt;UserProfile user=&#123;user&#125; /&gt;      &lt;UserPosts posts=&#123;posts&#125; /&gt;      &lt;UserComments comments=&#123;comments&#125; /&gt;    &lt;/div&gt;  );&#125;\n\n这里，组件依赖于多个 props​，即使它可能并不总是使用它们。\n重构后代码function UserProfileComponent(&#123; user &#125;) &#123;  return &lt;UserProfile user=&#123;user&#125; /&gt;;&#125;function UserPostsComponent(&#123; posts &#125;) &#123;  return &lt;UserPosts posts=&#123;posts&#125; /&gt;;&#125;function UserCommentsComponent(&#123; comments &#125;) &#123;  return &lt;UserComments comments=&#123;comments&#125; /&gt;;&#125;\n\n通过将组件拆分成更小的组件，每个组件仅依赖于它实际使用的数据。\n反例(ts-angular)interface Worker &#123;  work(): void;  eat(): void;&#125;class HumanWorker implements Worker &#123;  work() &#123;    console.log(&#x27;Working&#x27;);  &#125;  eat() &#123;    console.log(&#x27;Eating&#x27;);  &#125;&#125;class RobotWorker implements Worker &#123;  work() &#123;    console.log(&#x27;Working&#x27;);  &#125;  eat() &#123;    throw new Error(&#x27;Robots do not eat&#x27;); // Violates ISP  &#125;&#125;\n\n这里，RobotWorker ​被迫实现了不相关的 eat ​方法。\n重构后代码interface Worker &#123;  work(): void;&#125;interface Eater &#123;  eat(): void;&#125;class HumanWorker implements Worker, Eater &#123;  work() &#123;    console.log(&#x27;Working&#x27;);  &#125;  eat() &#123;    console.log(&#x27;Eating&#x27;);  &#125;&#125;class RobotWorker implements Worker &#123;  work() &#123;    console.log(&#x27;Working&#x27;);  &#125;&#125;\n\n通过分离 Worker​ 和 Eater​ 接口，我们确保客户端只依赖于它们所需要的。\n\n五、依赖倒置原则 (DIP)原则高级模块不应依赖于低级模块。两者都应依赖于抽象（例如接口）。\n反例(js-react)function fetchUser(userId) &#123;  return fetch(`/api/users/$&#123;userId&#125;`).then(res =&gt; res.json());&#125;function UserComponent(&#123; userId &#125;) &#123;  const [user, setUser] = useState(null);  useEffect(() =&gt; &#123;    fetchUser(userId).then(setUser);  &#125;, [userId]);  return &lt;div&gt;&#123;user?.name&#125;&lt;/div&gt;;&#125;\n\n这里，UserComponent​ 与 fetchUser​ 函数紧密耦合。\n重构后代码function UserComponent(&#123; userId, fetchUserData &#125;) &#123;  const [user, setUser] = useState(null);  useEffect(() =&gt; &#123;    fetchUserData(userId).then(setUser);  &#125;, [userId, fetchUserData]);  return &lt;div&gt;&#123;user?.name&#125;&lt;/div&gt;;&#125;// Usage&lt;UserComponent userId=&#123;1&#125; fetchUserData=&#123;fetchUser&#125; /&gt;;\n\n通过将 fetchUserData​ 注入组件，我们可以轻松地交换实现以进行测试或用于不同的用例。\n反例(ts-angular)@Injectable()export class UserService &#123;  constructor(private http: HttpClient) &#123;&#125;  getUser(userId: string) &#123;    return this.http.get(`/api/users/$&#123;userId&#125;`);  &#125;&#125;@Injectable()export class UserComponent &#123;  constructor(private userService: UserService) &#123;&#125;  loadUser(userId: string) &#123;    this.userService.getUser(userId).subscribe(user =&gt; console.log(user));  &#125;&#125;\n\n​UserComponent​ 与 UserService​ 紧密耦合，因此很难替换掉 UserService​。\n重构后代码interface UserService &#123;  getUser(userId: string): Observable&lt;User&gt;;&#125;@Injectable()export class ApiUserService implements UserService &#123;  constructor(private http: HttpClient) &#123;&#125;  getUser(userId: string) &#123;    return this.http.get&lt;User&gt;(`/api/users/$&#123;userId&#125;`);  &#125;&#125;@Injectable()export class UserComponent &#123;  constructor(private userService: UserService) &#123;&#125;  loadUser(userId: string) &#123;    this.userService.getUser(userId).subscribe(user =&gt; console.log(user));  &#125;&#125;\n\n通过依赖接口（UserService​），UserComponent​ 现在与 ApiUserService​ 的具体实现分离。\n\n结论无论是前端的 React​、Angular​ 等框架，还是后端的 Node.js​，SOLID​ 原则都能作为指南，让软件架构更加稳固。SOLID​ 原则能非常有效地确保代码干净、可维护且可扩展，在 JavaScript​ 和 TypeScript​ 框架（如 React​ 和 Angular​）中同样如此。应用这些原则，开发人员能编写灵活且可重复使用的代码，随着需求的发展，这些代码也能轻松扩展和重构。遵循 SOLID​ 原则，能让代码库变得强大，为未来的增长做好准备。\n‍\n","tags":["js","设计模式"]},{"title":"杰弗里·辛顿深度访谈","url":"/blog/%E6%9D%B0%E5%BC%97%E9%87%8C%C2%B7%E8%BE%9B%E9%A1%BF%E6%B7%B1%E5%BA%A6%E8%AE%BF%E8%B0%88/","content":"\n一、个人学术历程：从哲学到神经网络\n\n\n阶段\n经历\n关键转折\n\n\n\n​高中时期（1966年左右）\n同学提及“大脑使用全息图存储记忆” → 受Lashley大鼠实验启发\n对分布式记忆产生兴趣\n\n\n剑桥大学本科\n先学生理+物理 → 转哲学（认为缺乏判断真假的方法）→ 再转心理学（理论过于简陋）\n意识到传统学科无法解释大脑智能\n\n\n短暂休学\n成为木匠\n反思后决定投身AI\n\n\n爱丁堡大学博士\n师从Langer Higgins（已放弃神经网络，推崇符号AI）\n坚持神经网络方向，与导师激烈争论\n\n\n加州圣地亚哥（UCSD）\n遇David Rumelhart、Don Norman等开放思想者\n进入神经网络研究黄金期\n\n\n\n✅ ​启示​：跨学科背景 + 坚持直觉 + 找到志同道合的环境 = 创新土壤\n\n\n二、三大核心技术贡献（辛顿自评最自豪）1. 玻尔兹曼机（Boltzmann Machines）\n​核心思想：用简单学习算法训练全连接网络，仅观测部分节点。\n\n​优势：\n\n学习规则局部（每个突触只需前后神经元信息）\n“醒-睡”两阶段传播机制，更接近生物神经活动\n\n\n​演进：受限玻尔兹曼机（RBM） → 实际可用（如Netflix竞赛）\n\n\n2. 深度信念网络（Deep Belief Nets, DBN）\n​方法：逐层预训练RBM → 将特征作为新数据 → 叠加多层\n\n​突破：\n\n首次实现高效深度网络训练\n提供​变分下界（variational bound）保证：每加一层，模型下界提升\n融合​有向图模型​（Sigmoid belief net）与无向能量模型\n\n\n\n3. 变分推断与近似EM算法\n​关键论文​：1993年与Van Camp提出首个变分贝叶斯神经网络\n\n​贡献：\n\n证明​E步无需精确，近似即可有效\n使贝叶斯学习在神经网络中变得可行\n为现代变分自编码器（VAE）  奠定基础\n\n\n\n\n🔍 注：辛顿强调这些工作当时被忽视，多年后才被认可。\n\n\n三、关于反向传播（Backpropagation）的真相\n​并非原创：Werbos（1974）、Parker 等人早有类似想法\n\n为何1986年论文引爆社区？\n\n发表于《Nature》\n展示​词嵌入雏形：通过家庭树任务（如“Mary has mother Victoria”）学习语义向量\n向审稿人Stuart Sutherland清晰解释特征可解释性\n\n\n​与大脑的关系：\n\n辛顿坚信：进化很可能实现了类似backprop的机制\n\n提出替代方案：\n\n​Recirculation算法（1987）：通过循环稳定活动学习\n​重建误差导数法（2007）：堆叠自编码器中，重建误差 ≈ 判别梯度\n\n\n\n\n\n\n💡 观点：大脑可能用“预测编码”或“重建反馈”实现类backprop功能\n\n\n四、当前研究方向（截至访谈时）1. 胶囊网络（Capsule Networks）\n​核心理念：\n\n用胶囊（capsule）  替代单个神经元\n每个胶囊输出​多维向量，表示一个实体的多种属性（位置、朝向、颜色等）\n前提：局部区域最多存在一个该类实体\n\n\n​路由机制​： “协议路由”（Routing by Agreement）\n\n下层胶囊投票上层参数\n高维空间中“一致”极难偶然发生 → 强分割能力\n\n\n​目标​：提升​小样本泛化​、​视角不变性​、对象分割\n\n\n2. 快权重（Fast Weights）\n​起源：1973年未发表构想\n​机制：快速变化但快速衰减的权重 → 存储短期记忆\n​用途​：实现​真递归（reuse neurons &amp; weights in recursion）\n​复兴：2015年与Jimmy Ba合作发表ICLR论文\n\n3. 无监督学习的再思考\n​承认现实​：过去十年监督学习主导成功（如预测下一个词）\n\n​仍坚信​：无监督学习是未来关键\n\n​看好方向：\n\n变分自编码器（VAE）\n生成对抗网络（GAN）  → “深度学习中最重大的新思想之一”\n\n\n​批评旧思路：\n\n“稀疏性”非普适原则\n“慢特征”应改为“​可预测变化的特征”\n\n\n\n\n🎯 核心建模原则：将观测通过非线性变换 → 映射到状态空间 → 在该空间中动力学为线性（例：像素 → 3D坐标 → 矩阵变换视角 → 重建像素）\n\n\n五、给学习者的职业建议✅ 行动指南：\n读文献，但别读太多\n\n读一点 → 发现“哪里不对劲” → 相信直觉去改进\n\n\n永远不要停止编程\n\n复现论文 → 发现“魔鬼细节” → 培养工程直觉\n\n\n选择志同道合的导师\n\n导师若认同你的方向，会倾力指导\n\n\n面对质疑，坚持好想法\n\n“如果别人说你完全错了，那你可能真发现了什么”\n\n\n\n🎓 博士 vs 工业界？\n​现状：高校深度学习师资严重不足\n​趋势：大公司（如Google Brain）承担大量人才培养\n​建议​：不必拘泥路径，能接触前沿研究+持续实践更重要\n\n\n💬 辛顿金句： “要么你的直觉好，那就追随它；要么不好，那做什么都一样——所以不如相信直觉。”\n\n\n六、AI范式革命：从符号到向量\n\n\n传统AI（符号主义）\n辛顿主张（联结主义）\n\n\n\n思维 = 符号表达式（如逻辑公式）\n思维 =高维神经活动向量\n\n\n智能 = 推理\n智能 =表示 + 预测\n\n\n输入&#x2F;输出是字符串 → 中间也应是字符串\n输入&#x2F;输出是词 → 中间是​稠密向量（非语言）\n\n\n编程计算机\n向计算机展示（showing）\n\n\n\n🌍 辛顿断言： “我们与计算机的关系已根本改变——从编程到示范，这堪比工业革命。”\n\n\n🧩 Mermaid 脑图mindmap  root((Geoffrey Hinton))    个人历程      高中: 全息记忆启发      剑桥: 生理→哲学→心理→木匠      爱丁堡: 坚持神经网络      UCSD: 遇Rumelhart    核心贡献      玻尔兹曼机        局部学习规则        醒-睡机制        → RBM (实用化)      深度信念网络        逐层预训练        变分下界保证        融合有向/无向模型      变分方法        近似EM        变分贝叶斯(1993)        → VAE基础    Backprop真相      非原创(Werbos等)      1986 Nature论文        词嵌入雏形        特征可解释性      与大脑        进化可能实现        Recirculation(1987)        重建误差≈梯度(2007)    当前研究      胶囊网络        胶囊=多维向量        协议路由        目标: 小样本/视角不变      快权重        1973构想        2015复兴        实现真递归      无监督学习        承认监督学习成功        坚信无监督是未来        看好GAN/VAE        批评: 慢特征→可预测特征    学习建议      读文献但别太多      永远编程      选同频导师      相信直觉      博士vs工业界: 重实践    AI范式革命      传统: 符号表达式      新范式: 高维向量      关系转变: 编程 → 示范\n\n\n\n✅ ​使用说明：将上述 Mermaid 代码粘贴至支持 Mermaid v11+ 的编辑器（如 Typora、Obsidian、Mermaid Live Editor）即可生成交互式脑图。\n\n\n　　希望这份结构化总结助你深入理解辛顿的思想脉络与技术洞见。正如他所言： “伟大的想法，往往始于他人眼中的‘荒谬’。”  —— 保持好奇，勇敢探索。\n"},{"title":"第一、二章：图形学概述、向量与线性代数","url":"/blog/%E7%AC%AC%E4%B8%80%E3%80%81%E4%BA%8C%E7%AB%A0%EF%BC%9A%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%A6%82%E8%BF%B0%E3%80%81%E5%90%91%E9%87%8F%E4%B8%8E%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/","content":"第一章 图形学概述1.图形学应用场景游戏场景渲染、电影特效、动画、设计、可视化（人体三维扫描）、虚拟现实、数字绘图、模拟、GUI、字体排版等\n2.图形学包含内容：\n数学：矩阵、曲线、曲面\n\n物理学：光学、着色\n\n描述、操作三维的不同形体\n\n动画、仿真\n\n\n3.本课程包含的内容：\n光栅化\n\n光栅化是把三维空间的几何形体显示在屏幕上，是实时图形学的主要应用。实时：每秒钟生成 30 帧，否则叫做离线\n\n\n曲线、曲面\n\n如何表示一条光滑的曲线、如何表示曲面、怎么把简单曲面通过细分的方法得到更复杂的曲面，形状发生变化的时候面要如何变化，如何保持物体的拓扑结构\n\n\n光线追踪\n\n实时光线追踪技术\n\n\n动画&#x2F;模拟\n\n\n4.本课程不包含的内容：\n怎么使用 API\n\n怎么做三维建模\n\n计算机视觉：一切需要猜测的东西是计算机视觉（根据图像推测模型）。\n​​​​\nmodel 描述三维空间中形状的几何形体，或对于渲染而言描述它的材质、光照，把这些三维空间中有的东西转为一幅图（渲染），就是计算机图形学。此外，还包括纯三维空间的仿真，材质建模、材质与光线之间作用的研究等，都属于计算机图形学的范畴。\n\n\n从一张图识别出各种模型（比如识别出照片里哪些是桌子、椅子），或者图形、视频处理（中间涉及到一些推测、推理）等是计算机视觉的范畴。\n某些场景下没有严格的边界，比如 AR 需要二者的结合。\n第二章 向量与线性代数1.图形学依赖：\n数学基础：线性代数、微积分、统计\n\n数学基础：力学、光学\n\n其他杂项：信号处理、数值分析\n\n一点点美学\n\n\n2.向量（Vectors）向量表示两个内容：方向和长度，平移向量不会改变它（因为方向和长度不变）。\n​​\n一个向量除它的长度可以得到一个长度为 1 的单位向量。\n​​\n向量求和：几何上：平行四边形法则、三角形法则。\n​​\n代数上：坐标相加（笛卡尔坐标系）\n​​\n向量点乘：可以通过点乘快速得到两个向量的夹角（特别是两个向量都是方向向量，点乘后直接得到夹角的余弦）\n​​\n点乘运算满足交换律、分配律和结合律\n​​\n代数上的点乘即对应的坐标元素做乘积之后相加：\n​​\n点乘在图形学中的应用：\n找到两个向量（两个方向）之间的夹角。比如光照模型，计算光照到物体表面的法线等等\n找到一个向量到另一个向量上的投影，分解向量\n计算两个向量之间有多接近：夹角越小（点乘的结果越大）越接近。比如镜面反射计算高光点\n可以知道两个向量之间的方向是相同还是相反（正数相同、负数相反）​​​​\n\n向量叉乘叉乘后的向量同时垂直于两个原向量，叉乘得到的向量方向符合右手螺旋定则。\n​​\n叉乘不满足交换律，需要加一个负号。但满足分配律和结合律。\n​​\n代数上：\n​​​​\n叉乘在图形学中的应用：\n判定左和右\n\n判定内和外（三角形光栅化的基础）\n​​​​\n\n\n3.矩阵（Matrics）矩阵就是一堆数字，用 m 行 n 列的结构表示。\n图形学中，用矩阵实现一些移动、旋转的变换。\n​​\n矩阵乘一个数就是把矩阵中每一个数字和该数字想乘得到一个矩阵。\n矩阵乘积一定要满足前一个矩阵的列数等于后一个矩阵的行数才能实现相乘。计算方式：乘出来的结果在 m 行 b 列就去找相乘的前一个矩阵的 m 行对应的值与后一个矩阵的 n 列对应的值一一相乘后再相加。\n​​\n矩阵不满足交换律，但满足结合率和分配律：\n​​\n矩阵和向量相乘：认为向量是一个 m 乘 1 的矩阵，则可以将任意一个 n 乘 m 的矩阵与向量相乘，基于该前提实现一个向量变换（比如相对一个坐标轴翻转）\n​​\n矩阵转置​​\n单位矩阵单位矩阵只有对角线上有元素。\n如果两个矩阵相乘为单位矩阵，则该两个矩阵互为逆矩阵。\n​​\n向量点乘和叉乘写成矩阵的形式（用在旋转的推导上）\n​​\n","categories":["图形学"]},{"title":"浏览器底层运行原理","url":"/blog/%E6%B5%8F%E8%A7%88%E5%99%A8%E5%BA%95%E5%B1%82%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86/","content":"内存管理垃圾回收算法被分为两种，一个是 Major GC，主要使用了 Mark-Sweep &amp; Mark-Compact 算法，针对的是堆内存中的老生代进行垃圾回收；另外一个是 Minor GC，主要使用了 Scavenger 算法，针对于堆内存中的新生代进行垃圾回收。V8 引擎的新生代内存大小^（ 网传主流说法，没有找到具体的源码，仅做参考。）^ 32MB(64 位)、16MB(32 位) ；老生代初始内存大小为 512MB(64 位)、256MB(32 位)，默认配置下最大可以增加到 4GB。\nconst int kSystemPointerSize = sizeof(void*); // 32位 -&gt; 4；64位 -&gt; 8static const int kHeapLimitMultiplier = kSystemPointerSize / 4;// 老生代初始极值static const size_t kMaxInitialOldGenerationSize = 256 * MB * kHeapLimitMultiplier;static const size_t kOldGenerationLowMemory = 128 * MB * kHeapLimitMultiplier;\n\n\n新生代(new space)，大多数的对象开始都会被分配在这里，这个区域相对较小但是垃圾回收特别频繁，该区域被分为两半，一半用来分配内存，另一半用于在垃圾回收时将需要保留的对象复制过来。\n\nSemi Space，from space 和 to space 动态更换。\n采用Scavenge​ 算法(复制算法)进行垃圾回收。\n对象晋升：对象是否经历过一次 Scavenge 算法；To 空间的内存占比是否已经超过 25%。\n\n\n\n​​\n\n老生代(old space)，新生代中的对象在存活一段时间后就会被转移到老生代内存区，相对于新生代该内存区域的垃圾回收频率较低。老生代又分为老生代指针区和老生代数据区，前者包含大多数可能存在指向其他对象的指针的对象，后者只保存原始数据对象，这些对象没有指向其他对象的指针。\n大对象区(large object space)：存放体积超越其他区域大小的对象，每个对象都会有自己的内存，垃圾回收不会移动大对象区。\n代码区(code space)：代码对象，会被分配在这里，唯一拥有执行权限的内存区域。\nMap 区(map space)：存放 Cell 和 Map，每个区域都是存放相同大小的元素，结构简单，可以理解为隐藏类。\n\n​​\nJavaScript 在运行时，对象的属性是可以被修改的，这对于 V8 是存在不确定性的。像 C++ 这类静态语言，在编译阶段就确定对象的结构，可以直接通过偏移量来查询目标对象的各项属性值，因此运行效率非常高。V8 对每个对象做出两个假设：\n\n对象创建完成后不会添加新的属性。\n对象创建完成后不会删除属性。\n\n基于上述假设，V8 会给每个对象创建隐藏类(Hideen Class)，用于记录该对象的基础布局信息，具体包括：\n\n对象的所有属性。\n所有属性的相对偏移值。\n\n那么当 V8 访问某个对象的某个属性时，就会先去隐藏类中查找该属性相对于该对象的偏移量，也就能去内存中直接取值，从而跳过一系列的查找过程，大大提升 V8 查找对象的属性值的效率。\nV8 的每个对象都有 map 属性，该字段指向该对象的隐藏类。当两个对象的结构相同^（ 相同的属性名称；相等的属性个数；一致的属性顺序。）^时，就会复用同一个隐藏类，这样可以减少隐藏类的创建次数以及减少存储空间。而当结构发生变更时，就会重新创建隐藏类。因此在开发过程中，为提高 V8 引擎性能，需要注意以下几点：\n\n尽量使用字面量一次性初始化完整的对象属性。\n尽量保证初始化时属性的顺序一致。\n尽量避免使用 delete 方法。\n\n// --allow-natives-synta 指向同一地址，故复用同一个隐藏类const JnQ = &#123; name: &#x27;JnQ&#x27;, owner: &#x27;Qi Huang&#x27;, TL: &#x27;Sijie Cai&#x27; &#125;;const TCSplus = &#123; name: &#x27;TCS&#x27;, owner: &#x27;Guangyu Song&#x27;, TL: &#x27;Sijie Cai&#x27; &#125;;// 重新创建隐藏类 Case 1const JnQInfo = &#123;&#125;; // 新建隐藏类第 1 次JnQInfo.platform = [&#x27;Jimu&#x27;, &#x27;Juren&#x27;, &#x27;Rock&#x27;]; // 新建隐藏类第 2 次JnQInfo.member = 13; // 新建隐藏类第 3 次JnQInfo.meeting = &#x27;Firday&#x27;; // 新建隐藏类第 4 次// 重新创建隐藏类 Case 2const JnQInfo = &#123; platform: [&#x27;Jimu&#x27;, &#x27;Juren&#x27;, &#x27;Rock&#x27;], member: 13, meeting: &#x27;Firday&#x27; &#125;; // 新建隐藏类第 1 次delete JnQInfo.meeting; // 新建隐藏类第 2 次delete JnQInfo.platform; // 新建隐藏类第 3 次// 重新创建隐藏类 Case 3const jimu = &#123; member: 8, owner: &#x27;Zhihao Cao&#x27; &#125;; // 新建隐藏类第 1 次const quality = &#123; owner: &#x27;Xue Zhang&#x27;, member: 4 &#125;; // 新建隐藏类第 2 次\n\n垃圾回收\n根节点认定：全局对象；本地函数的局部变量和参数；当前嵌套调用链上的其他函数的变量和参数。\n\n标记-整理\n\n经历一次标记-清除后，内存空间可能会出现不连续的状态，即内存碎片；\n假设在老生代中有 A、B、C、D 四个对象；\n在垃圾回收的标记阶段，将对象 A 和对象 C 标记为活动的；\n在垃圾回收的整理阶段，将活动的对象往堆内存的一端移动；\n在垃圾回收的清除阶段，将活动对象左侧的内存全部回收。\n\n\n\n​​\n\n增量标记\n\n由于 JS 的单线程机制，垃圾回收的过程会阻碍主线程同步任务的执行，待执行完垃圾回收后才会再次恢复执行主任务的逻辑，这种行为被称为全停顿(stop-the-world)。在标记阶段同样会阻碍主线程的执行，一般来说，老生代会保存大量存活的对象，如果在标记阶段将整个堆内存遍历一遍，那么势必会造成严重的卡顿。\n因此，为了减少垃圾回收带来的停顿时间，V8 引擎又引入了Incremental Marking​(增量标记)的概念，即将原本需要一次性遍历堆内存的操作改为增量标记的方式，先标记堆内存中的一部分对象，然后暂停，将执行权重新交给 JS 主线程，待主线程任务执行完毕后再从原来暂停标记的地方继续标记，直到标记完整个堆内存。这个理念其实有点像 React 框架中的 Fiber 架构，只有在浏览器的空闲时间才会去遍历Fiber Tree​ 执行对应的任务，否则延迟执行，尽可能少地影响主线程的任务，避免应用卡顿，提升应用性能。\n得益于增量标记的好处，V8 引擎后续继续引入了延迟清理(lazy sweeping​)和增量式整理(incremental compaction​)，让清理和整理的过程也变成增量式的。同时为了充分利用多核 CPU 的性能，也将引入并行标记和并行清理，进一步地减少垃圾回收对主线程的影响，为应用提升更多的性能。\n\n\n\n​​\n编译解析编译型语言在程序执行之前，需要经过编译器的编译过程，并且编译之后会直接保留机器能读懂的二进制文件，这样每次运行程序时，都可以直接运行该二进制文件，而不需要再次重新编译了。比如 C&#x2F;C++、GO 等都是编译型语言。而由解释型语言编写的程序，在每次运行时都需要通过解释器对程序进行动态解释和执行。比如 JavaScript、Python 等都属于解释型语言。\n​V8 在执行过程中既有解释器 Ignition，又有编译器 TurboFan，此外较新版本的 Chrome 增加了一种中间层编译器 Maglev，V8 可以使用 jsvu 进行本地调试。\n解释编译具体步骤包括：\n\n生成抽象语法树和执行上下文\n\n词法分析，即分词(tokenize)，根据预设规则将每一行代码拆分成不可再分的 tokens。\n语法分析，即解析(parse)，根据语法规则将 tokens 组合转化为抽象语法树。\n执行上下文，代码执行过程中的环境信息。\n\n\n生成字节码\n\n字节码介于 AST 和机器码之间。字节码需要通过解析器将其转换为机器码后才能执行。\n解释器 Ignition 会根据 AST 生成字节码，并解释执行字节码。\nV8 最早并没有字节码，直接将 AST 转换为机器码效率更加高效，但机器码的内存占用远远大于字节码，这在移动端的问题更加突出。\n\n\n\n// JavaScript Code - 8 lines of codeconst foo = (day) =&gt; &#123;  const department = &#x27;Data-TnS-FE&#x27;;  const team = &#x27;JnQ&#x27;;  return day % 2 === 0 ? department : team;&#125;;for (let day=0; day &lt; 0x20227; day++) &#123;  foo(day);&#125;// V8 bytecode - 19 lines of code// --print-bytecodeCreateClosure [0], [0], #0StaCurrentContextSlot [2]LdaZeroStar11LdaUndefined...// Machine Code - 140 lines of code// --print-codeREX.W leaq rbx,[rip+0xfffffff9]REX.W cmpq rbx,rcxjz 0x174944159  &lt;+0x19&gt;movl rdx,0x84call [r13+0x50a0]int3lmovl rbx,[rcx-0xc]REX.W addq rbx,r14testb [rbx+0x16],0x20jnz 0x1149c5a00  (CompileLazyDeoptimizedCode)    ;; near builtin entry...\n\n​​\n\n执行代码\n\nIgnition 负责生成、解析和执行字节码。执行字节码的过程中如果发现一段代码被重复执行多次，就会将其标记为为热点代码(HotSpot)，那么后台的编译器 TurboFan 就会把该段热点字节码编译为更为高效的机器码(即时编译，JIT)，当再次执行这段被优化的代码时，只需要执行编译后的机器码就可以了，这样就可以兼顾代码的执行效率和内存占用。\n\n\n\n​​\n惰性解析是指解析器在解析的过程中，如果遇到函数声明，那么会跳过函数内部的代码，并不会为其生成 AST 和字节码，而仅仅生成顶层代码的 AST 和字节码。\n\n一次性解析和编译所有的 JavaScript 代码会增加编译时间，严重影响到首次执行 JavaScript 代码的速度。\n一次性解析和编译所有 JavaScript 代码会增加内存占用，解析完成的字节码和编译后的机器代码将会一直占用内存。\n\n循环机制事件循环每个渲染进程都有一个主线程负责处理 DOM、计算样式、排版布局、运行 JavaScript 代码以及响应交互行为。单线程来调度这些任务就需要消息队列和事件循环分别承担任务存储和处理的工作。\n渲染进程有专门用来接收其他进程传进来消息的 IO 线程。消息队列的任务类型有很多，如外设输入事件、文件读写、定时器、解析 DOM、样式计算、布局计算、CSS 动画等等。\n“先进先出”是队列的特点，鉴于这个属性，就需要解决两个问题。\n\n如何处理高优先级的任务。\n\n每个宏任务中都包含了一个微任务队列，宏任务执行完成后，会立即执行当前宏任务的微任务队列。\n\n\n如何解决单任务执行时间过长。\n\n\n消息队列分为执行队列和延迟队列两种。\n​​\n消息队列的任务是通过事件循环来执行的，WHATWG 规范是这么定义事件循环的宏任务执行过程：\n\n从多个消息队列中选出一个最老的任务，这个任务称为 oldestTask；\n循环系统记录任务开始执行的时间，并把这个 oldestTask 设置为当前正在执行的任务；\n当任务执行完成之后，删除当前正在执行的任务，并从对应的消息队列中删除掉这个 oldestTask；\n最后统计执行完成的时长等信息。\n\n任务调度一个事件循环模型有一个或者多个任务队列，任务队列是集合，而不是队列。因为事件循环处理模型从所选队列中选出第一个可执行的任务，而不是按照“先进先出”的原则。微任务队列不是任务队列，每个事件循环模型只且只有一个微任务队列，微任务队列是队列实现。并非所有事件都使用任务队列进行调度；许多是在其他任务执行期间派生的。\nimmediate_incoming_queue; // PostTask enqueues tasks hereimmediate_work_queue; // SequenceManager takes immediate tasks here.delayed_work_queue; // PostDelayedTask enqueues tasks here.delayed_incoming_queue; // SequenceManager takes delayed tasks here.\n\n​immediate_incoming_queue​ 存放的任务在immediate_work_queue​ 清空以后进入等待执行，为了提高效率，两个队列会在清空时进行职能互换。delayed_incoming_queue​ 中的任务，将在延迟时间到期以后进入delayed_work_queue​ 等待执行。任务产生以后会先进入到相应的incoming_queue​ 等待，work_queue​ 存放即将被执行的任务。\n延迟队列用于定时器或其他需要延时执行的任务，例如setTimeout​，由于执行任务都由渲染进程主线程来完成的缘故，定时器存在以下几个问题：\n\n如果当前任务执行时间过长，会影响定时器任务的执行。\n定时器存在嵌套关系，最短时间间隔为 4 毫秒。\n未激活的页面，定时器最小执行间隔是 1000 毫秒。\n延迟执行时间的最大值是 2147483647^(2147483647 毫秒 - Chrome、Safari、Firefox 都是以 32 个 bit 来存储延时值，超出 2*31 -1 的最大范围则会立即执行(等价于 0 毫秒)。)^ 毫秒(约 24.8 天)。\n\n异步回调有两种形式，第一种是把异步回调函数封装成一个宏任务，添加到消息队列尾部，当循环系统执行到该任务的时候执行回调函数；第二种方式的执行时机是在主函数执行结束之后、当前宏任务结束之前执行回调函数，这通常都是以微任务形式体现的。\n在当前宏任务中的 JavaScript 快执行完成时，也就在 JavaScript 引擎准备退出全局执行上下文并清空调用栈的时候，JavaScript 引擎会检查全局执行上下文中的微任务队列，然后按照顺序执行队列中的微任务。如果在执行微任务的过程中，产生了新的微任务，同样会将该微任务添加到微任务队列中，V8 引擎一直循环执行微任务队列中的任务，直到队列为空才算执行结束。也就是说在执行微任务过程中产生的新的微任务并不会推迟到下个宏任务中执行，而是在当前的宏任务中继续执行。\n早期 Mutation Event 采用观察者的设计模式，当 DOM 有变动时就会立刻触发相应的事件，这种方式属于同步回调，频繁触发会导致页面性能问题。MutationObserver 将响应函数改成异步调用，可以不用在每次 DOM 变化都触发异步调用，而是等多次 DOM 变化后，一次触发异步调用，同时为了保证实时性，MutationObserver 触发的回调会进入微任务队列。\n页面渲染​\n‍\n","categories":["浏览器"]},{"title":"第七章：z-buffer和着色","url":"/blog/%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9Az-buffer%E5%92%8C%E7%9D%80%E8%89%B2/","content":"回顾上一课：\n\n光栅化一个三角形\n\n采样\n\n反走样\n\n\n可见性&#x2F;遮挡（把三角形画在屏幕上，同时遮挡关系是对的）：\n\nz-buffer\n\npainter’s algorithm（画家算法）\n所有物体按深度排序（O(nlogn)），先把远的画上去，再把近的画上去，近的就会遮挡远的。但这种方式无法解决深度上互相遮挡的问题。\n​​\nz-buffer\n通过深度缓存维护存储每个像素当前的最小深度\n同步生成最后的结果（frame buffer）和当前看到的场景的任何一个像素对应的深度（depth buffer）。\n假设场景的点到相机的距离表示深度z，且这个值始终是正的，z越小的距离越近，越大的距离越远。\n​​\n先假设深度图上每一个像素的深度都是无限远，遍历每一个三角形的每一个像素，如果遍历到的像素深度比当前深度图记录的深度浅，就把深度图上的深度替换为这个像素的深度，否则不变。\n假设每个三角形覆盖的像素是常数项，时间复杂度O(n)。\n​​​​\n一般两个浮点数值不会一样，所以比较深度的时候一般不会出现深度一样的情况。\nMSAA采样的时候一个像素可能有多个采样点，所以是记录每个采样点的深度。\n透明物体处理不了深度。\n着色（shading）对不同物体应用不同的材质。\n一个基础的着色模型（Blinn-Phong 反射模型）\n高光、漫反射、环境光\n​​\n对于一个物体表面的点，定义一个法线方向、一个视线方向、一个光照方向，和一些物体表面的参数\n​​\n着色有局部性。不考虑其他的物体，只考虑自己。\n​​\n一个shading point周围的单位面积接收的能量和光照方向和发现方向夹角的余弦成正比。\n​​\n点光源，光线传播，每个时刻到达一个新的球壳。假如半径为1的时候，光的强度为I，则半径为r的时候，强度变为I&#x2F;r²\n​​\n从不同的角度观测同一个点的结果是一样的。\n​​\nk_(d)  漫反射的系数，表示吸收了（反射了）多少颜色颜色。\n​​\n","categories":["图形学"]},{"title":"现代浏览器架构","url":"/blog/%E7%8E%B0%E4%BB%A3%E6%B5%8F%E8%A7%88%E5%99%A8%E6%9E%B6%E6%9E%84/","content":"原文：Inside look at modern web browser\nPart 1​​\n​​\nChrome 的多进程架构图，多个渲染进程的卡片（render process）是用来表明 Chrome 会为每一个 tab 创建一个渲染进程。\nChrome 浏览器会有一个浏览器进程（browser process），这个进程会和其他进程一起协作来实现浏览器的功能。对于渲染进程（renderer process），Chrome 会尽可能为每一个 tab 甚至是页面里面的每一个 iframe 都分配一个单独的进程。\nChrome 多进程架构的好处\n多进程可以使浏览器具有很好的容错性。\n对于大多数简单的情景来说，Chrome 会为每个 tab 单独分配一个属于它们的渲染进程（render process）。举个例子，假如有三个 tab，就会有三个独立的渲染进程。当其中一个 tab 的崩溃时，可以随时关闭这个 tab 并且其他 tab 不受到影响。可是如果所有的 tab 都跑在同一个进程的话，它们就会有连带关系，一个挂全部挂。\n\n\n​​\n\n另外一个好处就是可以提供安全性和沙盒性（sanboxing）。\n因为操作系统可以提供方法让限制每个进程拥有的能力，所以浏览器可以让某些进程不具备某些特定的功能。例如，由于 tab 渲染进程可能会处理来自用户的随机输入，所以 Chrome 限制了它们对系统文件随机读写的能力。\n\n不好的地方\n那就是进程的内存消耗。由于每个进程都有各自独立的内存空间，所以它们不能像存在于同一个进程的线程那样共用内存空间，这就造成了一些基础的架构（例如 V8 JavaScript 引擎）会在不同进程的内存空间同时存在的问题，这些重复的内容会消耗更多的内存。所以为了节省内存，Chrome 会限制被启动的进程数目，当进程数达到一定的界限后，Chrome 会将访问同一个网站的 tab 都放在一个进程里面跑。\n\n\n网站隔离网站隔离功能会为网站内不同站点的 iframe 分配一个独立的渲染进程。之前说过 Chrome 会为每个 tab 分配一个单独的渲染进程，可是如果一个 tab 只有一个进程的话不同站点的 iframe 都会跑在这个进程里面，这也意味着它们会共享内存，这就有可能会破坏同源策略。同源策略是浏览器最核心的安全模型，它可以禁止网站在未经同意的情况下去获取另外一个站点的数据，因此绕过同源策略是很多安全攻击的主要目的。而进程隔离（proces isolation）是隔离网站最好最有效的办法了。这样每一个跨站点的 iframe 都会拥有一个独立的渲染进程。\n​​\nPart 2输入 url 到显示（一次导航）发生了什么浏览器进程有很多负责不同工作的线程（worker thread），其中包括绘制浏览器顶部按钮和导航栏输入框等组件的 UI 线程（UI thread）、管理网络请求的网络线程（network thread）、以及控制文件读写的存储线程（storage thread）等。当在导航栏里面输入一个 URL 的时候，其实就是 UI 线程在处理的输入。\n​​\n一次简单的导航1. 处理输入当用户开始在导航栏上面输入内容的时候，UI 线程（UI thread）做的第一件事就是询问：“输入的字符串是一些搜索的关键词（search query）还是一个 URL 地址呢？”。因为对于 Chrome 浏览器来说，导航栏的输入既可能是一个可以直接请求的域名还可能是用户想在搜索引擎（例如 Google）里面搜索的关键词信息，所以当用户在导航栏输入信息的时候 UI 线程要进行一系列的解析来判定是将用户输入发送给搜索引擎还是直接请求输入的站点资源。\n​​\n2. 开始导航当用户按下回车键的时候，UI 线程会叫网络线程（network thread）初始化一个网络请求来获取站点的内容。这时候 tab 上会展示一个提示资源正在加载中的旋转圈圈，而且网络线程会进行一系列诸如 DNS 寻址以及为请求建立 TLS 连接的操作。这时如果网络线程收到服务器的 HTTP 301 重定向响应，它就会告知 UI 线程进行重定向然后它会再次发起一个新的网络请求。\n​​\n3. 读取响应网络线程在收到 HTTP 响应的主体（payload）流（stream）时，在必要的情况下它会先检查一下流的前几个字节以确定响应主体的具体媒体类型（MIME Type）。响应主体的媒体类型一般可以通过 HTTP 头部的 Content-Type 来确定，不过 Content-Type 有时候会缺失或者是错误的，这种情况下浏览器就要进行 MIME 类型嗅探来确定响应类型了。MIME 类型嗅探并不是一件容易的事情，可以从 Chrome 的源代码的注释来了解不同浏览器是如何根据不同的 Content-Type 来判断出主体具体是属于哪个媒体类型的。\n​​\n如果响应的主体是一个 HTML 文件，浏览器会将获取的响应数据交给渲染进程（renderer process）来进行下一步的工作。如果拿到的响应数据是一个压缩文件（zip file）或者其他类型的文件，响应数据就会交给下载管理器（download manager）来处理。\n​​\n网络线程在把内容交给渲染进程之前还会对内容做 SafeBrowsing 检查。如果请求的域名或者响应的内容和某个已知的病毒网站相匹配，网络线程会给用户展示一个警告的页面。除此之外，网络线程还会做 CORB（Cross Origin Read Blocking）检查来确定那些敏感的跨站数据不会被发送至渲染进程。\n4. 查找渲染进程在网络线程做完所有的检查后并且能够确定浏览器应该导航到该请求的站点，它就会告诉 UI 线程所有的数据都已经被准备好了。UI 线程在收到网络线程的确认后会为这个网站寻找一个渲染进程（renderer process）来渲染界面。\n​\n由于网络请求可能需要长达几百毫秒的时间才能完成，为了缩短导航需要的时间，浏览器会在之前的一些步骤里面做一些优化。例如在第二步中当 UI 线程发送 URL 链接给网络线程后，它其实已经知晓它们要被导航到哪个站点了，所以在网络线程干活的时候，UI 线程会主动地为这个网络请求启动一个渲染线程。如果一切顺利的话（没有重定向之类的东西出现），网络线程准备好数据后页面的渲染进程已经就准备好了，这就节省了新建渲染进程的时间。不过如果发生诸如网站被重定向到不同站点的情况，刚刚那个渲染进程就不能被使用了，它会被摒弃，一个新的渲染进程会被启动。\n5. 提交导航到这一步的时候，数据和渲染进程都已经准备好了，浏览器进程（browser process）会通过 IPC 告诉渲染进程去提交本次导航（commit navigation）。除此之外浏览器进程还会将刚刚接收到的响应数据流传递给对应的渲染进程让它继续接收到来的 HTML 数据。一旦浏览器进程收到渲染线程的回复说导航已经被提交了（commit），导航这个过程就结束了，文档的加载阶段（document loading phase）会正式开始。\n这时导航栏会被更新，安全指示符（security indicator）和站点设置 UI（site settings UI）会展示新页面相关的站点信息。当前 tab 的会话历史（session history）也会被更新，这样当点击浏览器的前进和后退按钮也可以导航到刚刚导航完的页面。为了方便在关闭了 tab 或窗口（window）的时候还可以恢复当前 tab 和会话（session）内容，当前的会话历史会被保存在磁盘上面。\n​​\n额外步骤：初始加载完成（Initial load complete）当导航提交完成后，渲染进程开始着手加载资源以及渲染页面。一旦渲染进程“完成”（finished）渲染，它会通过 IPC 告知浏览器进程（注意这发生在页面上所有帧（frames）的 onload 事件都已经被触发了而且对应的处理函数已经执行完成了的时候），然后 UI 线程就会停止导航栏上旋转的圈圈。\n我这里用到“完成”这个词，因为后面客户端的 JavaScript 还是可以继续加载资源和改变视图内容的。\n​​\n导航到不同的站点如果这时用户在导航栏上输入一个不一样的 URL 会发生什么呢？如果是这样，浏览器进程会重新执行一遍之前的那几个步骤来完成新站点的导航。不过在浏览器进程做这些事情之前，它需要让当前的渲染页面做一些收尾工作，具体就是询问一下当前的渲染进程需不需要处理一下beforeunload事件。\nbeforeunload可以在用户重新导航或者关闭当前 tab 时给用户展示一个“确定要离开当前页面吗？”的二次确认弹框。浏览器进程之所以要在重新导航的时候和当前渲染进程确认的原因是，当前页面发生的一切（包括页面的 JavaScript 执行）是不受它控制而是受渲染进程控制，所以它也不知道里面的具体情况。\n**注意：不要随便给页面添加 beforeunload 事件监听，**定义的监听函数会在页面被重新导航的时候执行，因此这会增加重导航的时延。beforeunload 事件监听函数只有在十分必要的时候才能被添加，例如用户在页面上输入了数据，并且这些数据会随着页面消失而消失。\n​​\n如果重新导航是在页面内被发起的呢？例如用户点击了页面的一个链接或者客户端的 JavaScript 代码执行了诸如window.location &#x3D; &quot;​**​&quot;的代码。这种情况下，渲染进程会自己先检查一个它有没有注册beforeunload**事件的监听函数，如果有的话就执行，执行完后发生的事情就和之前的情况没什么区别了，唯一的不同就是这次的导航请求是由渲染进程给浏览器进程发起的。\n如果是重新导航到不同站点（different site）的话，会有另外一个渲染进程被启动来完成这次重导航，而当前的渲染进程会继续处理现在页面的一些收尾工作，例如unload事件的监听函数执行。Overview of page lifecycle states这篇文章会介绍页面所有的生命周期状态，the Page Lifecycle API会教如何在页面中监听页面状态的变化。\n​\nService Worker 的情景这个导航过程最近发生的一个改变是引进了service worker的概念。因为 Service worker 可以用来写网站的网络代理（network proxy），所以开发者可以对网络请求有更多的控制权，例如决定哪些数据缓存在本地以及哪些数据需要从网络上面重新获取等等。如果开发者在 service worker 里设置了当前的页面内容从缓存里面获取，当前页面的渲染就不需要重新发送网络请求了，这就大大加快了整个导航的过程。\n这里要重点留意的是 service worker 其实只是一些跑在渲染进程里面的 JavaScript 代码。那么问题来了，当导航开始的时候，浏览器进程是如何判断要导航的站点存不存在对应的 service worker 并启动一个渲染进程去执行它的呢？\n其实 service worker 在注册的时候，它的作用范围（scope）会被记录下来（可以通过文章The Service Worker Lifecycle了解更多关于 service worker 作用范围的信息）。在导航开始的时候，网络线程会根据请求的域名在已经注册的 service worker 作用范围里面寻找有没有对应的 service worker。如果有命中该 URL 的 service worker，UI 线程就会为这个 service worker 启动一个渲染进程（renderer process）来执行它的代码。Service worker 既可能使用之前缓存的数据也可能发起新的网络请求。\n​​\n​​\n导航预加载- Navigation Preload在上面的例子中，应该可以感受到如果启动的 service worker 最后还是决定发送网络请求的话，浏览器进程和渲染进程这一来一回的通信包括 service worker 启动的时间其实增加了页面导航的时延。导航预加载就是一种通过在 service worker 启动的时候并行加载对应资源的方式来加快整个导航过程效率的技术。预加载资源的请求头会有一些特殊的标志来让服务器决定是发送全新的内容给客户端还是只发送更新了的数据给客户端。\n​​\nPart3渲染进程处理页面内容渲染进程负责标签（tab）内发生的所有事情。在渲染进程里面，主线程（main thread）处理了绝大多数你发送给用户的代码。如果你使用了 web worker 或者 service worker，相关的代码将会由工作线程（worker thread）处理。合成（compositor）以及光栅（raster）线程运行在渲染进程里面用来高效流畅地渲染出页面内容。\n渲染进程的主要任务是将 HTML，CSS，以及 JavaScript 转变为我们可以进程交互的网页内容。\n​​\n解析前面文章提到，渲染进程在导航结束的时候会收到来自浏览器进程提交导航（commit navigation）的消息，在这之后渲染进程就会开始接收 HTML 数据，同时主线程也会开始解析接收到的文本数据（text string）并把它转化为一个 DOM（Document Object Model）对象\nDOM 对象既是浏览器对当前页面的内部表示，也是 Web 开发人员通过 JavaScript 与网页进行交互的数据结构以及 API。\n如何将 HTML 文档解析为 DOM 对象是在HTML 标准中定义的。不过在你的 web 开发生涯中，你可能从来没有遇到过浏览器在解析 HTML 的时候发生错误的情景。这是因为浏览器对 HTML 的错误容忍度很大。举些例子：如果一个段落缺失了闭合 p 标签（），这个页面还是会被当做为有效的 HTML 来处理；Hi! I’m Chrome! (闭合 b 标签写在了闭合 i 标签的前面) ，虽然有语法错误，不过浏览器会把它处理为 Hi! I’m Chrome!。如果你想知道浏览器是如何对这些错误进行容错处理的，可以参考 HTML 规范里面的An introduction to error handling and strange cases in the parser内容。\n子资源加载除了 HTML 文件，网站通常还会使用到一些诸如图片，CSS 样式以及 JavaScript 脚本等子资源。这些文件会从缓存或者网络上获取。主线程会按照在构建 DOM 树时遇到各个资源的循序一个接着一个地发起网络请求，可是为了提升效率，浏览器会同时运行“预加载扫描”（preload scanner）程序。如果在 HTML 文档里面存在诸如或者这样的标签，预加载扫描程序会在 HTML 解析器生成的 token 里面找到对应要获取的资源，并把这些要获取的资源告诉浏览器进程里面的网络线程。\n​​\nJavaScript 会阻塞 HTML 的解析过程当 HTML 解析器碰到 script 标签的时候，它会停止 HTML 文档的解析从而转向 JavaScript 代码的加载，解析以及执行。为什么要这样做呢？因为 script 标签中的 JavaScript 可能会使用诸如document.write()​​ 这样的代码改变文档流（document）的形状，从而使整个 DOM 树的结构发生根本性的改变（HTML 规范里面的overview of the parsing model 部分有很好的示意图）。因为这个原因，HTML 解析器不得不等 JavaScript 执行完成之后才能继续对 HTML 文档流的解析工作。如果你想知道 JavaScipt 的执行过程都发生了什么，V8 团队有很多关于这个话题的讨论。\n给浏览器一点如何加载资源的提示Web 开发者可以通过很多方式告诉浏览器如何才能更加优雅地加载网页需要用到的资源。如果你的 JavaScript 不会使用到诸如document.write()​​​ 的方式去改变文档流的内容的话，你可以为 script 标签添加一个async或者defer属性来使 JavaScript 脚本进行异步加载。当然如果能满足到你的需求，你也可以使用JavaScript Module。\n同时&lt;link rel=&quot;preload&quot;&gt;​​ 资源预加载可以用来告诉浏览器这个资源在当前的导航肯定会被用到，你想要尽快加载这个资源。更多相关的内容，你可阅读Resource Prioritization - Getting the Browser to Help You这篇文章。\n样式计算-Style calculation拥有了 DOM 树我们还不足以知道页面的外貌，因为我们通常会为页面的元素设置一些样式。主线程会解析页面的 CSS 从而确定每个 DOM 节点的计算样式（computed style）。计算样式是主线程根据 CSS 样式选择器（CSS selectors）计算出的每个 DOM 元素应该具备的具体样式，你可以打开 devtools 来查看每个 DOM 节点对应的计算样式。\n​​\n即使你的页面没有设置任何自定义的样式，每个 DOM 节点还是会有一个计算样式属性，这是因为每个浏览器都有自己的默认样式表。因为这个样式表的存在，页面上的 h1 标签一定会比 h2 标签大，而且不同的标签会有不同的 magin 和 padding。如果你想知道 Chrome 的默认样式是长什么样的，你可以直接查看代码。\n布局-Layout前面这些步骤完成之后，渲染进程就已经知道页面的具体文档结构以及每个节点拥有的样式信息了，可是这些信息还是不能最终确定页面的样子。举个例子，假如你现在想通过电话告诉你的朋友你身边的一幅画的内容：“画布上有一个红色的大圆圈和一个蓝色的正方形”，单凭这些信息你的朋友是很难知道这幅画具体是什么样子的，因为他不知道大圆圈和正方形具体在页面的什么位置，是正方形在圆圈前面呢还是圆圈在正方形的前面。\n渲染网页也是同样的道理，只知道网站的文档流以及每个节点的样式是远远不足以渲染出页面内容的，还需要通过布局（layout）来计算出每个节点的几何信息（geometry）。布局的具体过程是：主线程会遍历刚刚构建的 DOM 树，根据 DOM 节点的计算样式计算出一个布局树（layout tree）。布局树上每个节点会有它在页面上的 x，y 坐标以及盒子大小（bounding box sizes）的具体信息。布局树长得和先前构建的 DOM 树差不多，不同的是这颗树只有那些可见的（visible）节点信息。举个例子，如果一个节点被设置为了display:none，这个节点就是不可见的就不会出现在布局树上面（visibility:hidden的节点会出现在布局树上面，你可以思考一下这是为什么）。同样的，如果一个伪元素（pseudo class）节点有诸如p::before{content:&quot;Hi!&quot;}​ 这样的内容，它会出现在布局上，而不存在于 DOM 树上。\n​​\n即使页面的布局十分简单，布局这个过程都是非常复杂的。例如页面就是简单地从上而下展示一个又一个段落，这个过程就很复杂，因为需要考虑段落中的字体大小以及段落在哪里需要进行换行之类的东西，它们都会影响到段落的大小以及形状，继而影响到接下来段落的布局。\n如果考虑到 CSS 的话将会更加复杂，因为 CSS 是一个很强大的东西，它可以让元素悬浮（float）到页面的某一边，还可以遮挡住页面溢出的（overflow）元素，还可以改变内容的书写方向，所以单是想一下就知道布局这个过程是一个十分艰巨和复杂的任务。对于 Chrome 浏览器，有一整个负责布局过程的工程师团队。如果想知道他们工作的具体内容，他们在BlinkOn Conference上面的相关讨论被录制了下来。\n画-Paint知道了 DOM 节点以及它的样式和布局其实还是不足以渲染出页面来的。为什么呢？举个例子，假如你现在想对着一幅画画一幅一样的画，你已经知道了画布上每个元素的大小，形状以及位置，你还是得思考一下每个元素的绘画顺序，因为画布上的元素是会互相遮挡的（z-index）。\n举个例子，如果页面上的某些元素设置了z-index属性，绘制元素的顺序就会影响到页面的正确性。\n​​\n在绘画这个步骤中，主线程会遍历之前的到的布局树（layout tree）来生成一系列的绘画记录（paint records）。绘画记录是对绘画过程的注释，例如“首先画背景，然后是文本，最后画矩形”。如果你曾经在 canvas 画布上有使用过 JavaScript 绘制元素，你可能会觉着这个过程不是很陌生。\n​​\n高成本的渲染管线（rendering pipeline）更新关于渲染管线有一个十分重要的点就是管线的每一步都要使用到前一步的结果来生成新的数据，这就意味着如果某一步的内容发生了改变的话，这一步后面所有的步骤都要被重新执行以生成新的记录。举个例子，如果布局树有些东西被改变了，文档上那些被影响到的部分的绘画顺序是要重新生成的。\n\n如果你的页面元素有动画效果（animating），浏览器就不得不在每个渲染帧的间隔中通过渲染管线来更新页面的元素。我们大多数显示器的刷新频率是一秒钟 60 次（60fps），如果你在每个渲染帧的间隔都能通过管线移动元素，人眼就会看到流畅的动画效果。可是如果管线更新时间比较久，动画存在丢帧的状况的话，页面看起来就会很“卡顿”。\n​​\n即使您的渲染操作跟上屏幕刷新，这些计算也在主线程上运行，这意味着当您的应用程序运行 JavaScript 时它可能会被阻塞。\n​​\n对于这种情况，你可以将要被执行的 JavaScript 操作拆分为更小的块然后通过requestAnimationFrame​ 这个 API 把他们放在每个动画帧中执行。想知道更多关于这方面的信息的话，可以参考Optimize JavaScript Execution。当然你还可以将 JavaScript 代码放在WebWorkers中执行来避免它们阻塞主线程。\n​​\n合成如何绘制一个页面？到目前为止，浏览器已经知道了关于页面以下的信息：文档结构，元素的样式，元素的几何信息以及它们的绘画顺序。那么浏览器是如何利用这些信息来绘制出页面来的呢？将以上这些信息转化为显示器的像素的过程叫做光栅化（rasterizing）。\n可能一个最简单的做法就是只光栅化视口内（viewport）的网页内容。如果用户进行了页面滚动，就移动光栅帧（rastered frame）并且光栅化更多的内容以补上页面缺失的部分。Chrome 的第一个版本其实就是这样做的。然而，对于现代的浏览器来说，它们往往采取一种更加复杂的叫做合成（compositing）的做法。\n\n什么是合成？合成是一种将页面分成若干层，然后分别对它们进行光栅化，最后在一个单独的线程 - 合成线程（compositor thread）里面合并成一个页面的技术。当用户滚动页面时，由于页面各个层都已经被光栅化了，浏览器需要做的只是合成一个新的帧来展示滚动后的效果罢了。页面的动画效果实现也是类似，将页面上的层进行移动并构建出一个新的帧即可。\n你可以通过Layers panel在 DevTools 查看你的网站是如何被浏览器分成不同的层的。\n\n页面分层为了确定哪些元素需要放置在哪一层，主线程需要遍历渲染树来创建一棵层次树（Layer Tree）（在 DevTools 中这一部分工作叫做“Update Layer Tree”）。如果页面的某些部分应该被放置在一个单独的层上面（滑动菜单）可是却没有的话，你可以通过使用will-change​ CSS 属性来告诉浏览器对其分层。\n​​\n你可能会想要给页面上所有的元素一个单独的层，然而当页面的层超过一定的数量后，层的合成操作要比在每个帧中光栅化页面的一小部分还要慢，因此衡量你应用的渲染性能是十分重要的一件事情。想要获取关于这方面的更多信息，可以参考文章Stick to Compositor-Only Properties and Manage Layer Count。\n在主线程之外光栅化和合成页面一旦页面的层次树创建出来并且页面元素的绘制顺序确定后，主线程就会向合成线程（compositor thread）提交这些信息。然后合成线程就会光栅化页面的每一层。因为页面的一层可能有整个网页那么大，所以合成线程需要将它们切分为一块又一块的小图块（tiles）然后将图块发送给一系列光栅线程（raster threads）。光栅线程会栅格化每个图块并且把它们存储在 GPU 的内存中。\n​​\n合成线程可以给不同的光栅线程赋予不同的优先级（prioritize），进而使那些在视口中的或者视口附近的页面可以先被光栅化。为了响应用户对页面的放大和缩小操作，页面的图层（layer）会为不同的清晰度配备不同的图块。\n当图层上面的图块都被栅格化后，合成线程会收集图块上面叫做绘画四边形（draw quads）的信息来构建一个合成帧（compositor frame）。\n\n绘画四边形：包含图块在内存的位置以及图层合成后图块在页面的位置之类的信息。\n合成帧：代表页面一个帧的内容的绘制四边形集合。\n\n上面的步骤完成之后，合成线程就会通过 IPC 向浏览器进程（browser process）提交（commit）一个渲染帧。这个时候可能有另外一个合成帧被浏览器进程的 UI 线程（UI thread）提交以改变浏览器的 UI。这些合成帧都会被发送给 GPU 从而展示在屏幕上。如果合成线程收到页面滚动的事件，合成线程会构建另外一个合成帧发送给 GPU 来更新页面。\n​​\n合成的好处在于这个过程没有涉及到主线程，所以合成线程不需要等待样式的计算以及 JavaScript 完成执行。这也就是为什么说只通过合成来构建页面动画是构建流畅用户体验的最佳实践的原因了。如果页面需要被重新布局或者绘制的话，主线程一定会参与进来的。\n从浏览器的角度来看输入事件当你听到“输入事件”（input events）的时候，你可能只会想到用户在文本框中输入内容或者对页面进行了点击操作，可是从浏览器的角度来看的话，输入其实代表着来自于用户的任何手势动作（gesture）。所以用户滚动页面​，触碰屏幕​ 以及移动鼠标​ 等操作都可以看作来自于用户的输入事件。\n当用户做了一些诸如触碰屏幕的手势动作时，浏览器进程（browser process）是第一个可以接收到这个事件的地方。可是浏览器进程只能知道用户的手势动作发生在什么地方而不知道如何处理，这是因为标签内（tab）的内容是由页面的渲染进程（render process）负责的。因此浏览器进程会将事件的类型（如touchstart​）以及坐标（coordinates）发送给渲染进程。为了可以正确地处理这个事件，渲染进程会找到事件的目标对象（target）然后运行这个事件绑定的监听函数（listener）。\n​​\n合成线程接收到输入事件如果当前页面不存在任何用户事件的监听器（event listener），合成线程完全不需要主线程的参与就能创建一个新的合成帧来响应事件。可是如果页面有一些事件监听器（event listeners）呢？合成线程是如何判断出这个事件是否需要路由给主线程处理的呢？\n理解非快速滚动区域 - non-fast scrollable region因为页面的 JavaScript 脚本是在主线程（main thread）中运行的，所以当一个页面被合成的时候，合成线程会将页面那些注册了事件监听器的区域标记为“非快速滚动区域”（Non-fast Scrollable Region）。由于知道了这些信息，当用户事件发生在这些区域时，合成线程会将输入事件发送给主线程来处理。如果输入事件不是发生在非快速滚动区域，合成线程就无须主线程的参与来合成一个新的帧。\n​​\n编写事件处理程序时要注意Web 开发的一个常见的模式是事件委托（event delegation）。由于事件会冒泡，你可以给顶层的元素绑定一个事件监听函数来作为其所有子元素的事件委托者，这样子节点的事件就可以统一被顶层的元素处理了。因此你可能看过或者写过类似于下面的代码：\ndocument.body.addEventListener(&quot;touchstart&quot;, (event) =&gt; &#123;  if (event.target === area) &#123;    event.preventDefault();  &#125;&#125;);\n\n只用一个事件监听器就可以服务到所有的元素，乍一看这种写法还是挺实惠的。可是，如果你从浏览器的角度去看一下这段代码，你会发现上面给 body 元素绑定了事件监听器后其实是将整个页面都标记为一个非快速滚动区域，这就意味着即使你页面的某些区域压根就不在乎是不是有用户输入，当用户输入事件发生时，合成线程每次都会告知主线程并且会等待主线程处理完它才干活。因此这种情况下合成线程就丧失提供流畅用户体验的能力了（smooth scrolling ability）。\n​​\n为了减轻这种情况的发生，您可以为事件监听器传递passive：true​ 选项。 这个选项会告诉浏览器您仍要在主线程中侦听事件，可是合成线程也可以继续合成新的帧。\ndocument.body.addEventListener(  &quot;touchstart&quot;,  (event) =&gt; &#123;    if (event.target === area) &#123;      event.preventDefault();    &#125;  &#125;,  &#123; passive: true &#125;);\n\n检查事件是否可取消假设您在页面中有一个框，您希望将滚动方向限制为仅水平滚动。\n在您的指针事件中使用passive: true​ 选项意味着页面滚动可以平滑，但垂直滚动可能已经在您想要的时间开始，preventDefault​ 以限制滚动方向。您可以使用方法对此进行检查event.cancelable​。\n​​\ndocument.body.addEventListener(  &quot;pointermove&quot;,  (event) =&gt; &#123;    if (event.cancelable) &#123;      event.preventDefault(); // block the native scroll      /*       *  do what you want the application to do here       */    &#125;  &#125;,  &#123; passive: true &#125;);\n\n或者，您可以使用 CSS 规则来touch-action​ 完全消除事件处理程序。\n#area &#123;  touch-action: pan-x;&#125;\n\n查找事件的目标对象（event target）当合成线程向主线程发送输入事件时，主线程要做的第一件事是通过命中测试（hit test）去找到事件的目标对象（target）。具体的命中测试流程是遍历在渲染流水线中生成的绘画记录（paint records）来找到输入事件出现的 x, y 坐标上面描绘的对象是哪个。\nHit test：判断用户的鼠标或触摸点是否与页面上的某个元素相交的过程。它是一种消耗性能的操作，因为浏览器需要遍历页面上的所有元素，从最顶层开始，找到与用户输入点重叠的元素​^1^。\n​​\n最小化发送给主线程的事件数对于用户输入来说，触摸屏一般一秒钟会触发 60 到 120 次点击事件，而鼠标一般则会每秒触发 100 次事件，因此输入事件的触发频率其实远远高于我们屏幕的刷新频率。\n如果每秒将诸如touchmove​ 这种连续被触发的事件发送到主线程 120 次，因为屏幕的刷新速度相对来说比较慢，它可能会触发过量的命中测试以及 JavaScript 代码的执行。\n​​\n为了最大程度地减少对主线程的过多调用，Chrome 会合并连续事件（例如wheel​，mousewheel​，mousemove​，pointermove​，touchmove​），并将调度延迟到下一个requestAnimationFrame​ 之前。\n​​\n任何诸如keydown​，keyup​，mouseup​，mousedown​，touchstart​ 和touchend​ 等相对不怎么频繁发生的事件都会被立即派送给主线程。\n使用 getCoalesecedEvents 来获取帧内（intra-frame）事件对于大多数 web 应用来说，合并事件应该已经足够用来提供很好的用户体验了，然而，如果你正在构建的是一个根据用户的touchmove​ 坐标来进行绘图的应用的话，合并事件可能会使页面画的线不够顺畅和连续。在这种情况下，你可以使用鼠标事件的getCoalescedEvents​ 来获取被合成的事件的详细信息。\n​​\nwindow.addEventListener(&#x27;pointermove&#x27;, event =&gt; &#123;    const events = event.getCoalescedEvents();    for (let event of events) &#123;        const x = event.pageX;        const y = event.pageY;        // draw a line using x and y coordinates.    &#125;&#125;);\n\ndone！","categories":["浏览器"]},{"title":"第三章：变换","url":"/blog/%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%8F%98%E6%8D%A2/","content":"变换本章学习内容：\n\n为什么学习变换\n2 维空间变换：旋转、缩放和切片\n齐次坐标\n变换组合（不同的变换组合形新的变换）\n3 维空间变换\n\n为什么学习变换变换分为：模型变换、视图变换\n变换的重要应用：\nmodeling translation：描述摄像机的运动（位置移动）\nmodeling rotation：机器人动画关节转动，逆运动学\nmodeling scale：皮克斯开场动画 \nviewing：3 维到 2 维投影\n二维变换scale matrix 缩放\n​​\nreflection matrix 反射（对称）\n​​\nshear matrix 切变\n​​\nrotation matrix 旋转\n​​\n（同维度的）矩阵乘输入坐标可以得到输出到坐标叫做线性变换\n齐次坐标平移变换不能直接表示为矩阵乘坐标，需要加一个向量\n​​\n引入齐次坐标是为了找到一个解决方法统一表示二维变换\n​\n​​​​\n线性变化 + 平移可以统称为仿射变换，这种仿射变换都可以都可以转换为齐次坐标的形式。用一个矩阵可以统一所有的操作\n​​\n最后一行永远是 0 0 1\n​​\n逆变换（变换操作反过来，乘以变换的逆矩阵）\n​​\n变换组合​​\n先平移再旋转\n​​\n先旋转再平移\n​​\n复杂的变换可以通过简单的变换得到\n变换的顺序非常重要（矩阵乘法的顺序影响结果）\n变换组合从右到左应用矩阵\n​\n​​​\n变换分解\n如果希望在非原点旋转，可以把旋转点平移到原点后再进行旋转，旋转后再平移回去\n​​\n三维变换与 2 维类似\n​​\n","categories":["图形学"]},{"title":"第九章：重心坐标、纹理","url":"/blog/%E7%AC%AC%E4%B9%9D%E7%AB%A0%EF%BC%9A%E9%87%8D%E5%BF%83%E5%9D%90%E6%A0%87%E3%80%81%E7%BA%B9%E7%90%86/","content":"着色 1-2\n\nBlinn-Phong 反射模型（\n\n高光、漫反射、环境光，如何定义材质不同的表面和光线如何作用，可以得到不同的外观\n\n\n着色模型&#x2F;频率\n\nflat shading、gouraud shading、Phong shading\n\n\n实时渲染管线（vertax processing，fragment processing）\n\n纹理映射\n\n\n本节课\n着色 3\n\n重心坐标（插值）\n纹理怎么贴\n纹理的应用\n\n重心坐标\n为什么要做插值？\n\n希望在属性三角形内部做一个平滑的过渡\n\n需要插值哪些内容？\n\n纹理的坐标：三角形不同的顶点可以对应纹理的一个顶点，那么三角形内部就可以对应纹理的不同坐标\n颜色：逐顶点插值得到三角形内部的颜色\n法线\n\n如何在三角形内部做属性的插值？\n\n引入重心坐标\n\n什么是重心坐标​​​​\n三角形平面内的任意（x,y）都可以表示为顶点的线性组合\n如果这个点要在三角形内，α，β，γ 必须都为非负数\n​​\n可以通过面积比计算 α，β，γ，已经一个点的坐标和三个顶点的坐标，做叉乘可以计算每个三角形对面积\n​​\n三角形的重心，把三角形等面积地分为了三部分，因此重心坐标 α，β，γ 都是 1&#x2F;3。\n​​\n也可以用公式进行计算\n​​\n得到三角形里任意一个点的重心坐标后，就可以对属性（颜色、法线、深度）做线性插值。\n重心坐标问题：在投影变换下重心坐标不能保持不变。所以做插值的时候，如果取的是三维空间中的坐标，只能在三维空间下做插值，不能投影到二维再做插值。\n纹理应用​\n每个屏幕上的采样点坐标对应一个纹理坐标，设置采样颜色为纹理颜色。\n纹理应用过程中会遇到一些问题：纹理放大\n如果纹理图片太小了\n​​\nNearest：一个屏幕上的像素点对应的纹理坐标可能是小数，可以四舍五入为整数，使用用整数对应的纹理像素（texel），即多个像素可能对应同一个纹素。\nBilinear（双线性插值）平滑过渡：\n先水平方向做插值，再竖直方向做插值。（方向反过来也是一样）\n​​\nBicubic 插值：取临近的 16 个点。\n如果纹理图片太大了\n​​\n一个像素覆盖多个纹素，直接用像素中心点采样会出现走样问题\n​​\n反走样用超采样的方式，一个像素采用多个采样点进行采样，但这样会造成很大的成本\n​​\n可以采用另一种方式：Range Query，给定一块区域，快速求出其平均值。\nMipmap：快速，近似，正方形的范围查询。\n渲染之前，先生成 Mipmap\n每层像素小一半\n​​\n计算机视觉里面会用图像金字塔表示\n​​\n最后的存储量是之前的 3&#x2F;4。用四个像素中心点投影到纹理坐标，像素点最大的连线模拟纹理坐标中一个对应的一个方形像素的边长。\n​​\nD 是层数，L 是一个屏幕像素对应的纹理像素。求出在第几层一个屏幕像素对应的纹理像素会变成一个像素大小，就用这一层的 MipMap，快速求出范围平均值。\n​​\n但这样查询可能出现不连续的问题，比如在近的地方用低层，远的地方用高层，但是每一层之间是不连续的。\n如果要求两层中间的值，这个时候又可以用双线性插值把两层的结果求出来，再对两层求出来的值合在一起再在层与层之间做线性插值。即三线形插值：\n​​\n三线形插值的结果就是连续的：\n​​\n但由于 mipmap 限制在方块区域内，且插值都是近似结果，所以会出现 OverBlur 现象\n​​\n可以用各向异性过滤（Anisotropic）来解决\n​​\n分层时把图片长宽方向压缩，这样屏幕像素就可以对应纹理坐标系中的一个矩形区域，而不局限于一个方形区域。\n​​\n各向异性过滤（RipMaps）要三倍的额外存储空间​​\n对于斜着的矩形区域还是不能正常模拟，因此还有其他的过滤方式：\nEWA 过滤\n任意一个不规则的形状都可以拆成多个圆形，覆盖在不规则的形状上，每次查询一个圆形，多次查询。\n​​\n","categories":["图形学"]},{"title":"第二十一章：Animation、Simulation","url":"/blog/%E7%AC%AC%E4%BA%8C%E5%8D%81%E4%B8%80%E7%AB%A0%EF%BC%9AAnimation%E3%80%81Simulation/","content":"Animation&#x2F;Simulation\n计算机动画介绍：\n\n历史\n基本制作方法：关键帧\n物理模拟方法\n运动学\nrigging（绑定动画）\n\n动画最初的定义“让东西动起来”：\n\n一种交流的工具，展示动起来的东西\n美学\n\n对于建模或者几何的拓展\n\n把 3D 模型延伸到时间的纬度\n\n动画怎么制作\n\n把很多图按顺序，按一定速度去播放（人眼有视觉暂留的效果）\n\n虚拟现实为了让人们带头戴设备不晕，对帧率要求非常高（2 只眼睛必须达到 90fps）​​\n动画的发展​​\n电影技术的历史最早电影技术用于科学研究（比如生物学研究）​​\n第一部手绘 Feature-Length 动画​​\n第一部数字动画​​\n早期计算机动画​​\n电脑生成的恐龙​​\n玩具总动员（里程碑式的，整个电影都是用 CG 生成的，用光栅化的效果生成阴影）​​\n关键帧\n关键帧能定义动画的总的走向\n10 年前（食破天惊）​​\n近年（冰雪奇缘 2）​​\n​​关键帧插值​​\n线性插值不够连续，所以去要用到一些样条去做到更光滑的插值​​\n物理模拟牛顿第二定律：F&#x3D;ma，只要知道一些初始条件，比如物体的初始位置，受到的力，可以动态算出物体的位置。\n物体仿真\n建立正确的受力模型​​\n布料的模拟（模拟的不对会发生穿模的现象，比如衣服穿透了人的身体）​​\n流体：分为两步：1.模拟水是怎么运动的，拿到水的形状、位置。2.把结果拿去渲染​​\n质点弹簧系统模拟绳子的运动​​模拟头发的运动​​\n用点符号表示求导\n一块布可以用很多的质点弹簧进行模拟​​\n简单的弹簧\n理想的弹簧：a 受到的弹簧把 a 拉向 b 的力 fa-&gt;b &#x3D; ks(b-a)，b 受到的力与 a 相反力的大小和 a、b 间的距离成正比（胡克定律），ks 是弹性系数​​\n被拉伸的弹簧\na 受到的力等于弹簧质点间的距离绝对值减去弹簧原本长度，再乘以 a 到 b 的方向的单位向量。问题是：弹窗不会停下来。​​\n​​质点在运动过程中的能量损失，可以用摩擦系数来计算。表现起来就像是质点运动的时候有一个拉力，使得质点的速度慢下来。​​\n但也存在一个问题，这样做摩擦系数他会同时作用于两个质点，让所有的运动都慢下来（比如弹簧从高处落下来降到地上速度也会降低），但我们想要的是质点之间的关系。\n我们把弹簧的摩擦系数与质点之间的速度差做乘积，并在物体运动方向做投影，此时阻力仅在质点之间作用，不会影响整体。​​\n弹簧结构​\n​\n模拟一块布的时候，会遇到一些问题：\n1.这个结构无法承受对角线方向的剪力\n2.这个结构无法抵抗平面外的弯曲（比如把一张纸对折时，基本对折处的节点不会受到周围节点对抗的力，但是对于布而言，显然折叠时，折叠处的节点会受到周围节点的拉力）​​\n这个时候可以往剪力作用的方向的垂直方向加一个约束，此时可以对抗一个方向上的剪力，但还是无法对抗平面外的弯曲。​​\n再往另一个方向加一个约束，此时可以对抗两个方向的剪力，但还是无法对抗平面外弯曲​​\n在节点间跳连，来对抗平面外的弯曲，同时这个连接应该是一种较弱的起辅助作用的连接​​\n最后，可以得到一个比较好的对布的模拟：​​\n除了质点弹窗系统外，还可以用有限元的方法进行布的运动的模拟，运动从一个位置传递到另一个位置。\n粒子系统有一些运动可以用大量粒子来模拟，比如说雾、沙子，在游戏中有广泛的应用。粒子系统需要计算每个粒子受到的力，优点是易于理解和实现，可以用少量粒子来体现速度，更多的粒子来体现复杂度。缺点是有一些场景需要大量的粒子，比如说模拟流体，同时一个粒子会受到四周其他粒子的力的作用，这些计算需要用到加速结构。​​\n粒子系统动画制作的步骤：对于每一帧的运动：1.创造一些粒子\n2.计算每个粒子受到的作用力\n3.更新粒子的位置和速度\n4.移除死掉的粒子\n5.渲染\n​​\n粒子系统的受力：\n1.引力和斥力\n2.摩擦力\n3.碰撞\n​​\n粒子间的引力：​​\n模拟星云：​​\n模拟流体：​​\n粒子系统就是对一个群里中的个体的运动进行计算\n模拟鸟群，把每只鸟作为一个粒子，鸟的运动遵循一些基本规则：\n1.每个鸟会受到周围鸟的吸引\n2.每个个体之间有一段距离（斥力）\n3.所有鸟基本都朝着一个方向运动​​\n模拟分子运动​​\n正向运动学骨骼的表示：1.拓扑结构（找到每个骨骼相连的骨骼）\n2.关节处的几何关系\n3.树状结构：\n关节的连接类型\n1.一维的铰连接\n2.二维的球关节\n3.平移关节​​\n2d 模拟一个两段的手臂：先算出第一个关节的旋转角，再算出第二个关节的旋转角​​\n动画可以表示为时间和角度的函数​​\n正向运动学的优缺点：优点：\n运动的控制很方便，实现方式也很直接\n缺点：物体表示和艺术家们想要的动画效果不一致，花费太多时间​​\n逆向运动学从运动的顶点推测中间的位置​​\n​​逆向运动学下的模拟的手臂运动的求解​​\n逆向运动学的困难点：\n可能有多个解或者没有解​​\n​​​​因此会用到一些优化算法（比如梯度优化算法）​​\n逆向运动学的模拟 demo​​\nRigging就像牵线木偶一样，捕捉所有特征的变化，但制作成本很大，同时需要艺术和技术上的训练：​​\nBlend Shapes\n对两个面做插值，计算从一个面到另一个面变化的中间态。​​\n运动捕捉记录真实世界的运动，在大量数据中提取某一个动作。​​\n运用最多的还是光学的\n运动捕捉的优缺点：优点：可以快速捕捉大量真实数据，效果的真实性很高\n缺点：成本很大，捕捉的运动效果无法满足艺术家的需求（动画可以需要更夸张的运动）\n运动捕捉设备：光学的、电磁波的、机械的​​\n运用最多的还是光学的​​\n​​​​面部的动画模拟​​\n当模拟的动画过于接近真实人类时，会有恐怖谷效应\n面部表情捕捉​​\n电影的生产线​​\n下一节课：怎么通过力、物理理论模拟真实的运动 \n","categories":["图形学"]},{"title":"第二十二章：动画和仿真","url":"/blog/%E7%AC%AC%E4%BA%8C%E5%8D%81%E4%BA%8C%E7%AB%A0%EF%BC%9A%E5%8A%A8%E7%94%BB%E5%92%8C%E4%BB%BF%E7%9C%9F/","content":"动画和仿真\n上节课主要说到了模拟各种运动的各种知识，比如定义一个物体的速度、加速度，就自然能算出来物体在某个时刻出现在某个位置。\n这节课从上节课的概念出发，说一下具体的解法，怎么计算物体在不同时间出现的位置。\n本节课的主要内容：\n单粒子模拟\n\n欧拉方法\n\n解决不稳定的提高的若干办法\n\n\n刚体模拟\n流体模拟\n单粒子模拟模拟物体的运动即规定一个物体在任何时刻的速度，同时知道开始出现的位置，就求解在某个时间后物体出现在哪里。\n如果是匀速的，在 t0 时刻出现在某个位置，在 t1 时刻出现的位置即为 t0 的位置加上速度乘时间。\n但大多数时候没有这么简单，比如要模拟一个粒子在速度场中的运动。\n速度场和光场、磁场类似，表示空间中速度的分布。任意一个粒子的运动可以由一个速度场决定，该速度场是位置和时间的函数。\n​​\n先从简单的出发，研究一个粒子的运动，后面再提高到很多粒子去考虑。\n求解一个例子的速度即求解一个一阶常微分方程：\n​​\n一阶表示知道一个量的微分是多少，希望推出这个量是多少\n常微分方程表示不存在对其他变量的微分（对应于偏微分可能存在对多个变量的微分）\n​​\n求解这个常微分方程，给定粒子的初始位置 x₀，用积分求解这个粒子在时间 t 的位置，得到粒子的运动轨迹。​​\n怎么求解？可以把时间细分成很多小块，计算每个小块（比如时间 t+ 步长 Δt）粒子的位置的变化，在时间上做离散。\n欧拉方法（a.k.a. 前向欧拉、显式欧拉）下一帧的位置是上一帧的位置加 Δt 乘速度，下一帧的速度是上一帧的速度加 Δt 乘加速度\n始终都是用上一时刻的量计算下一时刻的量（也可以用计算出来的下一时刻的量计算下一时刻的量，比如用计算出来的下一时刻的速度来计算下一时刻的位置，但这种方法就不是欧拉方法）​​\n欧拉方法的问题：不准确，且稳定性上会出问题，迅速地变得不稳定。\n对于不准确的问题：步长分的越细，就模拟得越精确。​​\n对于稳定性的问题：\n如果速度场是螺旋形的，任何时刻都有一个和位置方向垂直的速度，物体应该是按照圆周运动来运动的。但用欧拉方法无论取多大的步长，无论如何得到的线都不可能沿着这个螺旋形走，最后都会飞出去。\n如果是下面这幅图的情况下，正常的运动是从左到右走到中间那条线上，但是欧拉方法 Δt 的会让运动轨迹上下震荡走越偏越远。\n这种情况在信号处理上被称为正反馈，即一旦出现问题，这个问题会被无限放大。​​\n误差和不稳定性\n一些用数值微分方法解决的问题都会遇到这些问题：\n\n误差\n\n每一步计算都会有误差，最后累加起来会变成更大的误差。但是可以通过用更小的步长降低误差\n误差在图形学应用中影响大，因为主要关注看起来效果怎么样，不要求物理上的完全一致\n\n\n不稳定\n\n有任何一个模拟方法，不管怎么去模拟最后得到的结果都会和正确的结果差的很远，且越来越发散\n不稳定是模拟中一种不能被忽视的非常基础的问题​​\n\n\n\n解决不稳定性的方法\n中点法\n\n自适应改变步长\n\n隐式方法\n\n不基于物理的方法，Verlet 积分​​\n\n\n中点法\n假设有一个点用欧拉方法模拟经过 Δt 从原始点到 a 点，取原始点到 a 点的中点 b 点，再回到原始点，应用 b 点的速度重新算一遍欧拉方法，达到 c 点，这样计算出来的结果就会比欧拉方法更准确。​​\n中点法之所以更准确，是因为中点法比欧拉方法多出了一个二次项，得到了一个类似抛物线的运动轨迹。原本欧拉方法是一个局部线性的估计模型，中点法算出了一个局部的二次模型。​\n​\nAdaptive Step Size应用两次 Δt&#x2F;2 和应用一次 Δt 的结果进行比较，如果应用两次 Δt&#x2F;2 计算的结果更准确，则把时间拆分得更短一点。​​\n隐式欧拉方法\n\n隐式欧拉又叫做后向欧拉。\n\n用下一帧的速度，下一帧的加速度去乘 Δt，解一个方程组。如果速度和加速度不是简单的按照线性方法叠加，这个方程就不是很好解。\n\n假设当前位置知道，下一个时刻的加速度也知道，就可以解出来下一个时刻的位置和下一个时刻的速度。\n\n\n\n可以用一些数值优化求根算法，比如牛顿方法\n有非常好的稳定性\n\n​\n怎么定义一个方法是不是稳定的\n\n用局部截断误差（ 每一步会产生的误差）和最后累积起来误差来衡量稳定性\n\n研究这两个数字没有意义，应该研究他们的阶。即研究这两个数字和取的 Δt 的关系，误差是如何随着更小的 Δt 减小的\n\n隐式的欧拉方法是一阶的，即：\n\n局部的误差是 O(h2)的\n全局的误差是 O(h)的\n\n\nh 表示步长（即 Δt），h 越小，误差越小。O(h)表示：\n\n如果把 h 减小一半，得到的误差也会减小到一半。阶数越高越好，如果是 2 阶的，假如 h 减少一半，那误差就会减少到 1&#x2F;4。\n\n\n\n​​\nRunge-Kutta 方法\n一类用于解决常微分方程的解法\n\n特别擅长解非线性常微分方程\n有一个用得特别广泛的方法，叫做 RK4，是一个四阶的解法。\n\ny 相当于位置，h 相当于 Δt，k 相当于速度场在不同的位置和不同时间的值（相当于一个扩展的中点法）\n更多的数值计算方法可以看数值分析的课程\n​​\nPosition-Based&#x2F;Verlet Integration\n不是基于物理的方法，主要做法是：\n\n通过调整粒子的不同位置，使得结果能满足某一种限制，来防止出现发散的不稳定的行为。\n\n使用约束的位置来计算速度。\n\n这些方法都会消耗能量，稳定性好。\n\n\n优缺点：\n\n速度很快\n不能保证能量守恒\n\n例子：比如说一个弹簧，被拉开后立刻回到原点，即被拉开后，会立刻调整两个端点的位置使得他们回到原点。这个是不符合真实物理的，是通过一种非物理的简化方式直接改变位置。​​\n刚体模拟不会发生形变，让内部所有点按同一种方式运动，就类似于一个粒子的运动\n只是刚体要考虑更多的属性，比如：刚体的位置、朝向（旋转角度）、速度、角速度\ntorque：扭矩； I：转动惯量\n用欧拉方法或者其他数值方法，可以求出任何一个时间 t 之后刚体对应的位置和旋转。​​\n流体模拟position-based 方法的例子：通过模拟形成整个水体的小球的位置来模拟浪花的运动\n首先认为整个水体是由不可压缩的刚体（小球）组成，只要能模拟出小球的位置就能模拟出浪的运动（模拟和渲染是分开的）\n假设水在任何地方都是不会被压缩的，即在任何时刻任何位置的密度都是一样的\n给任何一个时刻小球分布的位置，都可以知道任何一个地方的密度。如果有任何一个地方的密度和之前平静的水不一样的情况，就需要把这个密度修正过来。通过移动小球的位置来进行修正。\n要做这个修正需要知道任何一个点的密度对所有小球的位置的梯度是多少。一个点的密度会受到周围小球的位置的影响，任何一个点的密度都是任何一个其他小球的位置的函数。\n任何一个位置，要让不正确的密度变成正确的密度，且知道如何调整各个小球的位置使其密度朝向正确的方向去。这个过程就是梯度下降的过程。\n这个修正会导致停不下来，所以实际模拟过程中会考虑能量损失。​​\n在物理模拟中模拟大规模的物质用到两个不同思路：\n质点法：模拟水，认为水是由很多小水滴组成，逐个模拟，最后得到的结果就是正确的。这种方式被称为拉格朗日方法（也叫质点法）\n欧拉方法：和常微分方程的欧拉方法不是一回事。这里是指如何看待模拟一系列大规模的物体，把整个空间分成不同的网格，考虑网格随着不同的时间怎么变化。​​\nMaterial Point Method（物质点方法）\n混合型的方法，即考虑拉格朗日，又考虑欧拉方法。\n\n认为不同的粒子都具有材质属性\n用格子模拟融化的过程，把信息都记录在格子上\n再把格子里的信息写回粒子上\n\n下面怎么深入学习：《realtime rendering》、微分几何、离散几何、《games201》\n广告：\n​​​​\n《高质量实时渲染》\nhttps://www.bilibili.com/video/BV1YK4y1T7yY/?spm_id_from&#x3D;333.337.search-card.all.click&amp;vd_source&#x3D;d6c15f5bd49b1cdbb4227e5dc29a5666\n离线渲染《高级图像合成》\n​​\n","categories":["图形学"]},{"title":"第二十章：颜色和感知","url":"/blog/%E7%AC%AC%E4%BA%8C%E5%8D%81%E7%AB%A0%EF%BC%9A%E9%A2%9C%E8%89%B2%E5%92%8C%E6%84%9F%E7%9F%A5/","content":"颜色和感知（Color and Perception）\n本节课内容：完成上节课的光场\n颜色\n\n什么是颜色\n颜色感知\n颜色再现&#x2F;匹配\n颜色空间\n\n光场（Light Field&#x2F;Lumigraph）\n​​​​\n我们看到的世界，可以用眼前的一块幕布，来模拟我们在各个方向看到的光照\n​​\n碟中谍 4 里全息投影\n全光函数描述我们能看到的所有东西\n​​\n在某个方向看到的光照\n​​\n加上了波长的参数，可以看到彩色的\n​​\n加上时间的参数，可以看到电影\n​​\n再加上空间的参数，在不同位置看到的，可以看到全息电影\n​​\n最后把函数理解成在任何位置，往任何方向看，在任何时间，看到不同的颜色。这个 7 维的函数就叫做全光函数。\n​​\n可以从全光函数提取一部分信息出来，用来表示复杂的光。光场就是全光函数的一个小部分。\n​​\n定义光线：\n​​\n可以是起点 + 方向，或者是取光线上的任意两点\n重点是需要二维的位置和二维的方向\n​​\n根据光路可逆性，要描述一个物体能被看到的所有情况，即描述这个物体在包围盒上任何一个位置往各个方向过去的光线\n​​\n光场即在任何一个位置往任何一个方向去的光的强度\n首先三维物体的表面在一个二维的空间中，可以用（u,v）两个变量表示位置，任何一个空间中的方向都可以用（θ，φ）表示，所以光场是一个四维的函数。\n可以从光场中直接提取到任意一个位置看向一个物体的光强度\n​​\n可以简化一点，我们不需要知道光场表示的是什么东西，我们只需要知道盒子上表面任意一个点往任意一个方向（观测点）发出的光的强度（前提是观测点不在盒子内部）。\n​​\n更进一步，可以取一个平面，平面右边是发光的物体，光线会穿过平面。我们可以忽略平面右边的东西，对平面上任意一个点，只需要知道方向就可以。\n​​\n也可以用两个平面来定义光场，两个平面各取一个点确定方向：\n​​\n用(u,v)和(s,t)来确定光场：\n​​\n对于两个平面的参数化方法有不同的处理方式：可以固定一个(s,t)，让（u,v）变化：\n​​​​\n上图中的上图是从(u,v)平面上找到一个点看向(s,t)平面的所有方向，得到从这个点的方向看过去的物体的全貌\n​​\n下图是从(s,t)平面上找一个点，看向(u,v)平面，这里可以理解为(u,v)平面所有方向看向(s,t)同一个点得到的图像。\n类似于苍蝇的复眼，光照射到一个像素点上是不同方向的光混合起来的，这里在光前面用一个透镜，就可以把光分开，把一个像素不同方向上光分别记录在不同的位置。\n​​\n光场照相机先拍照，后期再重新聚焦\n​​\n光场相机就是用透镜把光分开，一个像素的 irradiance 现在分开记录到一块区域上的 radiance。\n​​\n光场相机还原照片，可以选择一个方向，计算这个方向上像素点接受的光照，这样就可以模拟相机移动。\n重新聚焦和移动相机位置一个道理，光场已经记录了所有方向所有位置的光照信息，只需要选取聚焦对应的方向和位置就可以计算得到。\n​​​​\n光场照相机的缺陷：\n\n分辨率不足。以前的一个像素要用很多个像素去记录，对胶片要求很高\n高成本。透镜非常精密，实现需要巨大的成本\n如果要记录更精密的方向信息，位置信息就会丢失的更多（复眼如果圆圈更大，那么圆圈的数量就更少）\n\nPhysical Basis of Color\n颜色是很多基本颜色混合得到的结果\n​​\n不同颜色的光有不同的波长，图形学关心的通常是可见光的光谱\n​​\n谱功率密度就是描述光在任何一个波长的分布是多少\n​​​​\n不同的光有不同的 SPD\n​​\nSPD 有线性的性质\n​​\n颜色是什么？颜色是人的感知\n​​\n人眼的构造：\n​​\n肌肉会拉扯晶状体改变焦距\n视网膜上有感光细胞\n​​\nRodCell 棒状细胞，感知光的强度，不感知颜色。用棒状细胞可以得到一个灰度图\nCones 锥形细胞，感知颜色。锥形细胞内部又分成三种不同的锥形细胞（S，M，L），感应不同范围的波长。\n曲线线叫做响应曲线，即给不同的光会有多强的反应。\n​​\n不同的人这些细胞的分布非常不一样\n​​\n把响应曲线和感应到的 SPD 做积分，得到三个数 S、M、L，就是人感知到的颜色，而不是光本身的 SPD。\n​​​​\n同色异谱\n光谱不一样，但是人感知到的颜色一样\n通过调和光谱，使得得到的颜色和看到的另一种颜色一样，就是 color mapping 的过程\n​​​​\n比如在显示器上显示一个太阳，混合的光谱可以和真实的完全不一样，但最后的颜色是一样的：\n​​\n计算机的成像系统是加色系统把 R、G、B 各自乘上不同的强度再混合起来（画画是减色系统，把各种颜色调和到一起最后会变成黑色）\n​​​​\n混色实验：\n​​​​\n但有一些颜色会怎么混两边颜色都不一样\n​​​​\n这个时候给左边的颜色加一个颜色，相当于右边的颜色减了一个颜色（真实情况下不能减，因为是加色系统）\n​​\nCIE RGB\n​​\n实验测算三种波长的光混出一个波长，得到一个匹配函数：\n​​\n给任何一种实际光的光谱，把每个波长需要多少 R、G、B 都算出来，然后做积分把颜色表示出来\n​​\n颜色空间\nsRGB（标准 RGB）\nRGB 形成的颜色空间色域是有限的\n​​\nA Universal Color Space: CIE XYZ\n定义颜色匹配函数，和 RGB 匹配函数不一样，不是实验测出来的匹配系统\n特别的 Y 本身还表示亮度​​\n可视化 XYZ 系统得到的所有颜色，但是三维的不好显示，所以把 X、Y、Z 做归一化处理，Y 表示亮度，所以把 Y 固定成某一个数，让 X、Z 发生变化，显示的图显示小写的（x, y），看到的形状就叫做色域。​​\n色域的中心是白色，是最不纯的颜色，最纯的颜色在边界上。​​\n不同的颜色空间表示的色域是不一样的：​​​​\nHSV Color Space​​\n通过色调选不同的颜色，通过饱和度选偏白还是偏这个颜色，亮度决定偏黑还是偏这个颜色​​\nCIELAB 空间轴上任意两端端颜色都是互补色：​​\n互补色（实验得到的，人的大脑的定义）：​​\n盯住下图的中心点十秒后切换到另一张白色的图上，会看到互补色：​​\n颜色是感知，所以看到的颜色有多强是感觉的：​​\n​​​​​​减色系统**CMYK **\n打印上混合各种颜色，所有颜色混起来变成黑色。这里面虽然黑色可以由其他颜色混合得到，但是考虑打印成本，都会带上一个黑色：\n​​\n","categories":["图形学"]},{"title":"第五章：光栅化","url":"/blog/%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%85%89%E6%A0%85%E5%8C%96/","content":"光栅化（三角形）上节课提到了观测变换：包含视图变换和投影变换。当完成观测矩阵变换后，下一步需要怎么绘制到屏幕上？这就是光栅化\n上节课提到透视投影转换为正交投影，近平面和远平面 z 轴位置不变，远平面大小变成和近平面一样大。\n正交投影里：x 轴定义左（l）和右（r），y 轴定义上（t）和下（b），z 轴定义远（f）和近（n）。\n锥体定义n 和 f 在正交投影和透视投影里面都是一样的，我们认为是已知的。做正交投影时我们把锥体 frustum 变成一个长方体，那么怎么定义这个 frustum？假设我们从相机出发，看向一个区域，首先我们给这个近的平面可以定义一个出一个高度和宽度（高宽比），再定义一个视角（field of view，表示可以看到的角度范围）\n下图中平面的上下两条边中点到相机的连线（红线）所夹的角度是竖直方向的可视角度，这个角度用于定义看到的世界。比如广角相机这个角度就比较大，角度越小透视投影就越不明显，比如可以拍到很远的物体。\n同理可推出水平可视角度：相机和左右两条变中点连线所夹的角度。\n​​\n长宽比和垂直可视角可以和做正交投影的长方体转为同一个概念。\n​​\n经过 MVP 投影后，我们会得到一个（-1，1）的三次方的立方形，接着我们要将它绘制到屏幕上。\n屏幕是什么1.是一个二维数组，数组的每一个元素是一个像素（pixel）\n2.屏幕分辨率表示像素的多少\n3.屏幕是一个典型的光栅成像设备\n光栅（Raster）是德语里的屏幕的意思，光栅化即把东西画到屏幕上的过程。\npixel 表示 picture element\n这门课里，我们把像素认为是一个个的小方块（实际的像素比这复杂得多），每一个方块表示一个颜色，一个像素里的颜色都不会变化。一般像素的颜色可以划分为不同的等级（0-255），用 RGB 表示。\n屏幕的空间认为屏幕左下角是原点，向右是 x，向上是 y。像素的坐标都是写成 x，y 的形式，用整数坐标来表示。如果一个屏幕的分别率是 width*height，那么所有的像素可以用（0, 0）到（width-1，height-1）来表示，所有像素的中心在(x+0.5, y+0.5)上，屏幕覆盖的范围为(0, 0)到（width, height）。\n​​\n接下来需要把[-1,1]³ 映射到屏幕上，先不管 z 轴，[-1,1]² 转换为[0,width]和[0,height]。先做缩放，然后要保持原点不变，所以还要做一个平移。这个变换被称为视口变换。接下来要把所有的结果打散成像素，画到屏幕上。\n​​\n成像设备早期的 CRT（Cathode Ray Tube）显示设备：\n成像原理：阴极射线管，电子加速后穿过显示设备，然后做偏转，电子打到屏幕上成像。\n成像的过程就是，通过扫描的方式，在屏幕上一行行的画线。提高扫描的速度：隔行扫描​\n现在的显示设备：\nLCD（Liquid Crystal Display）显示设置\n把内存（比如显存）中的一块区域映射到屏幕上。\n​​\n液晶会通过自己的不同排布影响光的偏振方向\n​​\nLED 显示设备（发光二极管）\n墨水屏（电压使得黑白墨水翻转， 刷新率很低）\n怎么在成像设备上绘制成像即把变换后得到的多边形的顶点打散到各个像素上\n三角形\n\n三角形是最基础的多边形，任何多边形都可以拆成三角形\n三角形内部一定是平面的\n三角形内外定义一定是清晰的\n只要定义三角形的三个顶点，就可以做到一个顶点属性到另一个顶点属性的插值\n\n​​\n当三角形的边只有一部分覆盖到像素，怎么判断是不是要绘制，即判断像素中心点和三角形的关系？\n采样把一个函数离散化的过程（给不同的 x 计算不同的函数值）\n用像素中心进行采样，定义不同的函数在像素中心的值\n​​\n定义一个 inside 的含义，给定任意（x,y）坐标，判定它是否在在三角形内，在三角形里其值为 1，不在则值为 0。\n​\n​\n通过叉积的计算可以判断一个点是否在三角形内部\n​​\n如果有一个点正好在三角形的边界上，自己定义一个标准，不同的 API 可能有不同的标准。\n​​\n不需要对屏幕上的所有像素做光栅化，只需要找到三角形的包围盒。\n​​\n更快的方式是只找每一行的最左和最右。\n实际的像素bayer pattern（右侧的）绿色出现的频率最高，因为人眼对绿色更敏感\n​​\n打印和屏幕相反，打印是一个减色系统（因为颜色越多越黑），但是屏幕 rgb 值越高，越亮，越靠近白色\n​​\n光栅化后，由于颜色均匀的填在像素格子里，就会形成锯齿，采样率不够高会导致锯齿更明显，造成走样问题。\n​​\n","categories":["图形学"]},{"title":"第八章：着色模型","url":"/blog/%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E7%9D%80%E8%89%B2%E6%A8%A1%E5%9E%8B/","content":"Blinn-Phong 模型\n\n漫反射\n高光\n环境光\n\n着色是在某一个点进行计算的，要得到一整张图就需要在不同的位置应用着色，就涉及到着色频率\n方向都是指单位向量\n本节课\n\nBlinn-phong 着色模型\n\n高光和环境光\n\n\n着色频率\n\n渲染管线\n\n纹理映射\n\n重心坐标\n\n\n高光观察方向和镜面反射方向接近的时候，可以看到高光。此时，半程向量也和法线方向接近。\n​​\n最早使用 Phong 模型：判断 R 和 v 是否足够接近，但是计算反射方向不好计算，计算量很大，所以后面优化为 Blinn-Phong 模型：判断 n 和半程向量 h 是否足够接近。\n这里简化掉了表示光吸收能量的系数（n*l）\n指数 p 是为了缩小高光的范围，在 Blinn-Phong 模型里一般取 100-200\n​\n​\n​​\n环境光这里假设任何一个点收到的环境光的强度 I_(a)都是一样的，环境光和光照方向、观测方向都没有关系，是一个常数。（计算真正的环境光远比这个复杂，需要用到环境光照的知识）\n​​​​\n着色频率着色分别应用在每个面、每个顶点（每个平面有四个顶点，每个顶点计算出法线，每个顶点做一个着色。三个顶点连接成三角形，三角形内部每一个点做插值）、每一个像素上（每个顶点求出法线，每个法线的方向在三角形内部做插值，得到每个像素的法线，再做一遍着色）\n​​\nFlat shading\n三角形的两条边做叉积得到法线\n​​\ngouraud shading\n每个顶点求法线，着色后，内部的点通过插值求颜色\n​​\nPhong shading顶点求出法线后，三角形内每个点通过插值求出法线方向，再进行着色\n​​\n用哪种着色模型取决于模型的复杂度\n​​\n顶点的法线怎么计算：相邻面的法线求（加权）平均\n​​\n求出两个顶点法线后，中间的法线插值求出来，需要注意求出来的方向向量都是单位向量。\n​​\n图形管线（实时渲染管线）从一个场景到一张图经历的过程（显卡 GPU 里的操作）\n​​\n这个过程是部分可编程（vertex processing 和 fragment processing）的**，**即开发者可以控制顶点和像素是如何着色的，这部分代码就叫做 Shader。\n​​​​\nhttps://www.shadertoy.com/view/ld3Gz2GPU 非常适合做图形学里的并行计算\n​​\n纹理映射纹理用来定义着色时各个点的属性**。**\n​​\n任何一个三维物体表面都是二维的，这个二维的图形就认为是纹理。\n​​\n纹理坐标三角形每个顶点都对应一个坐标。\n​​\n纹理可以被重复多次\n​​\n这种重复使用依旧衔接的很好的纹理叫做 tiled textures。\n​​\n","categories":["图形学"]},{"title":"第六章：反走样与深度缓冲","url":"/blog/%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E5%8F%8D%E8%B5%B0%E6%A0%B7%E4%B8%8E%E6%B7%B1%E5%BA%A6%E7%BC%93%E5%86%B2/","content":"反走样和深度缓冲上节课提到：MVP变换后，把得到的[-1,1]3区域映射到屏幕上。光栅化的思想：用像素的中心对三角形的可见行函数进行采样。本节课学习的主要内容：\n\n反走样\n采样理论\n实际图形学中怎么做反走样\n\n\n可见性&#x2F;遮挡\n深度缓冲\n\n\n\n采样在图形学中是一种广泛的做法：\n\n比如光栅化的过程，在屏幕空间用一些离散的点采样\n\n照片，所有到达感光元件所在平面的光学信息离散成图像上的像素\n\n采样可以发生在不同的时间，比如视频、动画是把一系列的图在不同时间进行采样。\n\n\n采样artifacts（瑕疵）：\n\n锯齿-空间中采样\n摩尔纹（照片奇数行和技术列去掉），拿手机拍屏幕-不同位置采样\n顺时针转的轮子看起来在逆时针旋转-人眼在时间中采样跟不上运动的速度\n\n采样artifacts的本质：信号的变化太快了，以至于采样的速度跟不上信号变换的速度。\n反采样：采样前做一个模糊（滤波）\n​​\n可以先模糊（滤波）再做采样，但不能先采样再模糊。\n为什么采样速度跟不上信号变换的速度会造成采样artifacts？\n频域用f定义余弦波变换的速度，周期是频率的倒数\n​​\n傅立叶级数展开任何一个周期函数都可以写成正弦、余弦的线性组合加常数项。\n​​\n傅立叶变换：把一个函数变成另一个函数\n​​\n傅立叶变换就可以把函数变成不同频域的段并显示出来。\n相同的采样点，原函数频率越高，采样越不准确。\n​​\n同样一个采样方法采样两种不同频率的函数，得出的结果无法区分，就叫做走样\n​​\n滤波把某个特定的频率去掉，看信号会发生什么样的变化。\n傅立叶变换可以把一个函数从时域（把空间不同的位置也看作时域）变到频域。把中心看作低频区，周围是高频区，用亮度表示在不同频率的位置上有多少信息，如下图大多数信息集中在低频上：\n​​\n为什么右侧的图像会有两条白线，因为处理图片信号的时候，会把图片视作周期性变化（类似于图片水平方向和竖直方向依次叠放了多张图），由于图片并不是真的周期变化，到达图片边界时，会发生剧烈的信号变化，产生极其高的高频。\n傅立叶变换可以让我们看到一张图像在不同的频率长什么样，即得到一张图像的频谱。\n假如去掉低频的信息，再做傅立叶逆变换，会得到图像内容的边界，因为在边界处会发生剧烈的变化，即频率比较高。这种滤波称为高通滤波，即这种滤波器只有高频信号能通过。\n​​\n假如只留下高频的信息，去掉低频的信息，再做傅立叶逆变换，会得到一张（边界）比较模糊的图。这种滤波称为低通滤波。\n​​\n滤波&#x3D;平均&#x3D;卷积卷积（图形学上定义：滑动过滤器，做点乘，得到一个加权平均值）\n​​\n卷积定理：时域上对两个信号做卷积，对应频域上两个信号做乘积。时域的卷积等于频域的乘积，时域上的乘积等于频域上的卷积：\n\n可以选择直接在时域上做卷积\n\n\n或者先做傅立叶变换变到频域上，卷积核也做傅立叶变换到频域上，在频域上做乘积，乘积结果再做逆变换变回来。\n​​\n\n\n卷积核：\n​​\n盒子越大，对应的频域范围越小，结果越模糊。盒子越小，频域范围越大。\n​​\n从频率的角度上看采样：重复频域上的内容。\n​​\n给一个原始信号(a)，乘一个冲击函数(c)（只在某些固定位置有值，其他位置值为0），得到采样结果(e)。\n把原始信号和冲击函数分别转换到频域上得到（b）和（d），做卷积得到（f）。\n可以看出来：采样就是重复原始信号的频谱。\n​​\n采样不同的间隔会引起频谱以不同的间隔移动，当采样率不足（采样不够快），原始信号复制粘贴的频谱间隔就很小。采样越稀疏，搬移频谱内容就越密集。原始信号和复制粘贴信号混在一起，这个时候发生了走样。\n反走样：1.增加采样率（高分辨率频幕）\n2.先做模糊再做采样（先把高频信号拿掉，再采样，这个时候频谱覆盖面变小，再以原本间隔复制，就不会发生混别）\n​​\n找一个一定大小的低通滤波器，对原来的频谱做卷积\n​​\n用一个1像素的方块对三角形函数做一个卷积操作：\n​​\n对三角形覆盖面积求平均：\n​​\n怎么计算三角形的覆盖面积，近似求解，把像素划分成很多小像素，判断小像素是不是在三角形里面再求平均：\nAntialiasing By Supersampling (MSAA)\n​​​​\n接着对格子中间进行采样（采样的结果就是平均的结果）\n​​\nMSAA不是靠提升分辨率直接解决走样问题，增加采样点只是得到三角形的近似覆盖，屏幕像素值不变，它解决的是模糊的问题。MSAA的代价：\n增大了计算量。工业上用更有效的不规则图案来减少采样点，有一些点还会被临近的像素来复用。\n其他抗锯齿：FXAA(Fast Approximate AA 快速近似抗锯齿)：和采样无关，通过图像后期处理，先得到一个有锯齿的图，再通过图像匹配的方法找到这些边界，再把有锯齿的地方换成没有锯齿的边界。\nTAA（Temporal AA）：静态物体两帧不变，因此相邻两帧可以用一个像素内的不同点感知是否在三角形内部，当前帧可以复用上一帧的结果。\n超分辨率：\n小图拉大；有一个高分辨率的图，但是采样率不够，想要把这个图恢复出来。\nDLSS（Deep Learning Super Sampling）深度学习\n","categories":["图形学"]},{"title":"第十七章：材质与外观","url":"/blog/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0%EF%BC%9A%E6%9D%90%E8%B4%A8%E4%B8%8E%E5%A4%96%E8%A7%82/","content":"Materials and Apperances （材质与外观）\n外观是不同材质与光线共同作用的结果\n光打进去后在物体内部反射多次变成一大片再出来——次表面散射\n自然界中有无数的材质，但渲染器中支持的材质很少（比如维塔数码的 Manuka 渲染器，只支持 40 种材质），要呈现自然界中的材质，需要各种纹理贴图。\n在渲染方程中，BRDF 是和材质相关的，它决定了光怎么被反射\nMaterial &#x3D;&#x3D; BRDF\n对于漫反射：假设空间中任何一个方向进来的光的 radiance 的一样的，它反射的光也是一样的。根据能量守恒，如果一个点不发光也不吸收光，那么进来多少就应该反射多少。\n​​\n定义一个反射率 albedo，它的值在 0-1 之间，可以引入不同颜色的 albedo。\n对于 Glossy 的材质，一部分反射，一部分折射\n​​\n光线折射过后会有部分被吸收\n​​\n镜面反射计算出射角，可以把它转换到 φ 平面上：\n​​\n镜面发射也可以写出 BRDF，但是出射方向只集中在镜面反射的方向，因此写出正确的 BRDF 不那么容易。\n对于折射：折射定律\n​​\n当出射的折射率大于入射的折射率时，可能出现无法折射的现象：\n​​​​\n折射的 BRDF 就叫做 BTDF，T 表示 transmission。BRDF 和 BTDF 统称 BSDF，S（scaterring）表示散射。\n​​\n菲涅尔项表示有多少光线被反射、多少被折射。图中的虚线表示极化现象下的光，极化现象即光只沿某一个方向振动。\n对于绝缘体：入射光线的入射角与物体表面越平行，反射的越多。\n​​\n对于导体：任何情况下反射都很多。\n​​\n菲涅尔项的计算：用 Schlick 近似进行拟合，不管曲线的真实趋势，认为 θ 为 0 时为 R₀，θ 为 90 度时为 1。\n​​\n微表面模型：当我们离的够远，我们看不到表面上的细节， 只能看到总体对光形成的一个效应。从远处看，看到的是材质和外观，从近处看，看到的是几何。每一个微表面，都看作是镜面。\n​​\n一个物体表面的粗糙程度可以用微表面的法线分布来表示：\n​​\n微表面的 BRDF：G（shadowing-masking term）表示微表面被遮挡的修正。当光线越平行于表面（grazing angle）时，越容易发生遮挡。D 表示法线分布。\n​各向同性&#x2F;各向异性材质\n​​\n各向同性的材质发现分布也很均匀\n​​\n各向异性用 BRDF 来解释就是方向角是绝对的，不是相对的。\n​​\n总结 BRDF 的属性：\n1.BRDF 的值一定是非负的\n2.线性性质\n​​\n3.可逆性。交换入射和出射方向的角色，得到的 BRDF 是一样的\n4.能量守恒\n​​\n5.各向同性和各向异性\n各向同性时，BRDF 只和相对方位角有关，即和 φ 的差值有关，即四维的方程可以转为三维的\n且由于可逆性，φ 的差值不需要考虑正负\n​​\n测量 BRDF\n如果能直接测量，就不需要用到模型去计算\n测量能够用真实世界的材质做到更精确的渲染​\n\n‍\n​\n​​\n​​​​\n​​\n","categories":["图形学"]},{"title":"第十一章：显示几何，曲线、曲面","url":"/blog/%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0%EF%BC%9A%E6%98%BE%E7%A4%BA%E5%87%A0%E4%BD%95%EF%BC%8C%E6%9B%B2%E7%BA%BF%E3%80%81%E6%9B%B2%E9%9D%A2/","content":"几何入门：\n几何例子\n\n不同表示几何的方式\n\n隐式\n显式\n\n\n\n本节课：\n\n显式几何\n\n曲线\n\n曲面\n\n\n显式几何有不同的表示方法：三角形面、贝塞尔曲面、点云\n点云物体用一堆点表示。\n只要点足够密，可以表示任何形状的几何。\n点云转换三角形面。\n多边形面三角形、四边形面。\n需要用更复杂的数据结构表示三角形对连接关系。\n是图形学中最常见的表示方式。\n三角形面形成的物体：\nv 定义 8 个点，vn 定义 6 个面的法线（图中有冗余）、vt 定义 12 个纹理坐标（每个面四个点的纹理坐标，中间会有共用的），f（face）定义三角形之间的连接关系（第一个参数是顶点，比如图中第一行使用第 5、1、4 三个顶点形成三角形，第二个参数是三个顶点的纹理坐标，第三个参数是指三个顶点的法线）\n​​\n曲线相机的运动曲线，三维建模模型的运动曲线、定义字体的控制点\n贝塞尔曲线（用一系列控制点来定义曲线）曲线的起点在 P0、开始的方向是 P0P1，曲线的终点是 P3，结束的方向是 P2P3\n​​\nde Casteljau 算法\n给任意一个时间 t，计算贝塞尔曲线在时间 t 的位置\n​​​​\n是一个递归的过程\n​​​​​​\nn 阶贝塞尔曲线可以表示为控制点的线形组合，系数就是一个和时间有关的多项式，被称为 Bernstein 多项式\n​​\n三维空间中同样可以用 Bernstein 多项式\n​​\nBernstein 多项式就是 1 的多阶展开，所以在坐标轴上画一条竖线，经过的每个点的 y 轴加起来的值都等于 1\n​​\n贝塞尔曲线的性质：1.起点和终点固定\n2.切线方向固定\n3.对曲线的顶点、控制点做仿射变换后，再画贝塞尔曲线，和对原始贝塞尔曲线做仿射变换后得到的曲线是一样的；但对投影不是这样\n​​\n4.秃包性质：任何一个贝塞尔曲线肯定在控制点形成秃包之内。比如如果给一堆控制点都在一条直线上，那这个贝塞尔曲线一定是这条线自己。\n秃包：能包围给定的几何形体的最小的凸多边形\n想象有一堆钉子，在最外层的钉子上绑一个橡皮筋，橡皮筋围成的形状就是秃包\n​​\nPiecewise 贝塞尔曲线控制点多的时候不好控制，逐段定义贝塞尔曲线，再连起来。一般是每四个控制定义一条贝塞尔曲线。\n​​\n几何上两条曲线都通过一个点，第一段的终点等于第二段的起点叫做 C0 连续\n​​\n第一段终点控制点连线和第二段起点控制点的连线大小一致，方向相反，C1 连续（一阶导数连续）\n​​\nSpline 曲线（样条）由一组控制点控制的曲线，能满足一定的连续性\nB-Spline basis splines（奇函数样条，由于不同的函数组合起来形成新的函数）\n\n用 Bernstein 多项式在时间 t 几个不同的项对不同的控制点做加权平均\n用控制点的位置对 Bernstein 多项式进行加权\n\nB-Spline 是对贝塞尔曲线的扩展，可以实现局部性，比如改变一个控制点，只影响一定范围内的曲线。\n本节课不深入学习 B 样条\n贝塞尔曲面贝塞尔曲线得到贝塞尔曲面\n4✖️4 控制点，双线性插值\n用时间 u 先确定一个方向的四个控制点，再用时间 v 确定曲面上的一个点\n​​​​​​\nMesh Operations：几何处理\n\n网格细分\n\n网格简化\n\n网格正规化（让三角形不要出现特别尖的三角形）\n​​\n\n\n‍\n","categories":["图形学"]},{"title":"第十九章：相机、透镜、光场","url":"/blog/%E7%AC%AC%E5%8D%81%E4%B9%9D%E7%AB%A0%EF%BC%9A%E7%9B%B8%E6%9C%BA%E3%80%81%E9%80%8F%E9%95%9C%E3%80%81%E5%85%89%E5%9C%BA/","content":" Cameras, Lenses and Light Fields (相机、透镜、光场)\n成像（Image） &#x3D; 合成（Synthesis） + 捕捉（Capture）\ntransient image：研究光在极短时间内传播会看到什么。\n整个 Imgae 更多的是在 computational photography 里面的研究。\n回到图形学里面：\n捕捉相机​​\n小孔成像​​\n快门控制光进入相机\n​​\n传感器（记录 irradiance）\n​​\n如果没有透镜，一个点可能接受各个方向传播过来的光，成的像就是糊的\n​​\n有一些研究在研究一些传感器，可以分开不同的方向记录\n针孔相机​​​​\n针孔相机拍出的像没有景深，各个方向都不会虚化。做光线追踪的时候也是用的针孔相机的模型。模拟光线和透镜作用，也可以做出景深的效果。\n​​\n视场（Field of View）\n能看到多大的范围，h：传感器的高度，f：焦距（传感器离小孔的距离）。焦距越小，视场越大。\n​​\n一般定义视场都是认为以 35mm 的胶片（传感器）为基准，通过定义焦距来定义 FOV。\n​​​​\n传感器越小，FOV 也越小\n​​\n传感器（Sensor）和胶片（Film）不完全等价，传感器负责记录每个像素收到的 irradiance 有多大，胶片决定存成什么样的图片格式。\n大的相机有大的传感器，所以有更大的分辨率\n​​\n曝光（Exposure）​​\n相机里面影响照片拍出来亮度的因素：\n光圈（aperture）大小相机可以控制光圈大小，由 f-stop 来控制。光圈大小会影响 senser 上的任意一个点接收到的 irradiance 的大小。\n快门（Shutter）速度\n快门速度越快，开放时间越短，越少的光进来\nISO gain（增益）感光度\n后期处理，接收到光后乘上一个数。这个处理可以在任何一个地方，比如说调节感光器的灵敏度，或者生成照片后，在照片的数字信号上去调节。\n​​\nF 越小，光圈越大，周围越虚化\n速度慢，曝光时间越长，图片越模糊\nISO 乘的数字越大，噪声越明显\n​​\nISO\n简单的线性的乘\n​​\nISO 能提高曝光度，但是会造成噪声放大的问题\n​​\n描述光圈大小的数：F-Number（F-Stop）\n非正式理解：F 是 1&#x2F;光圈直径\n​​\n快门\n快门用来调节曝光度，对于机械快门来说，无论速度多块，它的打开都有一个过程\n​​\n快门的速度对最后的成像会造成影响。\n高速运动的物体在快门曝光时间长会出现运动模糊，因为快门打开和关闭时，物体的位置不一样，最后得到的是平均之后的效果，所以会产生模糊。\n​​\n提高快门速度，可以减少运动模糊。但是曝光度也减少了，所以要保证亮度，还得调光圈和 ISO。\n​​\n如果物体的运动比快门速度更快或差不多，会造成对于非常高速运动的物体的扭曲，因为不同位置的图像可能记录的是不同时刻进来的光。\n​​\n快门和光圈要保证曝光度，快门速度快，就要提高光圈大小\nF-Stop 是 1&#x2F;直径，考虑光进来要用面积来算\n​​\n高速摄影\n非常短的快门时间，大的光圈\n​​​​\n超低速摄影\n延迟摄影，延长曝光时间，调小光圈\n​​​​\n薄透镜近似\n​​\n一面凸一面平的透镜无法把光聚到一点上：\n​​\n理想化的薄透镜\n平行的光打进来可以折射到一个焦点上，焦点到透镜中心的距离叫做焦距\n根据光路的可逆性，光从焦点打到透镜上，会折射成平行光\n薄透镜可以任意改变它的焦距（透镜组）\n​​\n透镜满足基本的物理规律：从任何一个方向穿过透镜的中心都不会改变方向。\nz₀：物距\nz_(i)：相距\n​​​​​​\nDefocus Blur\nCoC：物体成像的点离感光元件还有一段距离时，光线会继续传播，到达感光元件上的时候会是一个圆，这个圆就叫做 CoC。CoC 的大小和光圈大小成正比。\n​​​​\n重新定义 F-Number\nF-Number：焦距&#x2F;光圈的直径\n​​​​\n拍更清楚的照片要用小光圈\n​​\n模拟薄透镜做光线追踪\n​​​​\n景深（Depth of Field）\n用不同大小的光圈会影响景深的范围\n​​\n景深就是指成像清晰的一段范围：在实际场景中有一段深度，这段深度经过透镜后会在成像屏幕附近有一段区域，这段区域的 CoC 都是足够小的。\n​​\n景深的最远处穿过透镜和最近处穿过透镜会得到一段范围 Depth of focus：\n​​\n光场&#x2F;Lumigraph（to be continue）\n","categories":["图形学"]},{"title":"第十三章：Ray tracing 1 基础光线追踪算法","url":"/blog/%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0%EF%BC%9ARay%20tracing%201%20%E5%9F%BA%E7%A1%80%E5%85%89%E7%BA%BF%E8%BF%BD%E8%B8%AA%E7%AE%97%E6%B3%95/","content":"Ray Tracing（光线追踪）光栅化的问题\n不能很好地处理全局效果，比如：\n1.软阴影\n2.光线多次弹射（毛玻璃反射、间接反射）\n​​\n光栅化速度快，但是质量低；光线追踪准确但是速度慢。所以一般光栅化用于实时、光线追踪用于离线。\n​​\n基础的光线追踪算法光线的三种假设：\n\n光沿直线传播（实际并不是\n\n光线相交时不会碰撞（实际并不是\n\n光线从光源传播到眼睛（根据光的可逆性，光线以不变的光路从眼睛传播到光源\n​​\n\n\n光线投射从摄像机到成像平面中的一个像素连成一条射线，这个射线会和一个物体相交。再把这个交点和光源做连线，判定他是不是在阴影内。\n​​\n假设眼睛是一个点（针孔摄像机），同时光源也是点光源。光线打到场景中的物体会发生完美的折射和反射。\n考虑光线和场景中的物体最近的交点，交点再与光源做连线，如果没有遮挡说明没有阴影。求出交点后再对交点做着色。\n​​​​\nrecursive Whitted-styled ray tracing光线可以不断弹射。每个弹射点可画出一条 shadow ray，计算是不是在阴影里，光源弹射后能照到的点的着色值最后都加到一个像素里面去。\n​​\n求光线和物体表面的交点\n光线的定义：\n点光源：起点 + 方向\n​​\n判断光线与球体是否相交：\n​​\n点即在光线上，又在球上。求解一元二次方程：\n​​\n对于一般面\n隐式表示：列出 surface 的隐式表达式，带入求解：\n​​\n显式表示：求光线与三角面的交点\n一个封闭的图形，从图形内部发出一条射线，与图形的边的交点数量一定是奇数\n​​\n简单做法：一个一个三角形求解是否与射线相交\n先光线与平面求交，再判断一个点是不是在三角形内部\n用一个法线和一个平面上的点可以确定一个平面\n​​\nMöller Trumbore Algorithm\n快速求交点（重心坐标表示平面上的点）\n解线性方程组\nb1 和 b2 必须是非负的\n​​\n加速光线和表面求交\n如果每个三角形都求一次交点很花时间\n​​\n用包围盒进行加速如果一个光线碰不到包围盒，那就不可能碰到包围和里的物体\n​​\n三个对面形成的交集\n通常用 AABB 包围盒（和坐标轴平行的包围盒）\n​​\n2D 求交：\n​​\n3D 求交：3D 下有三组对面，光线要进入所有面才算进入盒子，只要出了一个面就认为出了盒子\n3D 对三组对面分别计算进入的最大时间和出来的最小时间\n如果出来时间小于进入时间，说明光线在盒子里待了一段时间\n​​\n离开时间小于 0，说明盒子在光线背后\n如果进入时间小于 0，说明起点在盒子里\n​​\n用 AABB 包围盒更好计算\n​​\n","categories":["图形学"]},{"title":"第十二章：Mesh细分、光线追踪","url":"/blog/%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0%EF%BC%9AMesh%E7%BB%86%E5%88%86%E3%80%81%E5%85%89%E7%BA%BF%E8%BF%BD%E8%B8%AA/","content":"网格操作：细分、简化、规则化Mesh 细分（引入更多的三角形，让三角形的位置发生变化，使得原来的模型变得更光滑）\nLoop Subdivision（Loop 不是循环的意思，是发明者的 familyname 是 Loop）\n​​\n1.把三角形分成更多的三角形：连接边的中点\n2.调整三角形的位置（把三角形的顶点区分成新的顶点和老的顶点，分别应用不同的规则改变顶点的位置）\n度：一个点相邻的边数。\n​​\n新的顶点用四周的老顶点做加权平均\n​​\n老的点用原本的点位置和相连三角形的顶点位置再加上度做加权平均。\nCatmull-Clark Subdivision（General Mesh）\nLoop Subdivision 只能处理三角形的情况，Catmull-Clark 可以处理任何面\n两个概念：\n1.非四边形面\n2.奇艺点（度不为 4 的点）\n​​\n细分：​​\n每一条边都选它的中点，每一个面都选中间的一个点。把边上的中点和面的中点连起来。\n只要是非四边形面，就一定会引入新的奇艺点。经过一次细分后，非四边形都会消失，也即不会再增加新的奇艺点。\n​​\n新的点考虑在面中心的点和边中心的点两种情况。\n老的点用它原本的位置和新的面中心点、边中心点做加权平均。\n​​\nMesh 简化不同情况下选用不同复杂度的模型，比如离得远的时候用简化模型\n​​\n但是几何的层级结构不好处理，从 300 个网格到 3000 个网格时平滑过渡怎么处理\n简化怎么计算？一种方法：边坍缩\n​​\n坍缩即找到一条边的两个顶点，捏成一个顶点，重点是找到要坍缩哪些点。\n用到一种叫做二次（平方）误差度量（Quadric Error Metrics）的方法\n​​\n找到一个最优位置，使得它到原本相关联的各个面的平方和达到最小。\n​​\n选坍缩的边的时候，给每个边一个分数表示坍缩后最优位置计算出来的平方和，选择平方和最小的边。但是坍缩一条边后，会影响其他相邻的边。所以需要一边求最小，一边动态更新任一点的值，需要用到优先队列（堆）的数据结构。\n​​\n局部取最小，更新受影响的边的二次度量误差，再取最小，再更新…\n用局部最优解找全局最优解（贪心算法）\n越简单越接近平面的面坍缩得越多（计算出来的二次度量误差越小），比如下图中的小奶牛的面部坍缩的多，但是颈部坍缩的少\n​​\n光线追踪光栅化怎么绘制阴影？\n着色是一种局部行为，仅考虑自己、光源和摄像机，不考虑其他物体，因此无法解决阴影的问题\n于是发明了阴影映射（shadow mapping）。\n\n图像空间算法\n\n\n在生成阴影的时候不需要知道场景的几何信息\n会产生走样现象\n\n\n主要思想\n\n如果一个点不在阴影里面，说明可以从照相机看到这个点，也可以从光源看到这个点\n如果一个点在阴影里，说明相机可以看到这个点，但是光看不到这个点\n\n\n\n经典的 shadow mappding 只能处理点光源，这种阴影是非 0 即 1 的阴影，叫做硬阴影\n​​\n从光源看向物体，生成一幅图，把不同位置看到的点的深度记录下来\n​​\n再从摄像机出发看向场景。把看到的点投影回光源，就知道之前记录到深度图上的深度。把记录的深度图深度和眼睛看到的点到光源的实际深度比较，如果二者一致，说明这个点一定即可以被光源看到，又可以被摄像机看到。\n​​\n如果深度不一致，说明这个点被挡住了。\n​​​​\nshadowMapping 会有各种问题：判断深度是否相等，需要判断两个浮点数相等，实际一定会有误差，有精度问题。\n另外 shadowMap 自己有分辨率，如果这个分辨率很低，但是渲染场景的分辨率很高，那么阴影信息是走样的\n另外要做两遍渲染，从光源看过去做一遍，从相机看过去做一遍，性能开销大\n​​\n硬阴影 VS 软阴影硬阴影要么可见要么不可见，边缘很锐利\n软光源边缘是慢慢过渡的，越靠近物体根部阴影越硬\n软硬指的是物理上的半影。如果一个地方完全看不到光源，则这个地方叫做本影区域，如果看得到部分光源就叫做半影，如果完全能看到则没有阴影。\n​​\n阴影程度取决于可以看到多大的光源。\n","categories":["图形学"]},{"title":"第十六章：Ray tracing4 蒙特卡洛路径追踪","url":"/blog/%E7%AC%AC%E5%8D%81%E5%85%AD%E7%AB%A0%EF%BC%9ARay%20tracing4%20%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E8%B7%AF%E5%BE%84%E8%BF%BD%E8%B8%AA/","content":"Ray tracing4 蒙特卡洛路径追踪\n回顾上节课\n\n辐射度量学\n\n光线传播\n\n反射方程\n渲染方程\n\n\n全局光照\n\n概率论复习\n\n\n本节课：\n\n简短的 review\n蒙特卡洛积分\n路径追踪\n\nreview\n渲染方程\n​​\n概率论\n​​\n蒙特卡洛积分在 a、b 随机采样，找到一个 x 对应的 f(x)，用 f(x)从 a 到 b 围出一个矩形。做多次采样，平均采样的结果，得到一个定积分的值。\n​​​​\n如果是均匀的采样，采样的 PDF 是一个常数：\n​​\n对于均匀的采样，蒙特卡洛的积分结果是：\n​​\n更通用的情况，不是均匀采样，即 x 的概率密度不是常数，可以通用的表示为：\n​​\n越多的采样，得到的结果越准。\n在 x 上积分，就得在 x 上采样。\nPath Tracing使用 Path Tracing 的原因是 whitted-style ray tracing 有一些不符合真实物理，需要提升这种算法。\n​​\n1.whitted-style ray tracing 无法处理磨砂材质的反射，他会认为反射光还朝着镜面反射的方向，而这是不对的：\n​​2.whitted-style ray tracing 认为光线打到漫反射到物体就停下来了，但真实的光线还会继续传播\ncolor-bleeding 一个面反射的光到了另一个漫反射的面上，反射面的颜色流到了被反射的面上\n​​\nwhitted-style ray tracing 是错的，但是渲染方程是对的。渲染方程包含了两个问题：\n​​\n1.对一个半球求解积分\n2.递归的问题\n可以用蒙特卡洛积分解渲染方程。考虑一个像素点在直接光照下：\n​​​​\n简单的做一个均匀的采样\n​​​​\n只考虑直接光照：随机选择一个方向从着色点发出一条射线，如果打到了光源，就把光源的贡献算出来，没打到光源的就不算\n​​\n如果是间接光照，Q 点打到 P 点的光照，就相当于 P 点有一个相机看向 Q 点，在 Q 点算出来的直接光照。\n​​\n这样可以写出一个递归的算法：\n​​\n但这样会有一些问题1.光线的弹射数量会爆炸\n​​\nN&#x3D;1，弹射的数量才不会爆炸。所以，每次只选择一个方向进行采样，这个就叫做路径追踪：\n​​\n每个像素会有 n 条路径，把 n 条路径的着色结果加起来求平均：\n​​​​\n2.递归不会停下来\n​​\n如果限制弹射次数，又会有能量损失。\n​​​​\n于是引入了俄罗斯轮盘赌，以一定的概率决定是不是要停止追踪\n​​\n最终期望的结果就是正确的结果：\n​​​​\n现在可以得到正确的结果，但不够高效：\n​​\n光源小的情况下，很多 ray 会被浪费：\n​​\n因此我们考虑对光源采样，从光源随机打出一条射线到着色点。\n​​但前面提过蒙特卡洛在 x 上采样就得在 x 上积分，但是渲染方程是对立体角积分，但采样是在光源上采样。\n因此，需要把渲染方程写成对光源积分的形式。\n先找到 dA 和 dω 的关系：\n​​\n均匀地对光源采样：\n​​\n最后把这个光照分为两部分：光源直接照射的部分和其他反射的部分\n​​​​\n还有一个问题，需要计算光源被挡住的情况：\n​​\n比较过去和现代的 raytracing过去特指 whitted-style ray tracing，现在是指光线传播问题的一些解决方法的大集合：\n​​\n还有一些没提到的问题：\n怎么对半球均匀采样\n怎么选择采样的 pdf（重要采样）\n怎么生成真正均匀的随机数\n能不能把光源采样和半球采样结合起来\n把经过像素的每条光线的采样结果做平均时是怎么做平均，是否需要加权\n算出来的 radiance 是怎么转换为颜色的\n​​\n​​​​\n","categories":["图形学"]},{"title":"第十八章：高级光线传播","url":"/blog/%E7%AC%AC%E5%8D%81%E5%85%AB%E7%AB%A0%EF%BC%9A%E9%AB%98%E7%BA%A7%E5%85%89%E7%BA%BF%E4%BC%A0%E6%92%AD/","content":"高级光线传播\n无偏的光线传播方法\n双向路径追踪（BDPT）\nMetropolis 光线传播（MLT）\n\n\n\n\n有偏的光线追踪方法\n\n光子映射（Photon mapping）\nVertex connection and merging（VCM，结合了光子映射和双向映射追踪）\n\n\n实时辐射度算法（把间接光表示成很多很小的光源）\n\n​​\n\n\n无偏和有偏蒙特卡罗不管用多少样本，期望永远是对的，被称为无偏的；其他情况就是有偏的，但如果取的样本非常多，多到无穷多，最后期望值会收敛到正确值。这个时候就称为一致的。\n​​\n双向路径追踪路径追踪是利用光路可逆性，从相机开始打出的路径，连接相机和光源\n双向路径追踪分别从光源和相机出发，生成两条半（子）路径，再把半路径的端点连接起来，就形成了整个路径。\n​​\n双线路径追踪适合光源在一侧的复杂传输，但是实现起来比较困难，且运行速度很慢\n​​\nMetropolis 光线传播用一个统计学上的采样工具马尔可夫链，通过当前的样本，生成和他靠近的下一个样本。可以做到只要给足够的时间，可以生成以任意的函数的形状为 PDF 的样本。\n而当采样的函数 p(x)和积分的函数 f(x)的形状一致的时候，得到的偏差是最小的。\n给定一条路径，可以生成周围更多和他相似的路径。因此是一个局部的方法。\n​​\nMetropolis 特别适合做复杂的光路传播，因为只要找到一条正确的，就能不断在它周围找到更多。\n​​\n缺点是：1.很难在理论上分析它收敛的速度（给一幅图，无法分析渲染多长时间才会收敛）\n2.所有操作都是局部的，有一些像素收敛的快，有一些收敛的慢，得到的图像比较“脏“\n3.因为不同像素收敛速度不一样，所以不能渲染动画。因为两帧之间会差距很大。\n​​\n光子映射光子映射是一个有偏的估计，很适合用来渲染 caustic（caustic 是由于光线聚焦产生的一些图案）。同时适合用来处理 SDS 路径。\n​​\n一种光子映射的方法：第一步：光子从光源出发，不断的反射和折射，直到光子打到 diffuse 的物体，就停下来。然后把所有的光子都记录下来\n第二步：从相机开始打出多条路径，直到打到 diffuse 的物体上就停下来\n​​\n接下来做局部的密度估计：\n对任何一个着色点，选择离他最近的 n 个光子，再找这 n 的光子占据的面的面积，计算光子的密度。光子分布的越集中的地方越亮。\n​​\n为什么是有偏的：正常计算密度应该用很小的 n 除以很小的面积，当实际的覆盖面积足够小（光子打出去的面积足够多）的时候，就接近真实的密度，这种情况被称为是一致的。\n​​\n在渲染里简单的理解有偏或无偏：有偏：只要结果有一点模糊，就认为是有偏的。\n一致的：虽然有模糊的，但是样本足够多，就能收敛到正确的结果。\n​​\nVertex Connection and Merging双向路径追踪和光子映射的结合\n主要思想是：对于两个 subpath，最后他们的交点非常接近的时候，用光子映射把两个 subpath 结合到一起。\n​​\nInstant Radiosity 实时辐射度认为已经被照亮的地方就是光源，可以继续照射别的地方。\n假设从光源射出来的光线最后会停在某个地方，这个地方就变成了一个虚拟的点光源，然后用这些虚拟的点光源照亮着色点。\n​​\n缺点：\n1.在一些接缝会出现一些光点\n2.做不了镜面的材质\n​​\n出现光点的原因是：做 light sampling 的时候，对积分域转换，把对立体角的采样转换成对面积的采样。此处分母出现了一个距离的平方，当距离很近，接近 0 点时候会出现一个很大的结果。\n​​\n工业界现在主要在用 path tracing 的方法。\nAdvanced Appearance Modeling 外观建模\n非表面模型\n\n散射介质\n头发、毛发、纤维\n粒状材质（沙子）\n\n\n表面模型\n\n半透明材质\n布料\n有细节度的模型\n\n\n程序化生成的模型\n\n​​\n\n\n非表面模型散射介质：雾、云\n​​​​\n光线的传播过程中会：1.被吸收 2.被散射\n​​\n由 Phase Function（相位函数）来定义在每个点怎么散射\n​​\n散射介质的渲染随机地找到一个方向发生弹射，随机地往一个方向前进，找到一个 path 把各个弹射的位置相连。\n​​\nparticipanting media 有很多应用：超能特工队\n​​\n刺客信条：\n​​\n巧克力也是一种散射介质，只是光进去了以后很快就会消失\n​​\n**头发（**光线和一根曲线作用）有两种类型的高光：有色的高光和无色的高光。\n​​\nKajiya-Kay把头发当成一个圆柱，光线打到上面会散射出一个圆锥。同时，有一些光线会被散射到四面八光（有点类似于 Diffuse 和 Specular 加起来）。\n​​​​\nMarschner Model\n考虑光线打到头发上，有一部会直接反射，记为 R\n一部分会打进去，发生折射，再打出来，记为 TT\n还有一部分进到头发里面，走到内壁，发生一次内部的反射，再发生一次穿透，记 TRT\n​​\n把头发当成一个玻璃材质的圆柱，有表皮（cuticle）和皮层（cortex）。头发内部有色素，光线传播进去会有部分被吸收。\n​​​​\n光线打到多根头发，就会从一根头发弹射到另一根头发，所以计算量巨大。\n头发模型的应用：\n​​​​\n人的头发模型不足以描述光线和动物毛发的作用\n​​\n毛发除了之前提到的表皮和皮质层，还有中间的髓质层，光线进入髓质层会被反射到四面八方。而动物毛发的髓质层比人要粗很多。\n​​​​​​\nDouble Cylinder Model（双层圆柱模型）\n​​\n相比之前增加了光线穿过髓质折射出来的分量 TTs 和光线穿过髓质，发生反射再穿出来的分量 TRTs\n​​\n最后头发的颜色由五个分量结合而成：\n​​​​​​​​\nGranular Material（颗粒材料）\n​​\n可以做一些简化，不去计算每一个颗粒。\n比如下图中，把整个模型分成很多个单元，每个单元中由不同的材质按不同的比例来构成。用这种单元模型去做渲染。\n​​​​​​​​\n非表面模型 translucent material （半透明材质）光线可以从某个地方进去材质表面，从另外一个面穿出来。\n​​玉石：\n​​\n水母：\n​​\n次表面散射：光线从一个点进入物体表现，发生了很多次反射，再从另一个表面出来。]\n​​\n次表面反射是对 BRDF 的延伸，BSSRDF，中间加了 SS（次表面反射）。即计算一个点的反射，除了考虑各个方向对这个点的影响，还要考虑其他点反射过来的光，既要对方向做积分，又要对面积做积分。\n​​\nDipole Approximation次表面反射可以近似为物体内部的一个光源加上外部的一个光源共同照射的结果：\n​​​​​​​​​​\nBSSRDF 的应用：\n​​\nCloth 材质\n很多纤维缠绕形成股，很多股缠绕形成线，最后织成布。\n​​\n有三种方法进行渲染：\n1.把布当作表面，用 BRDF 模型进行渲染。根据不同的织法、形状得到不同的渲染结果。\n​​\n但是明显布的材质不一定是一个表面，比如天鹅绒材质。\n​​\n2.像散射介质一样渲染：把空间分成很小的格子，知道每个格子的纤维朝向分布、复杂程度。把这些性质转换为光线的吸收和散射，就像是渲染散射介质。\n​​\n3.把每一根纤维都渲染出来，当头发一样渲染。\n​​​​​​\n有细节的复杂材质\n​​​​​​​​​​​​​​​​​​​​​​\n我们认为每一个微表面都是镜面，很难通过反射的方式让光线打到光源或者摄像机上。所以用一个像素覆盖很多微表面，在一个小的范围内把微表面的法线分布算出来，替代之前光滑的分布。\n​​\n不同的范围选择会得到不同的微表面法线分布结果：\n​​\n不同性质的材质会得到不同形状的微表面分布：\n​​​​​​\n细节材质的应用\n​​\n在微型的细节上，比如物体很小，小到和光的波长相当，此时不能从几何光学的角度去分析，要考虑光的振动，需要用到波动光学。\n​​\n在一个黑暗的房间里用点光源打出一道光，会看到材质表面有很多颜色：\n​​​​\n波动光学下的 BRDF：\n​​​​​​​​​​\n程序化生成的表面（Procedural Appearance）\n用三维空间中的噪声函数生成材质外观，procedural 表示不提前生成，随用随取，用的时候去查询。\n​​​​\n对噪声函数可以做一些处理得到不同的效果，比如车上的锈，可以做二值化，有些地方有，有些地方没有。\n​​\n噪声函数的应用生成地形\n​​\n生成水面\n​​\n生成三维的木头，任意切割可以得到内部的外观\n​​\n​​\n","categories":["图形学"]},{"title":"第十五章：Ray tracing 3 光线传播和全局光照","url":"/blog/%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0%EF%BC%9ARay%20tracing%203%20%E5%85%89%E7%BA%BF%E4%BC%A0%E6%92%AD%E5%92%8C%E5%85%A8%E5%B1%80%E5%85%89%E7%85%A7/","content":"RayTracing 3 光线传播和全局光照\n回顾上节课\n\n基础的光线追踪\n\n光线生成\n光线和对象求交\n\n\n加速\n\n光线和 AABB 盒求交\n空间划分 VS 物体划分\nBVH 遍历\n\n\n辐射度量学\n\n\n本节课\n\n继续辐射度量学\n\n光线传播\n\n反射方程\n渲染方程\n\n\n全局光照\n\n概率论\n\n\n回顾上节课的概念\nRadiant energy Q \nRadiant flux（power）（单位时间的能量）\nRadiant intensity （单位立体角的能量）\nSolid Angle（立体角）我们考虑光照都是用瞬时量，因为物体一般接受能量一边也在辐射能量，有一些荧光的材质可能收到光线时间长短影响有不同的颜色，这种情况先不考虑。\n​​\n微分立体角（θ，Φ）不是均匀的划分球体面积，靠近顶（底）部，sinθ 小，微分立体角小，靠近球中间，sinθ 大。\n​​\nIrradiance（power per unit area）单位面积垂直方向上的光线的能量，光如果不是垂直的，需要计算垂直方向的投影\n​​\n夏天太阳垂直照射，冬天有一个倾斜角度\n​​\nIrradiance Fallof单位立体角的能量不会衰减（r 越大辐射面积越大，单位体积角始终不变），单位面积能量会衰减。\n​​\nRadiance光线传播过程中带的能量。单位立体角、单位投影面积上的能量。\n​​​​\nirradiance 和 radiance 的区别：是否有方向性。radiance 可以理解为单位面积上某个方向接受到的能量。\n​​\n也可以用 intensity 来理解，即一个单位面积上往一个方向辐射出去的能量。\n​​\n对各个方向的 radiance 积分得到 irradiance。H 平方表示半球。\n​​\n反射方程：Bidirectional Reflectance Distribution Function （BRDF， 双向反射分布函数）\n理解反射：可以理解为光线发射到一个物体表面，被吸收了，再从某一个角度发出去\n​​\ndE(ω_(i))表示 dA 在一个方向上的单位立体角接收到的能量，dL_(r)(ω_(i))表示一个比率：dA 上任何一个出射方向算出来的 radiance 除以 dA 接收到的 irradiance。\n​​\nBRDF 定义了光线和物体是怎么作用的，定义了不同的材质\n任何一个输入方向对观测方向的贡献加起来得到最终的光照\n​​\n光线会弹射多次，任何出射的 radiance 都有可能成为入射的 radiance，所以是一个递归的问题。\n​​\n渲染方程（绘制方程）假如物体自己会发光，出射的光线包含两部分。\n​​\n方程中假设所有方向都是向外的。\n一个点光源：\n​​\n如果有很多点光源，就把每个点光源的反射加起来：\n​​\n如果是一个面光源，就把面光源上每个点的反射积分：\n​​\nradiance 不只是从光源发出的，也有可能是其他点反射的 radiance。\n​​\n简写渲染方程：\n​​\n写成算子的形式：E：光源发出的能量，K：反射操作符，KL：反射的能量\n​​\n求解 L，下图 I 表示单位矩阵，最后 L 可以写成一种泰勒展开的形式：\n​​\nL 表示为一种弹射次数的分解：\n弹射 0 次：光源自己\n弹射一次：直接光照\n弹射两次及以上：间接光照\n全局光照：直接和间接光照的集合\n​​\n光栅化做的部分：弹射 0 次和 1 次，后面的部分光栅化很难处理，因此用光线追踪来处理\n​​\n接下来求解渲染方程。\n需要一些前置的概率论知识：\nX：随机变量\np(x)：随机变量的概率分布\n​​\n概率：\n​​\n期望（平均）：\n​​\n连续情况下描述变量和分布（概率密度函数）：\n​​\n如果有一个随机变量的函数，函数的期望等于函数在某个变量的值乘以对应的概率密度再积分。\n","categories":["图形学"]},{"title":"第十四章：Ray tracing2 加速结构、辐射度量学","url":"/blog/%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0%EF%BC%9ARay%20tracing2%20%E5%8A%A0%E9%80%9F%E7%BB%93%E6%9E%84%E3%80%81%E8%BE%90%E5%B0%84%E5%BA%A6%E9%87%8F%E5%AD%A6/","content":"Ray Tracing 2\n\n加速结构\n辐射度量学\n\n题外话：\nGTC（GPU Technology Conference）：\n\nDLSS（Deep Learning Super Sampling）2.0 https://zhuanlan.zhihu.com/p/116211994\n\n光栅化生成一个 1080p 的图，把它拉大成一张 4K 的图，结果不损失太多性能，同时看上去依然清晰\n\n\nRTXGI（全局光照）https://developer.nvidia.com/rtxgi\n\n\n回顾上节课：\n\n为什么要做光线追踪\n\nWhitted-style ray tracing（递归的光线追踪，光线弹射到多个地方，在每个交点计算着色和阴影）\n\n光线和物体求交\n\n光线和隐式表面求交\n光线和三角形求交\n\n\nAABB 包围盒\n\n理解包围盒：坐标轴上三对相对的平板\n光线和 AABB 盒求交\n\n\n\n本节课：\n\nAABB 盒怎么加速光线追踪？\n\n均匀的网格（Uniform grids）\n空间划分 （spatial partitions）\n\n\n辐射度量学\n\n\nAABB 加速光线追踪均匀的网格：Uniform Spatial Partitions（Grids）\n先让光线和盒子求交，再进一步和盒子里的物体求交\n预处理：\n1.先找到场景里的一个包围盒\n2.把盒子分成一堆格子\n3.标记与物体表面相交的格子\n​​​​\n怎么判断光线继续往后传播时要和哪个盒子求交，不能每个格子都求一遍。有一个简单的思路是：如果光线往右上传播，就只看当前格子右边和上面的格子，判断光线与哪个格子有交点，再把光线移动一格。光栅化一条线:https://zhuanlan.zhihu.com/p/20213658。\n加速效果：一个格子（格子很稀疏），基本没有加速效果\n​​\n格子太密，要做很多次光线和格子的求交，效率很低\n​​\n需要找一个平衡\n​​\n当几何物体在场景中分布比较均匀时，格子加速的效果比较好\n​​\n物体在场景中分布不均匀的时候，加速的效果不好\n​​\n空间划分 Spatial Partitions三种空间划分的结构：Oct-Tree：8 叉树，把空间分成 8 个小方块，小方块继续分割，当格子里是空的，或物体足够少，就停止分割（平面是 4 叉树，即分成几份和维度有关系）\nKD-Tree：2 叉树，每次一个格子只砍一刀（水平竖直沿着坐标轴交替划分，基本保证划分的空间是均匀的）\nBSP-Tree：选一个方向砍一刀\n​​\nKD-Tree 预处理，建立加速结构把空间划分为二叉树：\n​​\n数据结构：\n中间节点需要存储：\n\n当前节点沿着哪个坐标轴划分\n划分在哪个位置（不一定划分在中间）\n2 个子节点\n\n叶子节点需要存储：\n\n和格子相交的几何物体\n​​\n\n判断光线和当前节点是不是有交点，如果有交点，继续判断和当前节点的子节点是不是有交点，一直到叶子节点，如果光线和叶子节点有交点，就求光线和叶子节点里面所有物体的交点；如果光线和当前节点没有交点就不需要继续往下找。如果是求最近的交点就一边找一边记录最近的。\n​​​​​​​​​​​​\nKD-Tree 的问题：\n1.不好判断几何对象（三角形）和盒子是否有交集\n2.1 个对象可能和不同的盒子都有交集，即同一个物体会被多个叶子节点存储\nObject Partitions &amp; Bounding Volumn Hierarchy（BVH）划分物体：把一个盒子里的三角形分为两部分，把两部分的三角形再重新求包围盒，然后每个包围盒继续划分，直到一个包围盒里包含的节点数够少就停止划分。\n​​​​​​​​\nBVH 的好处是：一个物体只可能出现在一个盒子里，且无需求三角形和包围盒的交点，避免了 KD-Tree 的问题。\n但 BVH 也有一个问题：BVH 对空间的划分不是很严格的划分开，BoundingBox 可以相交，所以需要在划分几何形体的时候尽量减少重叠。\n​​\n总结构造 BVH 加速结构的过程：\n1.找到一个包围盒\n2.递归地把包围盒中的物体拆成两部分\n3.重新计算包围盒\n4.当包围盒的物体足够少的时候停止递归\n5.把物体信息存储在叶子节点里\n怎么做节点的划分？\n\n选一个维度\n\n方式 1：每次选一个最长的轴把节点分成两半，使得节点最后分布比较均匀\n\n方式 2：取中间的三角形的位置把节点分为两半，是的分割后节点的三角形数量差不多，让这个树形结构两边保持平衡（深度小，平均搜索次数小）\n\n取中间的三角形涉及到排序：所有三角形取重心，沿一个轴排个序，找到中间的那个三角形。（也可以不用排序找中位数，快速选择算法，可以达到 O(n)的时间复杂度）\n\n\n如果场景是动态的，三角形数量会变化，就需要每次变化都重新算一下 BVH。\n​​\n\n\nBVH 的数据结构：中间节点存储：\n\n包围盒\n子节点的指针\n\n叶子节点存储：\n\n包围盒\n实际的物体\n​​\n\nBVH 算法伪代码：\n​​\n空间划分和物体划分的区别：\n​​\n以上是 Whitted-style 光线追踪的内容。\n辐射度量学 Basic radiometry为什么要学习辐射度量学？\n之间的 Blinn-Phong 模型里提到光的强度 I 是怎么得到的，他的物理意义是什么？\n​​\nWhitted-style 光线追踪给的结果是正确的吗？\n​​\n辐射度量学给了一种精准定义光照的物理量的方法。\n辐射度量学学习的内容：为如何描述光照定义了一系列的方法和单位\n给光定义了各种空间中的属性（仍然是基于几何光学，认为光线沿直线传播）：\n​​\n\nRadiant flux，intensity，irradiance，radiance\n\nRadiant Energy and Flux\nRadiant energy 是电磁辐射的能量，单位是焦耳，用符号 Q 表示。\nRadiant Flux 是单位时间的能量。\n​​\n另一种理解：单位时间通过感光平面的光子的数量\n​​\n光源辐射的能量：radiant Intensity，定义了方向性和能量相关的概念\n物体表面接受到了多少能量：Irradiance\n光线传播中的能量怎么度量：Radiance\n​​\nRadiant Intensity\n单位立体角上点光源辐射出的单位能量\n​​\n立体角：角度：弧长&#x2F;半径\n立体角：角度在三维的延伸。锥体对应的面积&#x2F;求面的面积。\n​​\n单位立体角（微分立体角）\n​​\n对单位立体角做积分可以得到整个球面\n​​\n在辐射度量里面通常用 ω 表示方向，ω 可以用 θ 和 φ 来定义位置，并通过 sinθdθdφ 算出单位立体角。\n​​\n对一个点光源，radiant intensity 是单位立体角的能量，把所有方向上的单位立体角的 intensity 积分，就可以得到它的 power，反之任何一个方向的 Intensity 就是 power&#x2F;4π。\n​​\n小知识：现代 LED 灯上标注的瓦数不是真实的，而是对应于白炽灯的瓦数，LED 实际瓦数更低。\n​​\n","categories":["图形学"]},{"title":"第十章：纹理应用、几何","url":"/blog/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E7%BA%B9%E7%90%86%E5%BA%94%E7%94%A8%E3%80%81%E5%87%A0%E4%BD%95/","content":"Shading 1&amp;2\n\nBlinn-Phong 反射模型\n着色模型&#x2F;着色频率\n图形管线\n纹理映射\n\nShading 3\n\n重心坐标系\n\n纹理反走样（MIPMAP）\n\n纹理太小插值，纹理太大 MIPMAP 范围查询\n\n\n纹理应用\n\n\n纹理应用纹理：一块内存，可以做不同的范围查询（过滤）环境光照（环境光映射）\n把任何一个方向来的光都记录下来，用纹理描述环境光，用环境光渲染其他物体。假设环境光源都是来自无限远处，不考虑位置。犹他茶壶\n​​​​​​\n环境光可以记录在球面上，放在不同的方向上记录一个点，再把图展开（就像世界地图）\n但这样会在顶部和底部出现扭曲\n​​\n此时可以假设球外面有一个包围盒，把球心到球表面的连线延长到立方体上，把环境光信息记录在一个立方体上对应的 6 个面上，再把立方体展开：\n​​\n6 个面基本是均匀的，所以不会发生扭曲，但是需要计算方向和面的对应关系。\n​​\n凹凸贴图（法线贴图）纹理不只是可以表示颜色，也可以表示高度。\n可以在不把几何形体变复杂的情况下，定义任意一个点的相对高度，通过相对高度计算出一个假的法线，产生着色上的明暗对比。\n​​\n对像素做扰动，重新计算法线方向\n​​\n用相邻两点的高度差除长度，得到切线，通过切线旋转 90 度再算法线\n​​\n三维情况下需要计算两个方向的切线（假设局部坐标系的法线是（0，0，1））：\n​​\n位移贴图凹凸贴图没有真正改变顶点的高度，在边缘和自己的几何会产生自己的阴影的情况下表现失真，这个时候用位移贴图，真正改变三角形顶点的高度。问题就是三角形需要定义得足够细，能跟上纹理定义的频率。\n​​\nDirectX（动态曲面细分） 先应用一个粗糙一点的模型，应用过程中检测是否满足要求，根据需要把三角形拆得更细做位移贴图。\n三维过程噪声不真正生成纹理图，定义一个三维噪声函数，计算空间中每一个点计算出噪声的值，再通过一些计算得到纹理。\n​​\n预计算阴影​​\n先计算环境光遮蔽写进纹理图，再把纹理图乘以着色的结果，得到阴影。\n三维体积渲染医学成像，核磁共振扫描人体，得到一个密度的三维纹理。\n几何曲线、光滑曲面、齿轮、布料（透明的、纤维）、水的表面形状、城市（大量几何形状）、动物毛发、细胞等等怎么用几何表示。\n隐式表示\n满足特定关系的一些点表示一个几何，比如一个球体。\nf(x,y,z) &#x3D; 0;\n​​\n问题：不好直接看出来表示的几何是什么形状\n好处：可以很快得判断一个点在不在这个几何面上（在几何体内还是外）\n显式表示\n1.把几何上的面的点直接表示出来\n2.通过参数映射定义表面\n​​\n好处：很容易找到形状，把(u,v)都算一遍\n问题：不能很快判断一个点是不是在表面上（在几何体内部还是外部）\n隐式表示方法：\n代数曲面：\n​​\n可以不只用代数方式来表达：\nConstructive Solid Geometry（构造立体几何法，CSG）\n用基础的结构体做一些简单运算形成复杂的几何：\n​​\nDistance Function（距离函数）定义任意一个点到这个几何体表面的最近距离\n如果距离是正的，说明这个点在物体外部，距离是负的则在物体内部\n对两个几何做融合（blend）得到 A→B 从左到右运动的一个中间状态。blend 两个几何的距离函数，其实就是 blend 两个边界。可以通过 blend 出来的结果距离函数，还原出边界（SDF 为 0）。\n​​\n距离函数也可以不写成解析表达式，比如水平集\n等高线也是类似\n​​\n水平集也可以定义在三维上。比如计算三维中 f(x)等于某一个值的所有点，可以得到一个三维空间中的一个表面。医学扫描\n​​\n水滴融合\n​​\n分形自重复几何\n​​\n总结：\n优点：隐式函数表示起来比较容易，对存储也比较友好，比较容易判断是否在物体表面。用隐式函数表示的表面很容易对光线求交。严格地表示简单形体，很容易给出准确描述。很适合描述拓扑结构。缺点：对复杂的模型很难用一个规则的函数来描述。\n","categories":["图形学"]},{"title":"第四章：三维变换","url":"/blog/%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E4%B8%89%E7%BB%B4%E5%8F%98%E6%8D%A2/","content":"补充知识：旋转矩阵的逆等于它的转置，如果一个矩阵的逆等于它的转置，数学上称为正交矩阵\n​​​\n​​​\n本章知识：\n3D 变换\n\nviewing（观测）变换\n\nView（视图）&#x2F;Camera transformation\n\nProjection（投影） tranformation\n\nOrthographic（正交）projection\nPerspective（透视）projection\n\n\n\n\n\n三维变换​\n​\n​​​​\n绕坐标轴旋转\n​​\nx 和 z 的旋转矩阵和 y 的旋转矩阵是互逆的。循环对称：x 叉乘 y 得到 z，y 叉乘 z 得到 x，但是得到 y 是要 z 叉乘 x 而不是 x 叉乘 z。\n一般旋转用简单的旋转组合形成复杂的旋转\n​​\n绕任意轴的旋转都可以转换为绕 x、y、z 轴的旋转罗德里格斯旋转公式（Rodrigues‘ Rotation Formula）\n​\n其中 n 是任意旋转轴（可以不经过原点），α 是旋转角\n绕任意轴旋转：先平移，让旋转轴位于原点，再旋转，再平移回来。四元数：解决插值问题。比如二维旋转 20 度的矩阵和旋转 30 度的矩阵相加后除以 2，不等于旋转 25 度的旋转矩阵，需要用到四元数做旋转和旋转间的插值。\nViewing Transform\n什么是视图变换\n\n拍照片（MVP 变换）\n\n找一个好的位置放置模型（model transformation）\n找一个好的角度（view tansformation）\n茄子！（projection transformation）\n\n\n\n模型视图变换（Model viewing transformation）放在哪，往哪看，相机的向上方向（相机怎么摆）\n​\n​​​\n约定俗成：相机放到（0，0，0）位置，向上摆放，沿着-Z 方向看\n​\n​​​\n直接旋转角度到坐标轴不好处理，但把坐标轴旋转到某个方向比较容易，所以可以先旋转坐标轴，得到旋转矩阵，再求它的逆。\n​​\n正交矩阵的逆就是它的转置。先把中心移动到原点再做旋转的到的变换就是视图变换。相机通过这种变换变换到一个固定位置，其他物体也做一样的变换，保持和相机的相对位置不变。总结：\n\n任何时候相机和物体做一样的变换\n\n只要相机能移动到规定的位置，那其他物体也会落到需要的位置上\n\n\n所以模型视图经常一起变换，被称为模型视图变换。\n投影变换（Projection TransFormation）​​\n正交投影不会近大远小（鸽子为什么那么大）\n​​\n透视投影就是把相机放在空间的一个点，往一个方向连出一个四棱锥，把这个四棱锥某一个深度到另一个深度之间的区域（frustum）都显示出来，显示到近处的平面上正交投影假设相机离得无限远，这个时候近和远基本是一样的大小\n正交投影简单做法：\n相机移到原点，把 z 轴扔掉（怎么区分物体前后后面再说），所有东西都在(x,y)上，然后把范围约束到[-1，1]² 这样的一个矩形里（约定俗成），得到正交投影的结果。\n​​\n正式的做法：\n​​\n定义一个立方体，映射到一个正则（规范、标准）立方体上。先做平移，再做缩放。\n这里用的是右手系，z 方向向外，面离我们更远则 z 值更小，离我们更近则 z 值越大，所以 f 小于 n。所以有一些图形学的 API（比如 OpenGL 从透视空间到裁剪空间，webgl 也是类似）会用左手系，让 z 方向朝里。\n​​\n透视投影近大远小平行线不再平行\n​​\n先把锥体向内挤压成一个立方体，约定近面和远面的 z 轴不变，远面中心点不变，近面大小不变（从透视到正交）。\n再做正交投影\n​​\n找到远面的 y 和近面的 y’之间的比例关系\n​​\n齐次坐标里，点矩阵乘一个数字和以前表示的含义一样\n​\n​​​\n近平面的所有点不改变，可以计算出转换矩阵的前两个数字\n​​\n远平面中心点不变，结合前面近平面的特征，可以计算出剩下两个数字\n​​\n最终得到透视到正交的转换矩阵\n​​\n思考：在近平面和远平面之间的中心点被挤压时，会被推向近平面还是远平面？对原矩阵做转换后，得到的结果的第四行的值为(0 0 1 0) 和 (x y z 1)相乘后得到：z；计算 z 转换后的值为（f&lt;z&lt;n）值：z(n+f)-nf，需要除以 z 把最后一位变为 1 后再和原来的 z 比较\n求解：(z(n+f) - nf)&#x2F;z 和 z 的关系，转换为抛物线求解，y &#x3D; z(n+f)- nf - z² , z 在 n 和 f 之间变化时，有两个解 n 和 f，且抛物线开口向下，即当 z 位于 n 和 f 之间时，其变换后的 z 的绝对值始终大于原来的 z 的绝对值。\n‍\n","categories":["图形学"]},{"title":"虚假的洗牌算法","url":"/blog/%E8%99%9A%E5%81%87%E7%9A%84%E6%B4%97%E7%89%8C%E7%AE%97%E6%B3%95/","content":"虚假的洗牌算法最常见的：\nconst shuffle = (list) =&gt; list.sort((x, y) =&gt; Math.random() - 0.5)\n\n可这并不合理，对于这个数组：[1,2,3,4,5]，每个数字出现在每个位置的概率应该是相同的。然而使用以上算法，1 出现在 index&#x3D;4 位置的概率 与 4 出现在 index&#x3D;4 的概率并不相同。\n真正的洗牌算法Fisher–Yates shuffle\nconst nums = Array(54)  .fill(undefined)  .map((_, index) =&gt; index)/** * 洗牌算法 * @param nums 数组 */function FYSufffle(nums) &#123;  const randNums = Array.from(nums)  let len = nums.length  while (len &gt; 1) &#123;    const rand = Math.floor(Math.random() * len)    len--    // 交换    ;[randNums[rand], randNums[len]] = [randNums[len], randNums[rand]]  &#125;  return randNums&#125;console.log(FYSufffle(nums))\n\n以上。\n","categories":["算法"]},{"title":"网络测速","url":"/blog/%E7%BD%91%E7%BB%9C%E6%B5%8B%E9%80%9F/","content":"前端如何测试网络的速度？B 站视频播放时有一个自动根据网络环境调整分辨率的功能，想了解如何测速\n然后我找了下面的方法测速\najax 请求利用 XMLHttpRequest 请求返回的 Content-length，和请求所需时间求得下载速度\nconst getSpeed = (url) =&gt; &#123;  return new Promise((resolve) =&gt; &#123;    const start = window.performance.now()    const xhr = new XMLHttpRequest()    xhr.open(&quot;GET&quot;, url)    xhr.onreadystatechange = function () &#123;      if (xhr.readyState === 4) &#123;        const time = (window.performance.now() - start) / 1000        const size = xhr.getResponseHeader(&quot;Content-Length&quot;) / 1024        console.log(time, size)        resolve(size / time)      &#125;    &#125;    xhr.send()  &#125;)&#125;getSpeed(&quot;./worker.js&quot;).then((speed) =&gt; console.log(speed))\n\n请求我本地的文件测得速度：\nImage 对象 onloadconst getSpeed = (url, fileSize) =&gt; &#123;  return new Promise((resolve) =&gt; &#123;    const start = window.performance.now()    const img = new Image()    img.src = url    img.onload = (e) =&gt; &#123;      const time = (window.performance.now() - start) / 1000      resolve(fileSize / time)    &#125;  &#125;)&#125;\n\n但是要注意如果请求服务器的文件，建立请求也需要消耗时间，最好是多次请求取平均值。\n还有一个 downlinkdownlink 的单位是 mbps, 所以要转化成 kb&#x2F;s\n","categories":["js"]},{"title":"包体积超限问题","url":"/blog/%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%8C%85%E4%BD%93%E7%A7%AF%E8%B6%85%E9%99%90%E9%97%AE%E9%A2%98/","content":"背景某日发布节点后，监控平台发现包体积超限，增长很多，于是拉了各个业务方进行排查\n排查我这边用 webpack-bundle-analyzer 发现增长的体积和懒加载的代码体积刚好对得上，怀疑是不是懒加载代码加载的时间提前了，代码有循环引用之类的，导致应该懒加载的代码，提前加载进来了。但是逐一查看改动代码，没有发现循环引用的情况。\n又看了下监控的数据，发现统计的数据是不稳定的，在这之前也有部分数据超限，感觉统计代码的脚本不是很稳定，于是又去看统计代码体积的脚本。看了代码，发现统计脚本是在插件加载完成后使用 performance.getEntriesByType 来获取所有加载的 script 资源的体积数据。\n又想到前两天上线的一个 如何实现全局图片监控 的功能中，有一行代码是改动了 performance 的缓存空间大小\nperformance.setResourceTimingBufferSize(2000)\n\n于是怀疑是不是这个改动影响了统计代码体积的脚本，于是把这段代码删掉，重新发布，发现包体积恢复’正常’。把这个size改为一个小值，跑一下脚本，发现统计的数据更少了，说明这个改动确实影响了统计代码体积的脚本。\n看了下这个 setResourceTimingBufferSize，这个接口用于设置浏览器资源计时缓冲区的大小。这个缓冲区用于存储页面加载过程中各种资源的性能数据，例如加载时间、传输时间等。这些数据可以通过 Performance 接口进行访问和分析。\n当缓冲区达到设定的最大大小时，新的资源计时数据会替换掉最早的数据。这意味着，如果缓冲区已满，最早进入缓冲区的数据会被新的数据覆盖。\n这个值不手动设置默认是 250， 又手动看了下打开页面后的资源大概多少，发现数值在 400 左右，所以初始的值 250 统计的值可能是偏小的，部分数据被丢掉了，数据不准确。\n把这个问题反馈上去，调整统计体积脚本的代码，设置了一个较大值去统计所有初始加载的资源，包括部分 prefetch 的懒加载代码，以调整后的资源大小作为基线去评估后面的包体积增长情况。\n总结这次排查总的来说还是比较幸运的，还是需要从代码和监控数据入手，大胆假设，小心求证。\n\nwebpack-boundle-analyzer 可以用来查看打包后的体积分布情况\nperformance.getEntriesByType 可以用来获取所有加载的资源的体积数据\nperformance.setResourceTimingBufferSize 可以用来设置 performance 的缓存空间大小，这个改动可能会影响 performance.getEntriesByType 的结果\n\n","tags":["js","性能"]},{"title":"逆天!纯CSS实现获取窗口大小","url":"/blog/%E9%80%86%E5%A4%A9!%E7%BA%AFCSS%E5%AE%9E%E7%8E%B0%E8%8E%B7%E5%8F%96%E7%AA%97%E5%8F%A3%E5%A4%A7%E5%B0%8F/","content":"先看看效果\n\n\n看看代码是怎么样的\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;    &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;style&gt;    @property --vw &#123;        syntax: &quot;&lt;length&gt;&quot;;        inherits: true;        initial-value: 100vw;    &#125;    @property --vh &#123;        syntax: &quot;&lt;length&gt;&quot;;        inherits: true;        initial-value: 100vh;    &#125;    :root &#123;        --w: tan(atan2(var(--vw), 1px));        --h: tan(atan2(var(--vh), 1px));    &#125;    body::before &#123;        counter-reset: w var(--w) h var(--h);        content: counter(w) &quot;X&quot; counter(h);        font-size: 100px;        margin: auto;        height: fit-content;        width: fit-content;        position: fixed;        inset: 0;    &#125;&lt;/style&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;\n\n就这么几行代码\n我们来分析一下\n首先，通过伪元素实现内容的水平垂直居中\nbody::before &#123;        content: “width X height”;        font-size: 100px;        margin: auto;        height: fit-content;        width: fit-content;        position: fixed;        inset: 0;&#125;\n\n然后定义了两个 CSS 的自定义属性：\n@property --vw &#123;        syntax: &quot;&lt;length&gt;&quot;;        inherits: true;        initial-value: 100vw;    &#125;@property --vh &#123;        syntax: &quot;&lt;length&gt;&quot;;        inherits: true;        initial-value: 100vh;&#125;\n\n详细的解释：\n\n​ ​@property --vw { ... }​ ​:\n\n这行代码定义了一个新的 CSS 自定义属性 --vw​。@property​ 是一个 CSS at-rule，用于定义自定义属性。在这个例子中，--vw​ 是一个自定义属性，用于表示视口宽度的百分比。\n\n\n​​syntax: &quot;&lt;length&gt;&quot;;​ ​:\n\n这行代码定义了 --vw​ 的语法类型。&lt;length&gt;​ 表示这个自定义属性的值是一个长度值，例如 px​, em​, rem​, vw​, vh​ 等。\n\n\n​​inherits: true;​ ​:\n\n这行代码定义了 --vw​ 是否可以继承。true​ 表示这个自定义属性可以被子元素继承。\n\n\n​​initial-value: 100vw;​ ​:\n\n这行代码定义了 --vw​ 的初始值。100vw​ 表示视口宽度的 100%，即整个视口的宽度。\n\n\n\n这几行代码定义了一个名为 --vw​ 的 CSS 自定义属性，用于表示视口宽度的百分比。这个属性可以被子元素继承，并且其初始值是视口宽度的 100%。\n之后，关键的来了：\n:root &#123;        --w: tan(atan2(var(--vw), 1px));        --h: tan(atan2(var(--vh), 1px));&#125;\n\n首先我们知道三角形一个角的对边&#x2F;临边&#x3D; tanA​，用反三角函数可以求得 A​ 的角度。也就是说 atan2(var(--vw), 1px)​ 这里求得的是（浏览器宽度&#x2F;1px 高度）所对应的那个角的角度值，然后再对这个角度求 tan​ 值，即可得出浏览器的当前宽度。这里求得的值是带 px​ 单位的，浏览器会自动转换将原来的 vw ​ 转为 px​。\n接下来就需要去掉px​把这个数值写入页面，利用的是 css counter​ 方法：\n// 1. 定义 w 为 var(--w) 的名字counter-reset: w var(--w) h var(--h);// 2. 利用 counter(w) 拿到值content: counter(w) &quot;X&quot; counter(h);\n\n以上\n"},{"title":"高性能的JavaScript","url":"/blog/%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84JavaScript/","content":"加载和执行每个&lt;script&gt;标签初始化下载都会阻塞页面渲染，所以减少页面的&lt;script&gt;标签数量可以起到优化作用，内嵌脚本外链脚本通用,另外HTTP会带来的额外的性能消耗，下载一个100KB的文件比下载4个25KB的文件更快，所以可以通过进行脚本的合并去1、减少&lt;script&gt;标签数量 2、减少HTTP请求带来的消耗（针对外链脚本）。\n数据存取1.字面量：代表自身，无特定位置，包括：字符串、数字、布尔值、对象、数组、函数、正则表达式及null和undefined2.本地变量：var&#x2F;let&#x2F;const关键字定义的数据存储单元3.数组元素：存储在JavaScript数组对象内部，以数字为索引，下标从0开始4.对象成员：存储在JavaScript对象内部，以字符串为索引从一个字面量和本地变量中存取数据时的性能消耗极小（可忽略），数组和对象则稍高一些。建议：尽量使用字面量和局部变量（局部变量在方法运行过后会自行释放，用完手动置为null或undefined也行），减少使用对象和数组,比如某作用域内的值呗函数引用一次以上，就可以把它存储到局部变量中来使用\n算法及流程控制\nfor in循环可以枚举任何对象的属性名（不是值），但是for in比其他三个循环明显要慢，所以除非要迭代一个属性数量未知的对象，否则避免使用for in循环，如果遍历一个属性数量已知属性列表，其他循环比for in快\n\n假设以上四种循环类型性能一样，可以从两个方面去优化循环的性能： (当循环体复杂度为X时，优化方案优先减少循环体的复杂度，循环体复杂度大于X时，优化方案优先减少迭代次数 ) 1.每次迭代的事务（减少循环体的复杂度） 2.迭代的次数（减少循环的次数，百度‘达夫设备’），可以这么理解，达夫设备就是拆解循环，比如遍历一个长度为100的数组，普通情况下循环体执行100次，达夫设备的思想是把100次拆为每次循环执行多次（n表示）100对n取余，执行取余次数，再执行100除以n（下舍）次循环，这个循环体执行n次普通循环体的操作 达夫设备代码：(这个8就是我说的n)\n var a = [1,2,3,4,5,6,7,8,9,10]var it = Math.floor(a.length / 4),st = a.length % 4,i = 0do&#123;  switch(st) &#123;    case 0: console.log(0,a[i++]);    case 7: console.log(7,a[i++]);    case 6: console.log(6,a[i++]);    case 5: console.log(5,a[i++]);    case 4: console.log(4,a[i++]);    case 3: console.log(3,a[i++]);    case 2: console.log(2,a[i++]);    case 1: console.log(1,a[i++]);  &#125;  st = 0&#125;while(--it)\n\n最小化属性查找：\n for(var i = 0, len = arr.length; i &lt; len; i++)&#123;    ...&#125;\n\n 基于函数的迭代：forEach() forEach遍历一个数组的所有成员，并执行一个函数\n arr.forEach(function(value, index, array)&#123;    ...&#125;)\n\n 但是所有情况下。基于循环的迭代比基于函数的迭代快8倍，在运行速度要求严格时，基于循环的迭代优先于基于函数的迭代\n\nif-else对比switch： 当条件较少时 使用if-else更易读，而当条件较多时if-else性能负担比switch大，易读性也没switch好。 优化if-else的方法是：尽可能的把可能出现的条件放在首位，比如：\n var i = Math.random(1);       if(i &lt;= 0.8)&#123;            //i小于0.8是几率最大的，如果i的值满足i &lt;= 0.8 后面的条件就不会再判断了        ...    &#125;else if(i &gt; 0.8 &amp;&amp; i &lt;= 0.9)&#123;        ...    &#125;else&#123;        ...    &#125;\n\n 当条件很多的时候：（比如10个和10个以上），避免使用条件语句if-else、switch是最佳方式是使用hash表\n\n\n\n* Memoization\n\n减少工作量就是最好的性能优化技术（你可以理解为，砍需求是为了性能优化）  \nMemoization避免重复工作，缓存前一个计算的结果为后面的计算所用\n\n\n​(do-while, while) &gt; for &gt; forEach​\n forEach为函数调用（慢在函数查找\n 达夫设备 速度和 (do-while, while) 相差无几，有时更慢，但是比其他循环更快\n\n\n实践\n//创建一个对象 较慢var myObject = new Object();my0bject.name = &quot;Nicholas&quot;;my0bject.count =50;//较快   直接量var myObject =&#123;  name: &quot;Nicholas&quot;  count: 50&#125;\n\n\n尽量使用直接量创建对象和数组。直接量的创建和初始化都比非直接量形式要快。·避免做重复的工作。当需要检测浏览器时，可使用延迟加载或条件预加载。\n在进行数学计算时，考虑使用直接操作数字的二进制形式的位运算。\nJavaScript的原生方法总会比你写的任何代码都要快。尽量使用原生方法。\n\n","categories":["js"],"tags":["性能优化"]},{"title":"齐次坐标到底是什么","url":"/blog/%E9%BD%90%E6%AC%A1%E5%9D%90%E6%A0%87%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88/","content":"齐次坐标齐次坐标可以用来区分 (X,Y) 到底是个向量还是个坐标，它不是一个新的坐标系，不是说把二维的变成三维的，它是一种记法。\n（x,y,0) 表示一个向量， (x,y,1)表示一个坐标。\n点+点&#x3D;点，点加向量&#x3D;点，向量+向量&#x3D;向量，点-点&#x3D;向量。\n引入齐次坐标是为了在发生变换时，其几何意义依然准确。\n一个向量平移之后，其结果仍然是这个向量，而一个点平移之后，其值就会发生变化但仍然是一个点。\n对于平移来说：\n$$\\left(\\begin{array}{cccc}1 &amp; 0 &amp; 0 &amp; t_{x} \\\\0 &amp; 1 &amp; 0 &amp; t_{y} \\\\0 &amp; 0 &amp; 1 &amp; t_{z} \\\\0 &amp; 0 &amp; 0 &amp; 1\\end{array}\\right) \\cdot\\left(\\begin{array}{c}x_{0} \\\\y_{0} \\\\z_{0} \\\\w_{0}\\end{array}\\right)&#x3D;\\left(\\begin{array}{c}x_{0}+w_{0} * t_{x} \\\\y_{0}+w_{0} * t_{y} \\\\z_{0}+w_{0} * t_{z} \\\\w_{0}\\end{array}\\right)$$\n如果$w_{0}$是0，那这个结果就是$\\left(x_{0}, y_{0}, z_{0}\\right)$，与向量的定义相符。\n如果$w_{0}$是1，结果仍是一个点，与点的定义相符。\n‍\n对于平移、旋转、缩放这3个最常见的仿射变换，平移变换只对点有意义，因为向量没有位置概念。\n而旋转和缩放对于向量和点都有意义。\n‍\n","categories":["图形学"]},{"title":"设计一个拦截器","url":"/blog/%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E6%8B%A6%E6%88%AA%E5%99%A8/","content":"拦截器是一个函数\nasync (ctx, next) =&gt; &#123;  do sth...&#125;\n\n它有两个参数。第一个参数是一个上下文，这个上下文在多个拦截切面中是共享的。第二个参数是一个 next 函数，调用它会进入下一个拦截切面。\nclass Interceptor &#123;  constructor() &#123;    this.aspects = []; // 用于存储拦截切面  &#125;  use(/* async */ functor) &#123;    // 注册拦截切面    this.aspects.push(functor);    return this;  &#125;  async run(context) &#123;    // 执行注册的拦截切面    const aspects = this.aspects;    // 将注册的拦截切面包装成一个洋葱模型    const proc = aspects.reduceRight(      function (a, b) &#123;        return async () =&gt; &#123;          await b(context, a);        &#125;;      &#125;,      () =&gt; Promise.resolve()    );    try &#123;      await proc(); //从外到里执行这个洋葱模型    &#125; catch (ex) &#123;      console.error(ex.message);    &#125;    return context;  &#125;&#125;module.exports = Interceptor;\n\n测试代码\nfunction wait(ms) &#123;  return new Promise((resolve) =&gt; &#123;    setTimeout(resolve, ms);  &#125;);&#125;const inter = new Interceptor();const task = function (id) &#123;  return async (ctx, next) =&gt; &#123;    console.log(`task $&#123;id&#125; begin`);    ctx.count++;    await wait(1000);    console.log(`count: $&#123;ctx.count&#125;`);    await next();    console.log(`task $&#123;id&#125; end`);  &#125;;&#125;;// 将多个任务以拦截切面的方式注册到拦截器中inter.use(task(0));inter.use(task(1));inter.use(task(2));inter.use(task(3));inter.use(task(4));// 从外到里依次执行拦截切面inter.run(&#123; count: 0 &#125;);\n\n使用拦截器的好处：控制业务流程，复用模块功能（拦截切面可以被共用，避免代码冗余）\n","categories":["js"],"tags":["进阶"]}]