---
title: 10 计算图（Computation Graph）
date: 2025-12-08T07:45:52Z
lastmod: 2025-12-08T07:47:02Z
categories: 神经网络与深度学习
---

### 1. 背景与动机

　　在深度学习中，神经网络的计算通常分为两个阶段：

- **前向传播（Forward Propagation）** ：从输入开始，逐层计算，最终得到输出（例如损失函数 $J$）。
- **反向传播（Backward Propagation）** ：从输出 $J$ 出发，利用链式法则计算梯度（即偏导数），用于参数更新。

　　**计算图** 正是用来清晰地表示这两个过程的工具。它将复杂的函数分解为一系列基本运算，并以有向图的形式组织起来，使得前向计算和反向求导变得直观且系统化。

---

### 2. 简化示例：函数 $J = 3(a + bc)$

　　为了说明计算图，课程使用了一个比完整神经网络更简单的函数：

$$
J = 3(a + bc)
$$

　　这个函数可以分解为 **三个计算步骤**：

#### 步骤 1：计算中间变量 $u$

$$
u = b \cdot c
$$

#### 步骤 2：计算中间变量 $v$

$$
v = a + u
$$

#### 步骤 3：计算最终输出 $J$

$$
J = 3v
$$

---

### 3. 构建计算图

　　计算图是一个**有向无环图（DAG）** ，节点表示变量或操作，边表示数据流向。

- **输入节点（叶节点）** ：$a, b, c$
- **中间节点**：$u, v$
- **输出节点（根节点）** ：$J$

　　图结构如下（文字描述）：

```text
a ----\
        +----> [v = a + u] ----> [J = 3v]
b ----\       ^
       *----> [u = b·c]
c ----/
```

- 从左到右（蓝色箭头）：**前向传播**，计算 $J$ 的值。
- 从右到左（红色箭头）：**反向传播**，计算 $\frac{\partial J}{\partial a}, \frac{\partial J}{\partial b}, \frac{\partial J}{\partial c}$。

---

### 4. 前向传播示例（数值代入）

　　设：

- $a = 5$
- $b = 3$
- $c = 2$

　　则逐步计算：

1. $u = b \cdot c = 3 \times 2 = 6$
2. $v = a + u = 5 + 6 = 11$
3. $J = 3v = 3 \times 11 = 33$

　　验证原式：

$$
J = 3(a + bc) = 3(5 + 3 \times 2) = 3(5 + 6) = 3 \times 11 = 33 \quad \checkmark
$$

---

### 5. 为什么需要计算图？

- **模块化**：将复杂函数拆解为简单操作（如加法、乘法），便于实现和调试。
- **自动微分基础**：现代深度学习框架（如 TensorFlow、PyTorch）底层都依赖计算图来自动计算梯度。
- **高效反向传播**：通过**链式法则（Chain Rule）** ，从输出 $J$ 反向逐层计算梯度，避免重复计算。

> 在后续课程中，将展示如何通过**从右向左的反向遍历**，高效计算：
>
> $$
> \frac{\partial J}{\partial a},\quad \frac{\partial J}{\partial b},\quad \frac{\partial J}{\partial c}
> $$

---

### 6. 与神经网络的联系

- 在逻辑回归或神经网络中，$J$ 通常是**损失函数（Loss Function）** ，例如交叉熵损失。
- 我们的目标是**最小化** **$J$**，因此需要知道 $J$ 对每个参数（如权重 $w$、偏置 $b$）的梯度。
- 计算图使得这一过程**系统化、可扩展**，即使网络有成千上万个参数，也能高效求导。

---

### ✅ 总结要点

|概念|说明|
| ------| -----------------------------------------------------|
|**计算图**|将函数分解为基本运算的有向图，用于组织前向/反向计算|
|**前向传播**|从输入到输出，计算函数值（如 $J$）|
|**反向传播**|从输出到输入，利用链式法则计算梯度|
|**中间变量**|如 $u = bc$, $v = a + u$，使复杂函数可分解|
|**实际应用**|是自动微分和深度学习框架的核心机制|
